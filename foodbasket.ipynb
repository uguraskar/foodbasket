{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.0 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "0e8f02916ce4ec57490847cc8c54c12a9dae65680be9326a3269d9b7a61d6d19"
   }
  },
  "interpreter": {
   "hash": "0e8f02916ce4ec57490847cc8c54c12a9dae65680be9326a3269d9b7a61d6d19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Web Scraping"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv(\"dev.env\")\n",
    "import os\n",
    "\n",
    "db_name = os.getenv(\"db_name\")\n",
    "db_username = os.getenv(\"db_username\")\n",
    "db_password = os.getenv(\"db_password\")\n",
    "db_host = os.getenv(\"db_host\")\n",
    "db_port = os.getenv(\"db_port\")\n",
    "website = os.getenv(\"website\")\n",
    "city_link = os.getenv(\"city_link\")\n",
    "chrome_path = os.getenv(\"chrome_path\")\n",
    "selenium_chrome_driver_path = os.getenv(\"selenium_chrome_driver_path\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import time\n",
    "import math\n",
    "import numpy as np\n",
    "import os.path\n",
    "import pandas as pd\n",
    "import re\n",
    "import pycld2\n",
    "import nltk\n",
    "import joblib\n",
    "import warnings\n",
    "from datetime import date, timedelta, datetime\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By \n",
    "from selenium.webdriver.support.ui import WebDriverWait \n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from nltk.corpus import stopwords\n",
    "from TurkishStemmer import TurkishStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "nltk.download('stopwords', quiet=True)\n",
    "\n",
    "stemmer = TurkishStemmer()\n",
    "\n",
    "conn_string = 'host={pghost} port={pgport} dbname={pgdatabase} user={pguser} password={pgpassword}'.format(pgdatabase=db_name,pguser=db_username,pgpassword=db_password,pghost=db_host,pgport=db_port)\n",
    "conn=psycopg2.connect(conn_string)\n",
    "cur=conn.cursor()\n",
    "\n",
    "options = Options()\n",
    "options.binary_location = chrome_path\n",
    "\n",
    "def check_if_table_exists(schema,table):\n",
    "    cur.execute(\"select exists(select * from information_schema.tables where table_schema='{schema}' AND table_name='{table}')\".format(schema=schema, table=table))\n",
    "    return cur.fetchone()[0]\n",
    "\n",
    "def check_if_index_exists(index):\n",
    "    cur.execute(\"SELECT EXISTS(SELECT * FROM PG_CLASS WHERE relname = '{index}')\".format(index=index))\n",
    "    return cur.fetchone()[0]\n",
    "\n",
    "def check_if_file_exists(filename):\n",
    "    return os.path.isfile(filename)\n",
    "\n",
    "def execute_mogrify(conn, df, schema, table):\n",
    "    tuples = [tuple(x) for x in df.to_numpy()]\n",
    "    cols = '\"'+'\",\"'.join(list(df.columns))+'\"'\n",
    "    cursor = conn.cursor()    \n",
    "    try:\n",
    "        for tup in tuples:\n",
    "            query  = \"\"\"INSERT INTO \"{schema}\".\"{table}\"({cols}) VALUES ({values}) ON CONFLICT DO NOTHING\"\"\".format(schema=schema,table=table, cols=cols, values=\",\".join(map(str,tup)))\n",
    "            cursor.execute(query)\n",
    "            conn.commit()\n",
    "    except (Exception, psycopg2.DatabaseError) as error:\n",
    "        print(\"Error: %s\" % error)\n",
    "        conn.rollback()\n",
    "        cursor.close()\n",
    "        return 1\n",
    "    cursor.close()\n",
    "\n",
    "def df_column_conversation(df, column_name, type):\n",
    "    if(type == 'timestamp'):\n",
    "        df[column_name] = df[column_name].apply(lambda x: f\"'{x}'::timestamp\")\n",
    "    if(type == 'text'):\n",
    "        df[column_name] = df[column_name].str.replace(\"'\",\"\").apply(lambda x: f\"'{x}'\")\n",
    "    if(type == 'date'):\n",
    "        df[column_name] = df[column_name].apply(lambda x: f\"'{x}'::date\")\n",
    "    if(type == 'numeric'):\n",
    "        df[column_name] = df[column_name].apply(str).str.replace(',','.')\n",
    "    if(type == 'integer'):\n",
    "        df[column_name] = df[column_name].apply(str).str.replace(',','.').apply(float).astype('Int64').apply(str)\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"[,.\\\"\\'!@#$%^&*(){}?/;`~:<>+=-\\\\]\", \"\", text)\n",
    "    return text\n",
    "    \n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Table ODS.EXT_FB_RESTAURANT already exists.\nTable ODS.EXT_FB_MENU already exists.\nTable ODS.EXT_FB_COMMENT already exists.\nTable EDW.DWH_FB_COMMENT already exists.\n"
     ]
    }
   ],
   "source": [
    "if(check_if_table_exists('ODS','EXT_FB_RESTAURANT')):\n",
    "    print('Table ODS.EXT_FB_RESTAURANT already exists.')   \n",
    "else:\n",
    "    start_time = math.trunc(time.time())\n",
    "    cur.execute(\"\"\"\n",
    "    CREATE TABLE \"ODS\".\"EXT_FB_RESTAURANT\"\n",
    "    (\n",
    "    \"RESTAURANT_ID\" text NOT NULL,\n",
    "    \"RESTAURANT_NAME\" text,\n",
    "    \"RESTAURANT_LINK\" text,\n",
    "    \"DATE\" date,    \n",
    "    CONSTRAINT \"RESTAURANT_ID\" UNIQUE (\"RESTAURANT_ID\")\n",
    "    );\n",
    "    \"\"\")\n",
    "    cur.execute('COMMIT;')\n",
    "    end_time = math.trunc(time.time())\n",
    "    print(\"Table ODS.EXT_FB_RESTAURANT created in {execute_time} seconds.\".format(execute_time=end_time-start_time))\n",
    "\n",
    "if(check_if_table_exists('ODS','EXT_FB_MENU')):\n",
    "    print('Table ODS.EXT_FB_MENU already exists.')   \n",
    "else:\n",
    "    start_time = math.trunc(time.time())\n",
    "    cur.execute(\"\"\"\n",
    "    CREATE TABLE \"ODS\".\"EXT_FB_MENU\"\n",
    "    (\n",
    "    \"PRODUCT_ID\" text NOT NULL,\n",
    "    \"RESTAURANT_ID\" text,\n",
    "    \"CATEGORY_NAME\" text,\n",
    "    \"PRODUCT_NAME\" text,\n",
    "    \"PRODUCT_DESCRIPTION\" text,\n",
    "    \"PRODUCT_LISTED_PRICE\" text,\n",
    "    \"PRODUCT_PRICE\" text,\n",
    "    \"DISCOUNT\" boolean,\n",
    "    \"DESIGN_TYPE\" text,\n",
    "    \"DATE\" date,\n",
    "    CONSTRAINT \"PRODUCT_ID\" UNIQUE (\"PRODUCT_ID\")\n",
    "    );\n",
    "    \"\"\")\n",
    "    cur.execute('COMMIT;')\n",
    "    end_time = math.trunc(time.time())\n",
    "    print(\"Table ODS.EXT_FB_MENU created in {execute_time} seconds.\".format(execute_time=end_time-start_time))\n",
    "\n",
    "if(check_if_table_exists('ODS','EXT_FB_COMMENT')):\n",
    "    print('Table ODS.EXT_FB_COMMENT already exists.')   \n",
    "else:\n",
    "    start_time = math.trunc(time.time())\n",
    "    cur.execute(\"\"\"\n",
    "    CREATE TABLE \"ODS\".\"EXT_FB_COMMENT\"\n",
    "    (\n",
    "    \"RESTAURANT_ID\" text,\n",
    "    \"USERNAME\" text,\n",
    "    \"COMMENT_TEXT\" text,\n",
    "    \"COMMENT_DATE\" text,\n",
    "    \"SPEED\" text,\n",
    "    \"SERVING\" text,\n",
    "    \"FLAVOUR\" text,\n",
    "    \"DATE\" date,\n",
    "    CONSTRAINT \"UNIQUE_COMMENTS\" UNIQUE (\"RESTAURANT_ID\", \"USERNAME\", \"COMMENT_TEXT\")\n",
    "    );\n",
    "    \"\"\")\n",
    "    cur.execute('COMMIT;')\n",
    "    end_time = math.trunc(time.time())\n",
    "    print(\"Table ODS.EXT_FB_COMMENT created in {execute_time} seconds.\".format(execute_time=end_time-start_time))\n",
    "\n",
    "if(check_if_table_exists('EDW','DWH_FB_COMMENT')):\n",
    "    print('Table EDW.DWH_FB_COMMENT already exists.')   \n",
    "else:\n",
    "    start_time = math.trunc(time.time())\n",
    "    cur.execute(\"\"\"\n",
    "    CREATE TABLE \"EDW\".\"DWH_FB_COMMENT\"\n",
    "    (\n",
    "    \"RESTAURANT_ID\" text,\n",
    "    \"USERNAME\" text,\n",
    "    \"COMMENT_TEXT\" text,\n",
    "    \"COMMENT_DATE\" date,\n",
    "    \"SPEED\" integer,\n",
    "    \"SERVING\" integer,\n",
    "    \"FLAVOUR\" integer,\n",
    "    \"DATE\" date,\n",
    "    CONSTRAINT \"UNIQUE_COMMENTS\" UNIQUE (\"RESTAURANT_ID\", \"USERNAME\", \"COMMENT_TEXT\")\n",
    "    );\n",
    "    \"\"\")\n",
    "    cur.execute('COMMIT;')\n",
    "    end_time = math.trunc(time.time())\n",
    "    print(\"Table EDW.DWH_FB_COMMENT created in {execute_time} seconds.\".format(execute_time=end_time-start_time))\n",
    "\n",
    "cur.execute(\"\"\"\n",
    "CREATE OR REPLACE FUNCTION public.try_cast(_in text, INOUT _out anyelement)\n",
    "    LANGUAGE 'plpgsql'\n",
    "AS $BODY$\n",
    "BEGIN\n",
    "   EXECUTE format('SELECT %L::%s', $1, pg_typeof(_out))\n",
    "   INTO  _out;\n",
    "EXCEPTION WHEN others THEN\n",
    "   -- do nothing: _out already carries default\n",
    "END\n",
    "$BODY$;\n",
    "\"\"\")\n",
    "cur.execute('COMMIT;')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "datetime.date(2021, 6, 11)"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "cur.execute(\"\"\"\n",
    "WITH DATES AS(\n",
    "SELECT \n",
    "MAX(\"DATE\") AS \"DATE\"\n",
    "FROM \"ODS\".\"EXT_FB_MENU\" EFM\n",
    "UNION ALL\n",
    "SELECT \n",
    "MAX(\"DATE\") AS \"DATE\"\n",
    "FROM \"ODS\".\"EXT_FB_COMMENT\" EFC\n",
    ")\n",
    "SELECT \n",
    "MAX(\"DATE\") AS \"LAST_EXECUTION_DATE\"\n",
    "FROM DATES;\n",
    "\"\"\")\n",
    "last_execution_date = cur.fetchone()[0]\n",
    "last_execution_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "restaurant_list = []\n",
    "end_date = min(date(2021,6,11),(date.today() - timedelta(days=1)))\n",
    "\n",
    "driver = webdriver.Chrome(options=options, executable_path=selenium_chrome_driver_path)\n",
    "if(last_execution_date < end_date):\n",
    "    driver.get(city_link)\n",
    "    time.sleep(5)\n",
    "    for i in range(25):\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(2)\n",
    "    city_restaurant_groups = driver.find_elements_by_class_name(\"restaurant-main-info\")\n",
    "    for restaurant in city_restaurant_groups:\n",
    "        restaurant_name = restaurant.find_element_by_class_name(\"restaurant-display-name\").text\n",
    "        restaurant_name = restaurant_name.replace(\"YENİ \", \"\")\n",
    "        restaurant_link = restaurant.find_element_by_class_name(\"restaurant-display-name\").find_element_by_xpath(\".//a\").get_attribute('href')\n",
    "        restaurant_id = restaurant_link.split(\"/\")[-1]\n",
    "        if(len(restaurant_link) < 2):\n",
    "            continue\n",
    "        restaurant_list.append([restaurant_id,restaurant_name,restaurant_link])\n",
    "    restaurant_df = pd.DataFrame(restaurant_list, columns=[\"RESTAURANT_ID\",\"RESTAURANT_NAME\",\"RESTAURANT_LINK\"])\n",
    "\n",
    "    df_column_conversation(restaurant_df, 'RESTAURANT_ID', 'text')\n",
    "    df_column_conversation(restaurant_df, 'RESTAURANT_NAME', 'text')\n",
    "    df_column_conversation(restaurant_df, 'RESTAURANT_LINK', 'text')    \n",
    "    restaurant_df['DATE'] = \"'\"+ datetime.strftime(date.today(), \"%Y-%m-%d\") + \"'::date\"\n",
    "    execute_mogrify(conn,restaurant_df,\"ODS\",\"EXT_FB_RESTAURANT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_command = \"\"\"\n",
    "    SELECT\n",
    "    \"RESTAURANT_ID\"\n",
    "    FROM \"ODS\".\"EXT_FB_RESTAURANT\" EFR\n",
    "    WHERE 1=1\n",
    "    AND NOT EXISTS(SELECT NULL FROM \"ODS\".\"EXT_FB_MENU\" EFM WHERE EFR.\"RESTAURANT_ID\" = EFM.\"RESTAURANT_ID\");\n",
    "    \"\"\"\n",
    "restaurant_df = pd.read_sql(sql_command,conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(last_execution_date < end_date):\n",
    "    for i in range(len(restaurant_df)):\n",
    "        sublink = restaurant_df.loc[i,\"RESTAURANT_ID\"]\n",
    "        restaurant_link = \"{website}/{sublink}\".format(website=website,sublink=sublink)\n",
    "        \n",
    "        driver.get(restaurant_link)\n",
    "        time.sleep(5)\n",
    "\n",
    "        try:\n",
    "            if(\"sipariş verebilirsiniz.\" in driver.find_element_by_xpath('//*[@id=\"restaurantDetail\"]/div/div[2]/h3').text):\n",
    "                continue\n",
    "            else:\n",
    "                pass\n",
    "        except Exception:\n",
    "            pass\n",
    "        \n",
    "        menu = driver.find_element_by_xpath('//*[@id=\"restaurant_menu\"]')\n",
    "        categories = menu.find_elements_by_xpath('//*[contains(@id,\"menu_\")]')\n",
    "\n",
    "        menu_list = []\n",
    "\n",
    "        for category in categories:\n",
    "            category_name = category.find_element_by_xpath(\".//b\").text\n",
    "            for product in category.find_elements_by_xpath(\".//div[2]/ul/li\"):\n",
    "                try:\n",
    "                    design_type = \"list\"\n",
    "                    try:\n",
    "                        product_id = product.find_elements_by_class_name(\"getProductDetail\")[-1].get_attribute('data-product-id')\n",
    "                        product_name = product.find_elements_by_class_name(\"getProductDetail\")[-1].text\n",
    "                    except:\n",
    "                        product_id = product.find_element_by_xpath(\".//strong\").get_attribute('data-product-id')\n",
    "                        product_name = product.find_element_by_xpath(\".//strong\").text\n",
    "                        design_type = \"card\"\n",
    "                    try:\n",
    "                        product_description = product.find_element_by_class_name(\"product-desc\").text\n",
    "                        product_price = product.find_element_by_class_name(\"price\").text    \n",
    "                    except:\n",
    "                        product_description = product.find_element_by_class_name(\"productInfo\").text\n",
    "                        product_price = product.find_element_by_class_name(\"newPrice\").text\n",
    "                        if(not(design_type==\"card\")):\n",
    "                            design_type = \"box\"\n",
    "                    discount = \"TRUE\"\n",
    "                    try:              \n",
    "                        if(design_type==\"list\"):\n",
    "                            product_listed_price = product.find_element_by_class_name(\"listed-price\").text\n",
    "                        if(design_type in [\"card\",\"box\"]):\n",
    "                            product_listed_price = product.find_element_by_class_name(\"listedPrice\").text\n",
    "                    except:\n",
    "                        product_listed_price = product_price\n",
    "                        discount = \"FALSE\"\n",
    "                    menu_list.append([product_id,sublink,category_name,product_name,product_description,product_listed_price,product_price,discount,design_type])\n",
    "                except:\n",
    "                    continue\n",
    "        menu_df = pd.DataFrame(menu_list, columns=[\"PRODUCT_ID\",\"RESTAURANT_ID\",\"CATEGORY_NAME\",\"PRODUCT_NAME\",\"PRODUCT_DESCRIPTION\",\"PRODUCT_LISTED_PRICE\",\"PRODUCT_PRICE\",\"DISCOUNT\",\"DESIGN_TYPE\"])    \n",
    "        menu_df = menu_df[menu_df['PRODUCT_ID'].str.len() > 0]\n",
    "        menu_df = menu_df[menu_df['PRODUCT_NAME'].str.len() > 0]\n",
    "\n",
    "        df_column_conversation(menu_df, 'PRODUCT_ID', 'text')\n",
    "        df_column_conversation(menu_df, 'RESTAURANT_ID', 'text')\n",
    "        df_column_conversation(menu_df, 'CATEGORY_NAME', 'text')\n",
    "        df_column_conversation(menu_df, 'PRODUCT_NAME', 'text')\n",
    "        df_column_conversation(menu_df, 'PRODUCT_DESCRIPTION', 'text')\n",
    "        df_column_conversation(menu_df, 'PRODUCT_LISTED_PRICE', 'text')\n",
    "        df_column_conversation(menu_df, 'PRODUCT_PRICE', 'text')\n",
    "        df_column_conversation(menu_df, 'DESIGN_TYPE', 'text')\n",
    "        menu_df['DATE'] = \"'\"+ datetime.strftime(date.today(), \"%Y-%m-%d\") + \"'::date\"\n",
    "        execute_mogrify(conn,menu_df,\"ODS\",\"EXT_FB_MENU\")\n",
    "    menu_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                        RESTAURANT_ID\n",
       "47        pizza-2m-kadikoy-caferaga-mah-moda-istanbul\n",
       "31                  by-bado-sile-kumbaba-mah-istanbul\n",
       "15        pizza-steak-beylikduzu-kavakli-mah-istanbul\n",
       "13  crakers-pizza-basaksehir-guvercintepe-mah-ista...\n",
       "39                   ghita-sariyer-huzur-mah-istanbul\n",
       "..                                                ...\n",
       "54      ellisse-beyoglu-omeravni-mah-kabatas-istanbul\n",
       "77      peggys-pizza-besiktas-arnavutkoy-mah-istanbul\n",
       "33  guvecci-pideci-aziz-usta-bayrampasa-cevatpasa-...\n",
       "1           pizzeria-eyup-gokturk-merkez-mah-istanbul\n",
       "64                un-po-beyoglu-kemankes-mah-istanbul\n",
       "\n",
       "[79 rows x 1 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>RESTAURANT_ID</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>47</th>\n      <td>pizza-2m-kadikoy-caferaga-mah-moda-istanbul</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>by-bado-sile-kumbaba-mah-istanbul</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>pizza-steak-beylikduzu-kavakli-mah-istanbul</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>crakers-pizza-basaksehir-guvercintepe-mah-ista...</td>\n    </tr>\n    <tr>\n      <th>39</th>\n      <td>ghita-sariyer-huzur-mah-istanbul</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>54</th>\n      <td>ellisse-beyoglu-omeravni-mah-kabatas-istanbul</td>\n    </tr>\n    <tr>\n      <th>77</th>\n      <td>peggys-pizza-besiktas-arnavutkoy-mah-istanbul</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>guvecci-pideci-aziz-usta-bayrampasa-cevatpasa-...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>pizzeria-eyup-gokturk-merkez-mah-istanbul</td>\n    </tr>\n    <tr>\n      <th>64</th>\n      <td>un-po-beyoglu-kemankes-mah-istanbul</td>\n    </tr>\n  </tbody>\n</table>\n<p>79 rows × 1 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "sql_command = \"\"\"\n",
    "    SELECT\n",
    "    \"RESTAURANT_ID\"\n",
    "    FROM \"ODS\".\"EXT_FB_RESTAURANT\" EFR\n",
    "    WHERE 1=1\n",
    "    AND NOT EXISTS(SELECT NULL FROM \"ODS\".\"EXT_FB_COMMENT\" EFC WHERE EFR.\"RESTAURANT_ID\" = EFC.\"RESTAURANT_ID\");\n",
    "    \"\"\"\n",
    "restaurant_df = pd.read_sql(sql_command,conn)\n",
    "restaurant_df = restaurant_df.sample(frac=1)\n",
    "restaurant_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(last_execution_date < end_date):\n",
    "    for i in range(len(restaurant_df)):\n",
    "        sublink = restaurant_df.loc[i,\"RESTAURANT_ID\"]\n",
    "        last_comment_page_url = \"{website}/{sublink}?section=comments&page=9999\".format(website=website,sublink=sublink)\n",
    "        \n",
    "        driver.get(last_comment_page_url)\n",
    "        time.sleep(0.1)\n",
    "\n",
    "        comments_list = []\n",
    "        \n",
    "        if(sublink not in driver.current_url):\n",
    "            continue\n",
    "\n",
    "        last_comment_page_redirect_url = driver.current_url\n",
    "        last_comment_page_number = int(last_comment_page_redirect_url.replace(\"&status=closed\",\"\").replace(\"{website}/{sublink}?section=comments&page=\".format(website=website,sublink=sublink),\"\"))\n",
    "\n",
    "        for page_number in range(1, last_comment_page_number+1):\n",
    "            current_comment_page_url = \"{website}/{sublink}?section=comments&page={page_number}\".format(website=website,sublink=sublink,page_number=page_number)\n",
    "            driver.get(current_comment_page_url)\n",
    "            time.sleep(1)\n",
    "\n",
    "            try:\n",
    "                if(\"sipariş verebilirsiniz.\" in driver.find_element_by_xpath('//*[@id=\"restaurantDetail\"]/div/div[2]/h3').text):\n",
    "                    continue\n",
    "                else:\n",
    "                    pass\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "            try:\n",
    "                driver.find_element(By.XPATH, '//*[@id=\"alternative-restaurant-popup\"]/div[1]/div[2]/img').click(); #Closing pop-up\n",
    "            except Exception:\n",
    "                pass   \n",
    "\n",
    "            #driver.find_element(By.XPATH, '//*[@id=\"restaurantDetail\"]/div[2]/div[1]/ul/li[4]/a').click(); #Clicking comments\n",
    "\n",
    "            comment_list = driver.find_elements_by_class_name(\"comments-body\")\n",
    "        \n",
    "            for comment in comment_list:\n",
    "                try:\n",
    "                    username = comment.find_element_by_class_name(\"userName\").text\n",
    "                    comment_text = comment.find_element_by_xpath('.//p').text\n",
    "                    comment_date = comment.find_element_by_class_name(\"commentDate\").text\n",
    "                except NoSuchElementException:\n",
    "                    continue\n",
    "                try:\n",
    "                    speed = comment.find_element_by_class_name(\"speed\").text\n",
    "                except NoSuchElementException:\n",
    "                    speed = \"\"\n",
    "                try:                    \n",
    "                    serving = comment.find_element_by_class_name(\"serving\").text\n",
    "                except NoSuchElementException:\n",
    "                    serving = \"\"\n",
    "                try:\n",
    "                    flavour = comment.find_element_by_class_name(\"flavour\").text \n",
    "                except NoSuchElementException:\n",
    "                    flavour = \"\"\n",
    "                comments_list.append([sublink, username, comment_text, comment_date, speed, serving, flavour])\n",
    "        comment_df = pd.DataFrame(comments_list, columns=[\"RESTAURANT_ID\",\"USERNAME\",\"COMMENT_TEXT\",\"COMMENT_DATE\",\"SPEED\",\"SERVING\",\"FLAVOUR\"])\n",
    "        df_column_conversation(comment_df, 'RESTAURANT_ID', 'text')\n",
    "        df_column_conversation(comment_df, 'USERNAME', 'text')\n",
    "        df_column_conversation(comment_df, 'COMMENT_TEXT', 'text')\n",
    "        df_column_conversation(comment_df, 'COMMENT_DATE', 'text')\n",
    "        df_column_conversation(comment_df, 'SPEED', 'text')\n",
    "        df_column_conversation(comment_df, 'SERVING', 'text')\n",
    "        df_column_conversation(comment_df, 'FLAVOUR', 'text')\n",
    "        comment_df['DATE'] = \"'\"+ datetime.strftime(date.today(), \"%Y-%m-%d\") + \"'::date\"\n",
    "        execute_mogrify(conn,comment_df,\"ODS\",\"EXT_FB_COMMENT\")\n",
    "    comment_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.quit()"
   ]
  },
  {
   "source": [
    "# Data Preprocessing"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(last_execution_date < end_date):\n",
    "    sql_command = \"\"\"\n",
    "        WITH CLEAN_DATA AS(\n",
    "        SELECT\n",
    "        EFC.\"RESTAURANT_ID\",\n",
    "        EFC.\"USERNAME\",\n",
    "        LOWER(EFC.\"COMMENT_TEXT\") AS \"COMMENT_TEXT\",\n",
    "        EFC.\"COMMENT_DATE\",\n",
    "        TRY_CAST(REGEXP_REPLACE(EFC.\"SPEED\", '\\D','','g'),NULL::INTEGER) AS \"SPEED\",\n",
    "        TRY_CAST(REGEXP_REPLACE(EFC.\"SERVING\", '\\D','','g'),NULL::INTEGER) AS \"SERVING\",\n",
    "        TRY_CAST(REGEXP_REPLACE(EFC.\"FLAVOUR\", '\\D','','g'),NULL::INTEGER) AS \"FLAVOUR\",\n",
    "        EFC.\"DATE\",\n",
    "        REGEXP_REPLACE(EFC.\"COMMENT_DATE\", '\\D','','g')||' '||REPLACE(REPLACE(REPLACE(REGEXP_REPLACE(REPLACE(EFC.\"COMMENT_DATE\",' önce',''), '[^[:alpha:]]', '', 'g'),'ay','month'),'bugün','today'),'gün','day') AS \"COMMENT_DATE_INTERVAL\"\n",
    "        FROM \"ODS\".\"EXT_FB_COMMENT\" EFC\n",
    "        WHERE 1=1\n",
    "        AND EFC.\"USERNAME\" <> 'Yemeksepeti'\n",
    "        )\n",
    "        SELECT\n",
    "        CD.\"RESTAURANT_ID\",\n",
    "        CD.\"USERNAME\",\n",
    "        CD.\"COMMENT_TEXT\",\n",
    "        CASE WHEN CD.\"COMMENT_DATE_INTERVAL\" = ' today' THEN CD.\"DATE\" ELSE CD.\"DATE\" - CAST(CD.\"COMMENT_DATE_INTERVAL\" AS INTERVAL) END::date AS \"COMMENT_DATE\",\n",
    "        CD.\"SPEED\",\n",
    "        CD.\"SERVING\",\n",
    "        CD.\"FLAVOUR\",\n",
    "        CD.\"DATE\"\n",
    "        FROM CLEAN_DATA CD;\n",
    "        \"\"\"\n",
    "    comment_df = pd.read_sql(sql_command,conn)\n",
    "    comment_df['COMMENT_TEXT'] = comment_df['COMMENT_TEXT'].apply(clean_text)\n",
    "    comment_df\n",
    "    df_column_conversation(comment_df, 'RESTAURANT_ID', 'text')\n",
    "    df_column_conversation(comment_df, 'USERNAME', 'text')\n",
    "    df_column_conversation(comment_df, 'COMMENT_TEXT', 'text')\n",
    "    df_column_conversation(comment_df, 'COMMENT_DATE', 'date')\n",
    "    df_column_conversation(comment_df, 'SPEED', 'integer')\n",
    "    df_column_conversation(comment_df, 'SERVING', 'integer')\n",
    "    df_column_conversation(comment_df, 'FLAVOUR', 'integer')\n",
    "    df_column_conversation(comment_df, 'DATE', 'date')\n",
    "    comment_df.replace('<NA>', 'NULL', inplace=True)\n",
    "    execute_mogrify(conn,comment_df,\"EDW\",\"DWH_FB_COMMENT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                     RESTAURANT_ID USERNAME  \\\n",
       "0       magic-akademi-kartal-esentepe-mah-istanbul     ...i   \n",
       "1       magic-akademi-kartal-esentepe-mah-istanbul     ...3   \n",
       "2       magic-akademi-kartal-esentepe-mah-istanbul     ...0   \n",
       "3       magic-akademi-kartal-esentepe-mah-istanbul     ...t   \n",
       "4       magic-akademi-kartal-esentepe-mah-istanbul     ...e   \n",
       "...                                            ...      ...   \n",
       "271838  magic-akademi-kartal-esentepe-mah-istanbul     ...1   \n",
       "271839  magic-akademi-kartal-esentepe-mah-istanbul     ...d   \n",
       "271840  magic-akademi-kartal-esentepe-mah-istanbul     ...k   \n",
       "271841  magic-akademi-kartal-esentepe-mah-istanbul     ...7   \n",
       "271842  magic-akademi-kartal-esentepe-mah-istanbul     ...l   \n",
       "\n",
       "                                             COMMENT_TEXT COMMENT_DATE  SPEED  \\\n",
       "0       i̇lk kez sipariş verdim bu restauranttan patat...   2021-01-10   10.0   \n",
       "1       her söyledigimde somon daha da kötüleşiyor bu ...   2021-01-10    9.0   \n",
       "2                                                     itu   2021-01-10    8.0   \n",
       "3          18 dkda kapıdaydi sıcak ve lezzetli süpersiniz   2021-01-10   10.0   \n",
       "4       dağ kekikli tavuğun yanında gelen makarna bild...   2021-01-10   10.0   \n",
       "...                                                   ...          ...    ...   \n",
       "271838        anladık ki hamburgerler kötü pizzadan devam   2021-01-10    5.0   \n",
       "271839  tiramisu malesef rezaletti kreması ekşimişti y...   2021-01-10    1.0   \n",
       "271840     dağ kekikli tavuk inanılmaz güzel bağımlısıyım   2021-01-10   10.0   \n",
       "271841  waffle söyledik kalın bir hamur üzerine 6 7 kü...   2021-01-10    6.0   \n",
       "271842  pizza adana börek ve pasta nefisti teşekkür ed...   2021-01-10   10.0   \n",
       "\n",
       "        SERVING  FLAVOUR        DATE  \n",
       "0             5        8  2021-06-10  \n",
       "1             6        4  2021-06-10  \n",
       "2             8        8  2021-06-10  \n",
       "3            10       10  2021-06-10  \n",
       "4             6        3  2021-06-10  \n",
       "...         ...      ...         ...  \n",
       "271838        5        5  2021-06-10  \n",
       "271839        1        1  2021-06-10  \n",
       "271840       10       10  2021-06-10  \n",
       "271841        4        3  2021-06-10  \n",
       "271842       10        9  2021-06-10  \n",
       "\n",
       "[271843 rows x 8 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>RESTAURANT_ID</th>\n      <th>USERNAME</th>\n      <th>COMMENT_TEXT</th>\n      <th>COMMENT_DATE</th>\n      <th>SPEED</th>\n      <th>SERVING</th>\n      <th>FLAVOUR</th>\n      <th>DATE</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>magic-akademi-kartal-esentepe-mah-istanbul</td>\n      <td>...i</td>\n      <td>i̇lk kez sipariş verdim bu restauranttan patat...</td>\n      <td>2021-01-10</td>\n      <td>10.0</td>\n      <td>5</td>\n      <td>8</td>\n      <td>2021-06-10</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>magic-akademi-kartal-esentepe-mah-istanbul</td>\n      <td>...3</td>\n      <td>her söyledigimde somon daha da kötüleşiyor bu ...</td>\n      <td>2021-01-10</td>\n      <td>9.0</td>\n      <td>6</td>\n      <td>4</td>\n      <td>2021-06-10</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>magic-akademi-kartal-esentepe-mah-istanbul</td>\n      <td>...0</td>\n      <td>itu</td>\n      <td>2021-01-10</td>\n      <td>8.0</td>\n      <td>8</td>\n      <td>8</td>\n      <td>2021-06-10</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>magic-akademi-kartal-esentepe-mah-istanbul</td>\n      <td>...t</td>\n      <td>18 dkda kapıdaydi sıcak ve lezzetli süpersiniz</td>\n      <td>2021-01-10</td>\n      <td>10.0</td>\n      <td>10</td>\n      <td>10</td>\n      <td>2021-06-10</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>magic-akademi-kartal-esentepe-mah-istanbul</td>\n      <td>...e</td>\n      <td>dağ kekikli tavuğun yanında gelen makarna bild...</td>\n      <td>2021-01-10</td>\n      <td>10.0</td>\n      <td>6</td>\n      <td>3</td>\n      <td>2021-06-10</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>271838</th>\n      <td>magic-akademi-kartal-esentepe-mah-istanbul</td>\n      <td>...1</td>\n      <td>anladık ki hamburgerler kötü pizzadan devam</td>\n      <td>2021-01-10</td>\n      <td>5.0</td>\n      <td>5</td>\n      <td>5</td>\n      <td>2021-06-10</td>\n    </tr>\n    <tr>\n      <th>271839</th>\n      <td>magic-akademi-kartal-esentepe-mah-istanbul</td>\n      <td>...d</td>\n      <td>tiramisu malesef rezaletti kreması ekşimişti y...</td>\n      <td>2021-01-10</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2021-06-10</td>\n    </tr>\n    <tr>\n      <th>271840</th>\n      <td>magic-akademi-kartal-esentepe-mah-istanbul</td>\n      <td>...k</td>\n      <td>dağ kekikli tavuk inanılmaz güzel bağımlısıyım</td>\n      <td>2021-01-10</td>\n      <td>10.0</td>\n      <td>10</td>\n      <td>10</td>\n      <td>2021-06-10</td>\n    </tr>\n    <tr>\n      <th>271841</th>\n      <td>magic-akademi-kartal-esentepe-mah-istanbul</td>\n      <td>...7</td>\n      <td>waffle söyledik kalın bir hamur üzerine 6 7 kü...</td>\n      <td>2021-01-10</td>\n      <td>6.0</td>\n      <td>4</td>\n      <td>3</td>\n      <td>2021-06-10</td>\n    </tr>\n    <tr>\n      <th>271842</th>\n      <td>magic-akademi-kartal-esentepe-mah-istanbul</td>\n      <td>...l</td>\n      <td>pizza adana börek ve pasta nefisti teşekkür ed...</td>\n      <td>2021-01-10</td>\n      <td>10.0</td>\n      <td>10</td>\n      <td>9</td>\n      <td>2021-06-10</td>\n    </tr>\n  </tbody>\n</table>\n<p>271843 rows × 8 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "sql_command = \"\"\"\n",
    "    SELECT\n",
    "    *\n",
    "    FROM \"EDW\".\"DWH_FB_COMMENT\" EFR;\n",
    "    \"\"\"\n",
    "comment_df = pd.read_sql(sql_command,conn)\n",
    "comment_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                     RESTAURANT_ID USERNAME  \\\n",
       "0       magic-akademi-kartal-esentepe-mah-istanbul     ...i   \n",
       "1       magic-akademi-kartal-esentepe-mah-istanbul     ...3   \n",
       "2       magic-akademi-kartal-esentepe-mah-istanbul     ...0   \n",
       "3       magic-akademi-kartal-esentepe-mah-istanbul     ...t   \n",
       "4       magic-akademi-kartal-esentepe-mah-istanbul     ...e   \n",
       "...                                            ...      ...   \n",
       "271838  magic-akademi-kartal-esentepe-mah-istanbul     ...1   \n",
       "271839  magic-akademi-kartal-esentepe-mah-istanbul     ...d   \n",
       "271840  magic-akademi-kartal-esentepe-mah-istanbul     ...k   \n",
       "271841  magic-akademi-kartal-esentepe-mah-istanbul     ...7   \n",
       "271842  magic-akademi-kartal-esentepe-mah-istanbul     ...l   \n",
       "\n",
       "                                             COMMENT_TEXT COMMENT_DATE  SPEED  \\\n",
       "0       i̇lk sipariş verdim restauranttan patates sıca...   2021-01-10   10.0   \n",
       "1       söyledigimde somon kötüleşiyor sefer fettucini...   2021-01-10    9.0   \n",
       "2                                                     itu   2021-01-10    8.0   \n",
       "3             18 dkda kapıdaydi sıcak lezzetli süpersiniz   2021-01-10   10.0   \n",
       "4       dağ kekikli tavuğun yanında gelen makarna bild...   2021-01-10   10.0   \n",
       "...                                                   ...          ...    ...   \n",
       "271838           anladık hamburgerler kötü pizzadan devam   2021-01-10    5.0   \n",
       "271839  tiramisu malesef rezaletti kreması ekşimişti y...   2021-01-10    1.0   \n",
       "271840     dağ kekikli tavuk inanılmaz güzel bağımlısıyım   2021-01-10   10.0   \n",
       "271841  waffle söyledik kalın bir hamur üzerine 6 7 kü...   2021-01-10    6.0   \n",
       "271842    pizza adana börek pasta nefisti teşekkür ederiz   2021-01-10   10.0   \n",
       "\n",
       "        SERVING  FLAVOUR        DATE  \n",
       "0             5        8  2021-06-10  \n",
       "1             6        4  2021-06-10  \n",
       "2             8        8  2021-06-10  \n",
       "3            10       10  2021-06-10  \n",
       "4             6        3  2021-06-10  \n",
       "...         ...      ...         ...  \n",
       "271838        5        5  2021-06-10  \n",
       "271839        1        1  2021-06-10  \n",
       "271840       10       10  2021-06-10  \n",
       "271841        4        3  2021-06-10  \n",
       "271842       10        9  2021-06-10  \n",
       "\n",
       "[271843 rows x 8 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>RESTAURANT_ID</th>\n      <th>USERNAME</th>\n      <th>COMMENT_TEXT</th>\n      <th>COMMENT_DATE</th>\n      <th>SPEED</th>\n      <th>SERVING</th>\n      <th>FLAVOUR</th>\n      <th>DATE</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>magic-akademi-kartal-esentepe-mah-istanbul</td>\n      <td>...i</td>\n      <td>i̇lk sipariş verdim restauranttan patates sıca...</td>\n      <td>2021-01-10</td>\n      <td>10.0</td>\n      <td>5</td>\n      <td>8</td>\n      <td>2021-06-10</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>magic-akademi-kartal-esentepe-mah-istanbul</td>\n      <td>...3</td>\n      <td>söyledigimde somon kötüleşiyor sefer fettucini...</td>\n      <td>2021-01-10</td>\n      <td>9.0</td>\n      <td>6</td>\n      <td>4</td>\n      <td>2021-06-10</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>magic-akademi-kartal-esentepe-mah-istanbul</td>\n      <td>...0</td>\n      <td>itu</td>\n      <td>2021-01-10</td>\n      <td>8.0</td>\n      <td>8</td>\n      <td>8</td>\n      <td>2021-06-10</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>magic-akademi-kartal-esentepe-mah-istanbul</td>\n      <td>...t</td>\n      <td>18 dkda kapıdaydi sıcak lezzetli süpersiniz</td>\n      <td>2021-01-10</td>\n      <td>10.0</td>\n      <td>10</td>\n      <td>10</td>\n      <td>2021-06-10</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>magic-akademi-kartal-esentepe-mah-istanbul</td>\n      <td>...e</td>\n      <td>dağ kekikli tavuğun yanında gelen makarna bild...</td>\n      <td>2021-01-10</td>\n      <td>10.0</td>\n      <td>6</td>\n      <td>3</td>\n      <td>2021-06-10</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>271838</th>\n      <td>magic-akademi-kartal-esentepe-mah-istanbul</td>\n      <td>...1</td>\n      <td>anladık hamburgerler kötü pizzadan devam</td>\n      <td>2021-01-10</td>\n      <td>5.0</td>\n      <td>5</td>\n      <td>5</td>\n      <td>2021-06-10</td>\n    </tr>\n    <tr>\n      <th>271839</th>\n      <td>magic-akademi-kartal-esentepe-mah-istanbul</td>\n      <td>...d</td>\n      <td>tiramisu malesef rezaletti kreması ekşimişti y...</td>\n      <td>2021-01-10</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2021-06-10</td>\n    </tr>\n    <tr>\n      <th>271840</th>\n      <td>magic-akademi-kartal-esentepe-mah-istanbul</td>\n      <td>...k</td>\n      <td>dağ kekikli tavuk inanılmaz güzel bağımlısıyım</td>\n      <td>2021-01-10</td>\n      <td>10.0</td>\n      <td>10</td>\n      <td>10</td>\n      <td>2021-06-10</td>\n    </tr>\n    <tr>\n      <th>271841</th>\n      <td>magic-akademi-kartal-esentepe-mah-istanbul</td>\n      <td>...7</td>\n      <td>waffle söyledik kalın bir hamur üzerine 6 7 kü...</td>\n      <td>2021-01-10</td>\n      <td>6.0</td>\n      <td>4</td>\n      <td>3</td>\n      <td>2021-06-10</td>\n    </tr>\n    <tr>\n      <th>271842</th>\n      <td>magic-akademi-kartal-esentepe-mah-istanbul</td>\n      <td>...l</td>\n      <td>pizza adana börek pasta nefisti teşekkür ederiz</td>\n      <td>2021-01-10</td>\n      <td>10.0</td>\n      <td>10</td>\n      <td>9</td>\n      <td>2021-06-10</td>\n    </tr>\n  </tbody>\n</table>\n<p>271843 rows × 8 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "stop_words = [element for element in stopwords.words('turkish') if element not in ['çok','eğer','gibi','hiç','niçin','niye','sanki','yani','en','az','birkaç','bazı','aslında','neden','hepsi']]\n",
    "comment_df['COMMENT_TEXT'] = comment_df['COMMENT_TEXT'].apply(lambda x: ' '.join([word for word in x.lower().split() if word not in (stop_words)]))\n",
    "#comment_df['COMMENT_TEXT'] = comment_df['COMMENT_TEXT'].apply(lambda x: ' '.join([stemmer.stem(word) for word in x.split()]))\n",
    "comment_df"
   ]
  },
  {
   "source": [
    "# Machine Learning"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Bag of Words"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Gaussian Naive Bayes"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Total Features after vectorizing: 2733\n",
      "Accuracy Score for SPEED: 31.33%\n",
      "F1 Score for SPEED: 31.33%\n",
      "Precision Score for SPEED: 31.33%\n",
      "\n",
      "Total Features after vectorizing: 4003\n",
      "Accuracy Score for SERVING: 31.00%\n",
      "F1 Score for SERVING: 31.00%\n",
      "Precision Score for SERVING: 31.00%\n",
      "\n",
      "Total Features after vectorizing: 4003\n",
      "Accuracy Score for FLAVOUR: 28.87%\n",
      "F1 Score for FLAVOUR: 28.87%\n",
      "Precision Score for FLAVOUR: 28.87%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for label in ['SPEED','SERVING','FLAVOUR']:\n",
    "    model = CountVectorizer(min_df=3)\n",
    "    not_null_df = comment_df[0:10000][pd.notnull(comment_df[label])]\n",
    "    features = model.fit_transform(not_null_df['COMMENT_TEXT'].values).todense()\n",
    "    labels = not_null_df[label].values\n",
    "    print(\"Total Features after vectorizing: {total_features}\".format(total_features = np.shape(features)[1]))\n",
    "    #print(np.shape(labels))\n",
    "\n",
    "    features_train, features_test, labels_train, labels_test = train_test_split(features, labels, test_size = 0.3, random_state = 9)\n",
    "    \n",
    "    model_file_name = \"models/BoW_CountVectorizer_GaussianNB_{label}.mdl\".format(label = label)\n",
    "    \n",
    "    if(check_if_file_exists(model_file_name)):\n",
    "        model = joblib.load(model_file_name)\n",
    "    else:\n",
    "        model = GaussianNB()\n",
    "        model.fit(features_train, labels_train)\n",
    "\n",
    "        joblib.dump(model, model_file_name)\n",
    "\n",
    "    label_prediction = model.predict(features_test)\n",
    "\n",
    "    print(\"Accuracy Score for {label}: {accuracy_score:0.2f}%\".format(accuracy_score = accuracy_score(labels_test, label_prediction)*100, label=label))\n",
    "    print(\"F1 Score for {label}: {f1_score:0.2f}%\".format(f1_score = f1_score(labels_test, label_prediction, average='micro')*100, label=label))\n",
    "    print(\"Precision Score for {label}: {precision_score:0.2f}%\\n\".format(precision_score  = precision_score(labels_test, label_prediction, average='micro')*100, label=label))"
   ]
  },
  {
   "source": [
    "### Support Vector Machines"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "#### C-Support Vector Classification"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Total Features after vectorizing: 2733\n",
      "Accuracy Score for SPEED: 64.19%\n",
      "F1 Score for SPEED: 64.19%\n",
      "Precision Score for SPEED: 64.19%\n",
      "\n",
      "Total Features after vectorizing: 4003\n",
      "Accuracy Score for SERVING: 64.73%\n",
      "F1 Score for SERVING: 64.73%\n",
      "Precision Score for SERVING: 64.73%\n",
      "\n",
      "Total Features after vectorizing: 4003\n",
      "Accuracy Score for FLAVOUR: 62.00%\n",
      "F1 Score for FLAVOUR: 62.00%\n",
      "Precision Score for FLAVOUR: 62.00%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for label in ['SPEED','SERVING','FLAVOUR']:\n",
    "    model = CountVectorizer(min_df=3)\n",
    "    not_null_df = comment_df[0:10000][pd.notnull(comment_df[label])]\n",
    "    features = model.fit_transform(not_null_df['COMMENT_TEXT'].values).todense()\n",
    "    labels = not_null_df[label].values\n",
    "    print(\"Total Features after vectorizing: {total_features}\".format(total_features = np.shape(features)[1]))\n",
    "\n",
    "    features_train, features_test, labels_train, labels_test = train_test_split(features, labels, test_size = 0.3, random_state = 9)\n",
    "\n",
    "    model_file_name = \"models/BoW_CountVectorizer_SVC_{label}.mdl\".format(label = label)\n",
    "\n",
    "    if(check_if_file_exists(model_file_name)):\n",
    "        model = joblib.load(model_file_name)\n",
    "    else:\n",
    "        model = SVC()\n",
    "        model.fit(features_train, labels_train)\n",
    "\n",
    "        joblib.dump(model, model_file_name)\n",
    "\n",
    "    label_prediction = model.predict(features_test)\n",
    "\n",
    "    print(\"Accuracy Score for {label}: {accuracy_score:0.2f}%\".format(accuracy_score = accuracy_score(labels_test, label_prediction)*100, label=label))\n",
    "    print(\"F1 Score for {label}: {f1_score:0.2f}%\".format(f1_score = f1_score(labels_test, label_prediction, average='micro')*100, label=label))\n",
    "    print(\"Precision Score for {label}: {precision_score:0.2f}%\\n\".format(precision_score  = precision_score(labels_test, label_prediction, average='micro')*100, label=label))"
   ]
  },
  {
   "source": [
    "#### Linear Support Vector Classification"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Total Features after vectorizing: 2733\n",
      "Accuracy Score for SPEED: 60.05%\n",
      "F1 Score for SPEED: 60.05%\n",
      "Precision Score for SPEED: 60.05%\n",
      "\n",
      "Total Features after vectorizing: 4003\n",
      "Accuracy Score for SERVING: 61.63%\n",
      "F1 Score for SERVING: 61.63%\n",
      "Precision Score for SERVING: 61.63%\n",
      "\n",
      "Total Features after vectorizing: 4003\n",
      "Accuracy Score for FLAVOUR: 58.20%\n",
      "F1 Score for FLAVOUR: 58.20%\n",
      "Precision Score for FLAVOUR: 58.20%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for label in ['SPEED','SERVING','FLAVOUR']:\n",
    "    model = CountVectorizer(min_df=3)\n",
    "    not_null_df = comment_df[0:10000][pd.notnull(comment_df[label])]\n",
    "    features = model.fit_transform(not_null_df['COMMENT_TEXT'].values).todense()\n",
    "    labels = not_null_df[label].values\n",
    "    print(\"Total Features after vectorizing: {total_features}\".format(total_features = np.shape(features)[1]))\n",
    "\n",
    "    features_train, features_test, labels_train, labels_test = train_test_split(features, labels, test_size = 0.3, random_state = 9)\n",
    "\n",
    "    model_file_name = \"models/BoW_CountVectorizer_LinearSVC_{label}.mdl\".format(label = label)\n",
    "    \n",
    "    if(check_if_file_exists(model_file_name)):\n",
    "        model = joblib.load(model_file_name)\n",
    "    else:\n",
    "        model = LinearSVC()\n",
    "        model.fit(features_train, labels_train)\n",
    "\n",
    "        joblib.dump(model, model_file_name)\n",
    "\n",
    "    label_prediction = model.predict(features_test)\n",
    "\n",
    "    print(\"Accuracy Score for {label}: {accuracy_score:0.2f}%\".format(accuracy_score = accuracy_score(labels_test, label_prediction)*100, label=label))\n",
    "    print(\"F1 Score for {label}: {f1_score:0.2f}%\".format(f1_score = f1_score(labels_test, label_prediction, average='micro')*100, label=label))\n",
    "    print(\"Precision Score for {label}: {precision_score:0.2f}%\\n\".format(precision_score  = precision_score(labels_test, label_prediction, average='micro')*100, label=label))"
   ]
  },
  {
   "source": [
    "### Decision Tree Classifier"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Total Features after vectorizing: 2733\n",
      "Accuracy Score for SPEED: 63.50%\n",
      "F1 Score for SPEED: 63.50%\n",
      "Precision Score for SPEED: 63.50%\n",
      "\n",
      "Total Features after vectorizing: 4003\n",
      "Accuracy Score for SERVING: 63.27%\n",
      "F1 Score for SERVING: 63.27%\n",
      "Precision Score for SERVING: 63.27%\n",
      "\n",
      "Total Features after vectorizing: 4003\n",
      "Accuracy Score for FLAVOUR: 59.33%\n",
      "F1 Score for FLAVOUR: 59.33%\n",
      "Precision Score for FLAVOUR: 59.33%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for label in ['SPEED','SERVING','FLAVOUR']:\n",
    "    model = CountVectorizer(min_df=3)\n",
    "    not_null_df = comment_df[0:10000][pd.notnull(comment_df[label])]\n",
    "    features = model.fit_transform(not_null_df['COMMENT_TEXT'].values).todense()\n",
    "    labels = not_null_df[label].values\n",
    "    print(\"Total Features after vectorizing: {total_features}\".format(total_features = np.shape(features)[1]))\n",
    "\n",
    "    features_train, features_test, labels_train, labels_test = train_test_split(features, labels, test_size = 0.3, random_state = 9)\n",
    "\n",
    "    model_file_name = \"models/BoW_CountVectorizer_DecisionTreeClassifier_{label}.mdl\".format(label = label)\n",
    "    \n",
    "    if(check_if_file_exists(model_file_name)):\n",
    "        model = joblib.load(model_file_name)\n",
    "    else:\n",
    "        params = {\n",
    "            'max_depth': [10,13,14,15],\n",
    "            'min_samples_split': [2,3,4]\n",
    "            }\n",
    "\n",
    "        gscv = GridSearchCV(DecisionTreeClassifier(), params, cv=5)\n",
    "        gscv.fit(features_train, labels_train)\n",
    "        print(\"Best parameters: {best_parameters}\".format(best_parameters = gscv.best_params_))\n",
    "\n",
    "        model = gscv.best_estimator_\n",
    "        model.fit(features_train, labels_train)\n",
    "\n",
    "        joblib.dump(model, model_file_name)\n",
    "\n",
    "    label_prediction = model.predict(features_test)\n",
    "\n",
    "    print(\"Accuracy Score for {label}: {accuracy_score:0.2f}%\".format(accuracy_score = accuracy_score(labels_test, label_prediction)*100, label=label))\n",
    "    print(\"F1 Score for {label}: {f1_score:0.2f}%\".format(f1_score = f1_score(labels_test, label_prediction, average='micro')*100, label=label))\n",
    "    print(\"Precision Score for {label}: {precision_score:0.2f}%\\n\".format(precision_score  = precision_score(labels_test, label_prediction, average='micro')*100, label=label))"
   ]
  },
  {
   "source": [
    "### Logistic Regression"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Total Features after vectorizing: 2619\n",
      "Accuracy Score for SPEED: 63.19%\n",
      "F1 Score for SPEED: 63.19%\n",
      "Precision Score for SPEED: 63.19%\n",
      "\n",
      "Total Features after vectorizing: 3913\n",
      "Accuracy Score for SERVING: 64.90%\n",
      "F1 Score for SERVING: 64.90%\n",
      "Precision Score for SERVING: 64.90%\n",
      "\n",
      "Total Features after vectorizing: 3913\n",
      "Accuracy Score for FLAVOUR: 63.12%\n",
      "F1 Score for FLAVOUR: 63.12%\n",
      "Precision Score for FLAVOUR: 63.12%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for label in ['SPEED','SERVING','FLAVOUR']:\n",
    "    model = CountVectorizer(min_df=3)\n",
    "    not_null_df = comment_df[0:9600][pd.notnull(comment_df[label])]\n",
    "    features = model.fit_transform(not_null_df['COMMENT_TEXT'].values).todense()\n",
    "    labels = not_null_df[label].values\n",
    "    print(\"Total Features after vectorizing: {total_features}\".format(total_features = np.shape(features)[1]))\n",
    "\n",
    "    features_train, features_test, labels_train, labels_test = train_test_split(features, labels, test_size = 0.3, random_state = 9)\n",
    "\n",
    "    model_file_name = \"models/BoW_CountVectorizer_LogisticRegression_{label}.mdl\".format(label = label)\n",
    "    \n",
    "    if(check_if_file_exists(model_file_name)):\n",
    "        model = joblib.load(model_file_name)\n",
    "    else:\n",
    "        model = LogisticRegression(penalty='l2', C=1.2, n_jobs=-1)\n",
    "        model.fit(features_train, labels_train)\n",
    "\n",
    "        joblib.dump(model, model_file_name)\n",
    "\n",
    "    label_prediction = model.predict(features_test)\n",
    "\n",
    "    print(\"Accuracy Score for {label}: {accuracy_score:0.2f}%\".format(accuracy_score = accuracy_score(labels_test, label_prediction)*100, label=label))\n",
    "    print(\"F1 Score for {label}: {f1_score:0.2f}%\".format(f1_score = f1_score(labels_test, label_prediction, average='micro')*100, label=label))\n",
    "    print(\"Precision Score for {label}: {precision_score:0.2f}%\\n\".format(precision_score  = precision_score(labels_test, label_prediction, average='micro')*100, label=label))"
   ]
  },
  {
   "source": [
    "## Bag of Words with TF-IDF Vectorizer"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Gaussian Naive Bayes"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Total Features after vectorizing: 2733\n",
      "Accuracy Score for SPEED: 31.43%\n",
      "F1 Score for SPEED: 31.43%\n",
      "Precision Score for SPEED: 31.43%\n",
      "\n",
      "Total Features after vectorizing: 4003\n",
      "Accuracy Score for SERVING: 31.40%\n",
      "F1 Score for SERVING: 31.40%\n",
      "Precision Score for SERVING: 31.40%\n",
      "\n",
      "Total Features after vectorizing: 4003\n",
      "Accuracy Score for FLAVOUR: 28.57%\n",
      "F1 Score for FLAVOUR: 28.57%\n",
      "Precision Score for FLAVOUR: 28.57%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for label in ['SPEED','SERVING','FLAVOUR']:\n",
    "    model = TfidfVectorizer(min_df=3)\n",
    "    not_null_df = comment_df[0:10000][pd.notnull(comment_df[label])]\n",
    "    features = model.fit_transform(not_null_df['COMMENT_TEXT'].values).todense()\n",
    "    labels = not_null_df[label].values\n",
    "    print(\"Total Features after vectorizing: {total_features}\".format(total_features = np.shape(features)[1]))\n",
    "    #print(np.shape(labels))\n",
    "\n",
    "    features_train, features_test, labels_train, labels_test = train_test_split(features, labels, test_size = 0.3, random_state = 9)\n",
    "    \n",
    "    model_file_name = \"models/BoW_TFIDFVectorizer_GaussianNB_{label}.mdl\".format(label = label)\n",
    "    \n",
    "    if(check_if_file_exists(model_file_name)):\n",
    "        model = joblib.load(model_file_name)\n",
    "    else:\n",
    "        model = GaussianNB()\n",
    "        model.fit(features_train, labels_train)\n",
    "\n",
    "        joblib.dump(model, model_file_name)\n",
    "\n",
    "    label_prediction = model.predict(features_test)\n",
    "\n",
    "    print(\"Accuracy Score for {label}: {accuracy_score:0.2f}%\".format(accuracy_score = accuracy_score(labels_test, label_prediction)*100, label=label))\n",
    "    print(\"F1 Score for {label}: {f1_score:0.2f}%\".format(f1_score = f1_score(labels_test, label_prediction, average='micro')*100, label=label))\n",
    "    print(\"Precision Score for {label}: {precision_score:0.2f}%\\n\".format(precision_score  = precision_score(labels_test, label_prediction, average='micro')*100, label=label))"
   ]
  },
  {
   "source": [
    "### Support Vector Machines"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "#### C-Support Vector Classification"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Total Features after vectorizing: 2733\n",
      "Accuracy Score for SPEED: 65.76%\n",
      "F1 Score for SPEED: 65.76%\n",
      "Precision Score for SPEED: 65.76%\n",
      "\n",
      "Total Features after vectorizing: 4003\n",
      "Accuracy Score for SERVING: 66.67%\n",
      "F1 Score for SERVING: 66.67%\n",
      "Precision Score for SERVING: 66.67%\n",
      "\n",
      "Total Features after vectorizing: 4003\n",
      "Accuracy Score for FLAVOUR: 63.53%\n",
      "F1 Score for FLAVOUR: 63.53%\n",
      "Precision Score for FLAVOUR: 63.53%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for label in ['SPEED','SERVING','FLAVOUR']:\n",
    "    model = TfidfVectorizer(min_df=3)\n",
    "    not_null_df = comment_df[0:10000][pd.notnull(comment_df[label])]\n",
    "    features = model.fit_transform(not_null_df['COMMENT_TEXT'].values).todense()\n",
    "    labels = not_null_df[label].values\n",
    "    print(\"Total Features after vectorizing: {total_features}\".format(total_features = np.shape(features)[1]))\n",
    "\n",
    "    features_train, features_test, labels_train, labels_test = train_test_split(features, labels, test_size = 0.3, random_state = 9)\n",
    "    \n",
    "    model_file_name = \"models/BoW_TFIDFVectorizer_SVC_{label}.mdl\".format(label = label)\n",
    "    \n",
    "    if(check_if_file_exists(model_file_name)):\n",
    "        model = joblib.load(model_file_name)\n",
    "    else:\n",
    "        params = {\n",
    "            'C': [1.5],\n",
    "            #'C': [1.4,1.5,1.6],\n",
    "            'kernel': ['rbf']\n",
    "            #'kernel': ['linear','rbf','sigmoid']\n",
    "            }\n",
    "\n",
    "        gscv = GridSearchCV(SVC(), params, cv=5)\n",
    "        gscv.fit(features_train, labels_train)\n",
    "        print(\"Best parameters: {best_parameters}\".format(best_parameters = gscv.best_params_))\n",
    "\n",
    "        model = gscv.best_estimator_\n",
    "        model.fit(features_train, labels_train)\n",
    "\n",
    "        joblib.dump(model, model_file_name)\n",
    "\n",
    "    label_prediction = model.predict(features_test)\n",
    "\n",
    "    print(\"Accuracy Score for {label}: {accuracy_score:0.2f}%\".format(accuracy_score = accuracy_score(labels_test, label_prediction)*100, label=label))\n",
    "    print(\"F1 Score for {label}: {f1_score:0.2f}%\".format(f1_score = f1_score(labels_test, label_prediction, average='micro')*100, label=label))\n",
    "    print(\"Precision Score for {label}: {precision_score:0.2f}%\\n\".format(precision_score  = precision_score(labels_test, label_prediction, average='micro')*100, label=label))"
   ]
  },
  {
   "source": [
    "#### Linear Support Vector Classification"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Total Features after vectorizing: 2733\n",
      "Accuracy Score for SPEED: 63.05%\n",
      "F1 Score for SPEED: 63.05%\n",
      "Precision Score for SPEED: 63.05%\n",
      "\n",
      "Total Features after vectorizing: 4003\n",
      "Accuracy Score for SERVING: 65.10%\n",
      "F1 Score for SERVING: 65.10%\n",
      "Precision Score for SERVING: 65.10%\n",
      "\n",
      "Total Features after vectorizing: 4003\n",
      "Accuracy Score for FLAVOUR: 61.67%\n",
      "F1 Score for FLAVOUR: 61.67%\n",
      "Precision Score for FLAVOUR: 61.67%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for label in ['SPEED','SERVING','FLAVOUR']:\n",
    "    model = TfidfVectorizer(min_df=3)\n",
    "    not_null_df = comment_df[0:10000][pd.notnull(comment_df[label])]\n",
    "    features = model.fit_transform(not_null_df['COMMENT_TEXT'].values).todense()\n",
    "    labels = not_null_df[label].values\n",
    "    print(\"Total Features after vectorizing: {total_features}\".format(total_features = np.shape(features)[1]))\n",
    "\n",
    "    features_train, features_test, labels_train, labels_test = train_test_split(features, labels, test_size = 0.3, random_state = 9)\n",
    "    \n",
    "    model_file_name = \"models/BoW_TFIDFVectorizer_LinearSVC_{label}.mdl\".format(label = label)\n",
    "    \n",
    "    if(check_if_file_exists(model_file_name)):\n",
    "        model = joblib.load(model_file_name)\n",
    "    else:\n",
    "        model = LinearSVC()\n",
    "        model.fit(features_train, labels_train)\n",
    "\n",
    "        joblib.dump(model, model_file_name)\n",
    "\n",
    "    label_prediction = model.predict(features_test)\n",
    "\n",
    "    print(\"Accuracy Score for {label}: {accuracy_score:0.2f}%\".format(accuracy_score = accuracy_score(labels_test, label_prediction)*100, label=label))\n",
    "    print(\"F1 Score for {label}: {f1_score:0.2f}%\".format(f1_score = f1_score(labels_test, label_prediction, average='micro')*100, label=label))\n",
    "    print(\"Precision Score for {label}: {precision_score:0.2f}%\\n\".format(precision_score  = precision_score(labels_test, label_prediction, average='micro')*100, label=label))"
   ]
  },
  {
   "source": [
    "### Decision Tree Classifier"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Total Features after vectorizing: 2619\n",
      "Accuracy Score for SPEED: 62.93%\n",
      "F1 Score for SPEED: 62.93%\n",
      "Precision Score for SPEED: 62.93%\n",
      "\n",
      "Total Features after vectorizing: 3913\n",
      "Accuracy Score for SERVING: 61.98%\n",
      "F1 Score for SERVING: 61.98%\n",
      "Precision Score for SERVING: 61.98%\n",
      "\n",
      "Total Features after vectorizing: 3913\n",
      "Accuracy Score for FLAVOUR: 60.03%\n",
      "F1 Score for FLAVOUR: 60.03%\n",
      "Precision Score for FLAVOUR: 60.03%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for label in ['SPEED','SERVING','FLAVOUR']:\n",
    "    model = TfidfVectorizer(min_df=3)\n",
    "    not_null_df = comment_df[0:9600][pd.notnull(comment_df[label])]\n",
    "    features = model.fit_transform(not_null_df['COMMENT_TEXT'].values).todense()\n",
    "    labels = not_null_df[label].values\n",
    "    print(\"Total Features after vectorizing: {total_features}\".format(total_features = np.shape(features)[1]))\n",
    "\n",
    "    features_train, features_test, labels_train, labels_test = train_test_split(features, labels, test_size = 0.3, random_state = 9)\n",
    "    \n",
    "    model_file_name = \"models/BoW_TFIDFVectorizer_DecisionTreeClassifier_{label}.mdl\".format(label = label)\n",
    "    \n",
    "    if(check_if_file_exists(model_file_name)):\n",
    "        model = joblib.load(model_file_name)\n",
    "    else:\n",
    "        params = {\n",
    "            'max_depth': [9,10,11],\n",
    "            'min_samples_split': [2,3]\n",
    "            }\n",
    "\n",
    "        gscv = GridSearchCV(DecisionTreeClassifier(), params, cv=5)\n",
    "        gscv.fit(features_train, labels_train)\n",
    "        print(\"Best parameters: {best_parameters}\".format(best_parameters = gscv.best_params_))\n",
    "\n",
    "        model = gscv.best_estimator_\n",
    "        model.fit(features_train, labels_train)\n",
    "\n",
    "        joblib.dump(model, model_file_name)\n",
    "\n",
    "    label_prediction = model.predict(features_test)\n",
    "\n",
    "    print(\"Accuracy Score for {label}: {accuracy_score:0.2f}%\".format(accuracy_score = accuracy_score(labels_test, label_prediction)*100, label=label))\n",
    "    print(\"F1 Score for {label}: {f1_score:0.2f}%\".format(f1_score = f1_score(labels_test, label_prediction, average='micro')*100, label=label))\n",
    "    print(\"Precision Score for {label}: {precision_score:0.2f}%\\n\".format(precision_score  = precision_score(labels_test, label_prediction, average='micro')*100, label=label))"
   ]
  },
  {
   "source": [
    "### Logistic Regression"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Total Features after vectorizing: 2619\n",
      "Accuracy Score for SPEED: 65.71%\n",
      "F1 Score for SPEED: 65.71%\n",
      "Precision Score for SPEED: 65.71%\n",
      "\n",
      "Total Features after vectorizing: 3913\n",
      "Accuracy Score for SERVING: 65.73%\n",
      "F1 Score for SERVING: 65.73%\n",
      "Precision Score for SERVING: 65.73%\n",
      "\n",
      "Total Features after vectorizing: 3913\n",
      "Accuracy Score for FLAVOUR: 63.96%\n",
      "F1 Score for FLAVOUR: 63.96%\n",
      "Precision Score for FLAVOUR: 63.96%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for label in ['SPEED','SERVING','FLAVOUR']:\n",
    "    model = TfidfVectorizer(min_df=3)\n",
    "    not_null_df = comment_df[0:9600][pd.notnull(comment_df[label])]\n",
    "    features = model.fit_transform(not_null_df['COMMENT_TEXT'].values).todense()\n",
    "    labels = not_null_df[label].values\n",
    "    print(\"Total Features after vectorizing: {total_features}\".format(total_features = np.shape(features)[1]))\n",
    "\n",
    "    features_train, features_test, labels_train, labels_test = train_test_split(features, labels, test_size = 0.3, random_state = 9)\n",
    "    \n",
    "    model_file_name = \"models/BoW_TFIDFVectorizer_LogisticRegression_{label}.mdl\".format(label = label)\n",
    "    \n",
    "    if(check_if_file_exists(model_file_name)):\n",
    "        model = joblib.load(model_file_name)\n",
    "    else:\n",
    "        model = LogisticRegression(penalty='l2', C=1.2, n_jobs=-1)\n",
    "        model.fit(features_train, labels_train)\n",
    "\n",
    "        joblib.dump(model, model_file_name)\n",
    "\n",
    "    label_prediction = model.predict(features_test)\n",
    "\n",
    "    print(\"Accuracy Score for {label}: {accuracy_score:0.2f}%\".format(accuracy_score = accuracy_score(labels_test, label_prediction)*100, label=label))\n",
    "    print(\"F1 Score for {label}: {f1_score:0.2f}%\".format(f1_score = f1_score(labels_test, label_prediction, average='micro')*100, label=label))\n",
    "    print(\"Precision Score for {label}: {precision_score:0.2f}%\\n\".format(precision_score  = precision_score(labels_test, label_prediction, average='micro')*100, label=label))"
   ]
  },
  {
   "source": [
    "## Markov Chains"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                   RESTAURANT_ID  \\\n",
       "0    pizza-bulls-uskudar-altunizade-mah-istanbul   \n",
       "1         pizza-bulls-uskudar-ferah-mah-istanbul   \n",
       "2  pizza-bulls-kartal-soganlik-yeni-mah-istanbul   \n",
       "3       pizza-bulls-umraniye-cakmak-mah-istanbul   \n",
       "4        pizza-bulls-atasehir-fetih-mah-istanbul   \n",
       "\n",
       "                                         all_comment  comment_count  \n",
       "0  lezzeti eskisi gibi gelmedi bize. fark ödeyip ...           2293  \n",
       "1  her şey çok güzeldi. elinize sağlık. hizli ve ...           1764  \n",
       "2  cok pahali olmasi disinda bir problem yok gibi...           1743  \n",
       "3  çok lezzetli güvenle çoçuguma yedirebiliyorum ...           1582  \n",
       "4  servis ve hız 10 üzerinden 20.. bu siparişi is...           1277  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>RESTAURANT_ID</th>\n      <th>all_comment</th>\n      <th>comment_count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>pizza-bulls-uskudar-altunizade-mah-istanbul</td>\n      <td>lezzeti eskisi gibi gelmedi bize. fark ödeyip ...</td>\n      <td>2293</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>pizza-bulls-uskudar-ferah-mah-istanbul</td>\n      <td>her şey çok güzeldi. elinize sağlık. hizli ve ...</td>\n      <td>1764</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>pizza-bulls-kartal-soganlik-yeni-mah-istanbul</td>\n      <td>cok pahali olmasi disinda bir problem yok gibi...</td>\n      <td>1743</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>pizza-bulls-umraniye-cakmak-mah-istanbul</td>\n      <td>çok lezzetli güvenle çoçuguma yedirebiliyorum ...</td>\n      <td>1582</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>pizza-bulls-atasehir-fetih-mah-istanbul</td>\n      <td>servis ve hız 10 üzerinden 20.. bu siparişi is...</td>\n      <td>1277</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    "sql_command = \"\"\"\n",
    "    WITH COMMENTS AS(\n",
    "    SELECT \"RESTAURANT_ID\",\n",
    "    STRING_AGG(LOWER(\"COMMENT_TEXT\"), ' ') AS ALL_COMMENT,\n",
    "    COUNT(\"COMMENT_TEXT\") AS COMMENT_COUNT\n",
    "    FROM \"ODS\".\"EXT_FB_COMMENT\" EFC\n",
    "    GROUP BY \"RESTAURANT_ID\"\n",
    "    )\n",
    "    SELECT * \n",
    "    FROM COMMENTS\n",
    "    ORDER BY COMMENT_COUNT DESC;\n",
    "    \"\"\"\n",
    "restaurant_df = pd.read_sql(sql_command,conn)\n",
    "restaurant_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def make_markov_model(cleaned_stories, n_gram=2):\n",
    "    markov_model = {}\n",
    "    for i in range(len(cleaned_stories)-n_gram-1):\n",
    "        curr_state, next_state = \"\", \"\"\n",
    "        for j in range(n_gram):\n",
    "            curr_state += cleaned_stories[i+j] + \" \"\n",
    "            next_state += cleaned_stories[i+j+n_gram] + \" \"\n",
    "        curr_state = curr_state[:-1]\n",
    "        next_state = next_state[:-1]\n",
    "        if curr_state not in markov_model:\n",
    "            markov_model[curr_state] = {}\n",
    "            markov_model[curr_state][next_state] = 1\n",
    "        else:\n",
    "            if next_state in markov_model[curr_state]:\n",
    "                markov_model[curr_state][next_state] += 1\n",
    "            else:\n",
    "                markov_model[curr_state][next_state] = 1\n",
    "    \n",
    "    # calculating transition probabilities\n",
    "    for curr_state, transition in markov_model.items():\n",
    "        total = sum(transition.values())\n",
    "        for state, count in transition.items():\n",
    "            markov_model[curr_state][state] = count/total\n",
    "        \n",
    "    return markov_model\n",
    "\n",
    "def generate_story(markov_model, limit=100, start='my god'):\n",
    "    n = 0\n",
    "    curr_state = start\n",
    "    next_state = None\n",
    "    story = \"\"\n",
    "    story+=curr_state+\" \"\n",
    "    while n<limit:\n",
    "        next_state = random.choices(list(markov_model[curr_state].keys()),\n",
    "                                    list(markov_model[curr_state].values()))\n",
    "        \n",
    "        curr_state = next_state[0]\n",
    "        story+=curr_state+\" \"\n",
    "        n+=1\n",
    "    return story"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.  yemek çok güzeldi semih beye ilgisinden dolayı tesekkurler atakan kardeşim sağolsun çok ilgili atakan beye ikramları için teşekkürler tatlı için ayrıca teşekkürler gayet lezzetli ve hızlıydı başarıların devamını diliyorum herzaman hızlı ve harika bir sunum teşekkürler başarılınızın devamını dilerim semih beye selam \n1.  yemek çok güzeldi semih beye ilgisinden dolayı teşekkür ederiz her puanın karşılığını hakediyorlar her zamanki gibi harikaydı kurye arkadaşa da süperdi başka söz bulamadım sürekli sipariş verdiğim yer her zaman ki çok sıcak olduğu için çok teşekkür ediyorum siparişi getiren ali beyin \n2.  yemek çok lezzetliydi ve yanında 2 adet ikram sufle geldi pizza sıcaktı beğendim tam puan veriyorum atakan beye ikramdan dolayı teşekkürlerimi dile getirmek isterim kurye beye ve de pizzanın ulaşması için arayan çalışanınıza çok teşekkür ederim her şey çok lezzetli ve hızlıydı \n3.  yemek çok güzeldi semih beye ilgisinden ve ikramından dolayı özellikle çok teşekkür ederim bir numaralı bulls şubesi bilal bey siparisi verdikten hemen sonra iletisime gecerek siparis durumu ile ilgili bilgi verdi ayrica ikram olarak semih bey ve teslim eden ali beye çok \n4.  yemek çok lezzetliydi ve restoran bana çok yakın olmamasına rağmen sıcaktı da soğan halkaları da ayrıca teşekkürler zincir pizzacılar arasında üsküdarda fark yaratan hız ve lezzet iyi idi fakat 50 dk nın üzerinde gelince patates kızartması çalışan getiren emeği geçen herkese teşekkür \n5.  yemek çok güzeldi semih beye ilgisinden ve tatli ikramindan dolayi cok tesekkur ederim bayram günü geç saatlere kadar servis yapan iyi birine benziyor sıcak geldi güzeldi sipariş detayı karışmış peynirli kenar yanlış pizaya yapılmış yoğunluktan biraz geç gelse de sipariş verdiğim pizza \n6.  yemek çok lezzetliydi ve hızlıydı tesekkurler çok hızlı geldi ayrıca gönderdiğiniz sufleler için ayrıca teşekkür ediyoruz pizza kalitesinden ve servisinden dolayı ali beye teşekkürler ikram tatlı için teşekkür ederiz mustafa beyede teşekkür ederim pizza siparişi için bence uzun bir süreydi suffle tamamen \n7.  yemek çok lezzetliydi ve kuriyeniz atakan bey çok nazik teşekkürler hız lezzet mükemmel kurye arkadaşlara da çok teşekkürler çok ilgiliydi ve tatlı ikramında bulundu pizzalar da gayet lezzetliydi ve hızlı getirdi kurye çok güler yüzlü çok iyi biriydi hız da çok iyiydi \n8.  yemek çok güzeldi semih bey harikasınız maşallah size bize her zaman siz getirin ve sufle getirin mükemmel hizmet gayet hızlı geldi lezzet servis ve lezzet iyi idi fakat 50 dk nın üzerinde gelince patates kızartması ve pizza biraz soğumuştu sıcacık ve hızlı \n9.  yemek çok güzeldi semih beyin özel ilgisi için çok teşekkür ederim her şey harikaydı i̇lgililer her şey çok güzeldi sufle ayrı bir lezzet vermektedir son iki siparişimizde neden olduğunu bilmediğimiz sekilde midemize dokunuyor sufle için teşekkürler atakan beye tatlı ikramı ve ilgisinden \n10.  yemek çok güzeldi semih beye teşekkürler sufleler için çok teşekkürler çok beğendik çok güzel değildi 1 saatte eksik sosla geldi pizza sıcak gelsede ödeme yapmakla geçen 15 dakikada soğumuş oluyor lezzet harika servis çok iyiydi kısa sürede sipariş elimize ulaştı ve gayet \n11.  yemek çok lezzetliydi ve hızlı ulaştı servisi yapan arkadaş ali beye çok teşekkür ederim atakan beye teşekkürler promosyon tatlı istemiyorum beğenmedim beklediğimden çok daha iyiydi bilal bey cok kibardi bilal beye çok teşekkür ederim atakan beye ozellikle tesekkurler her seyiyle on numara \n12.  yemek çok güzeldi semih bey harikasınız sıcak geldi sadece elma dilim patatesler hamur gibiydi onun dışında her şey çok güzeldi semih beyin ilgisine de teşekkürler los angelos pizzalar harika özellikle atakana çok teşekkür ederiz servis ve lezzetli yemekler daha ne olsun yeri \n13.  yemek çok güzeldi semih beyin özel ilgisi için teşekkür ederiz siparişim hızlı ve sıcacık geldi sipariş vermekten hiçbir zaman pişman olmadım 22 dakika sıcak ve lezzetli ve müşteri memnuniyetini önemseyen personeli ile güzel bir yemekti emekleriniz için çok teşekkürler muhteşem bir pazar \n14.  yemek çok güzeldi semih beye teşekkürler her zamanki gibi müthiş beğenerek söylüyoruz roket burger ailesi bilal bey çok kibardı teşekkür ederiz bilal beyin iletisimi cok iyiyiydi ve her şey sıcak geldi çok teşekkür ederim atakan bey kurye 2 tane multinetten çektiği için \n15.  yemek çok lezzetliydi ve yanında 2 adet ikram sufle geldi pizza sıcaktı beğendim tam puan veriyorum bu kez i̇ki katlı çedar hamur istemiştik fakat çedarı çok az geldi kurye çok nazikti yemeğim sıcak ve çok lezzetliydi ayrıca tatlı ikramı için teşekkür ederiz \n16.  yemek çok güzeldi semih bey harikasınız sıcak geldi çok lezzetliydi sufle ikraminiz icin tesekkur ederiz pizzalarınız harika ve ilgili bir restoran i̇kram icin de coook tesekkurler burak beyin hızlı servisi ile süperdi caner beye güler yüzlülüğü için teşekkürler ama pizzalar çok sıcaktı \n17.  yemek çok lezzetliydi ve hızlıydı tesekkurler çok hızlı dumanı üstünde geliyor ama peynir kenarlı seçim yapmıştım fakat normal hamur çok kalındı ve ekmek yediğimi hissettim bir an i̇yi değildi jokerle sipariş vermemize rağmen her şey çok güzeldi tatlı için teşkkrederiz pizzalar sıcak \n18.  yemek çok lezzetliydi ve restoran bana çok yakın olmamasına rağmen sıcaktı da soğan halkaları için de teşekkür ederim pizza lezizdi her zamanki gibi tatlı için de teşekkür ederim her zaman olduğu gibi lezzetliydi semih beye nezaketi için teşekkür ederim sucukta olabilirdi icinde \n19.  yemek çok güzeldi semih beye çok teşekkürler ellerinize sağlık favori pizzacımız hiçbir olumsuzlukla karşılaşmadık senelerdir zaman zaman siparişimizle gelen hediye suffle için çok teşekkür ederiz sanitasyon koşullarına biraz daha dikkat edilmesi lazım bence bir de zeytin çekirdeği çıktı hazır alınıyor sonuçta tedarikçinin \n"
     ]
    }
   ],
   "source": [
    "restaurant_df['clean_comment'] = restaurant_df['all_comment'].apply(clean_text)\n",
    "text = restaurant_df.loc[0]['clean_comment'].split()\n",
    "\n",
    "markov_model = make_markov_model(text)\n",
    "\n",
    "for i in range(20):\n",
    "    print(str(i)+\". \", generate_story(markov_model, start=\"yemek çok\", limit=20))"
   ]
  },
  {
   "source": [
    "# Sources\n",
    "\n",
    " 1. [Selenium Documentation](https://selenium-python.readthedocs.io/)\n",
    " 2. [Selenium choose element by partial id](https://stackoverflow.com/questions/15845563/choose-element-by-partial-id-using-selenium-with-python)\n",
    " 3. [Selenium scroll down to end of the page](https://pythonbasics.org/selenium-scroll-down/)\n",
    " 4. [Selenium click button](https://stackoverflow.com/questions/52405456/selenium-how-to-click-on-javascript-button/52405550)\n",
    " 5. [Markov Chains](https://www.kaggle.com/orion99/markov-chain-nlp)\n",
    " 6. [Bag of Words](https://github.com/Suji04/NormalizedNerd/blob/master/Introduction%20to%20NLP/Bag%20of%20Words%20%2B%20TF-IDF.ipynb)\n",
    " 7. [Turkish Porter Stemmer](https://github.com/otuncelli/turkish-stemmer-python)\n",
    " 8. [Scikit-Learn: Save & Restore Models](https://stackabuse.com/scikit-learn-save-and-restore-models)\n",
    " 9. [Joblib vs Pickle](https://stackoverflow.com/questions/12615525/what-are-the-different-use-cases-of-joblib-versus-pickle)\n",
    " 10. [Hide warnings in Python](https://stackoverflow.com/questions/9031783/hide-all-warnings-in-ipython)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}