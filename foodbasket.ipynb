{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.0 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "0e8f02916ce4ec57490847cc8c54c12a9dae65680be9326a3269d9b7a61d6d19"
   }
  },
  "interpreter": {
   "hash": "0e8f02916ce4ec57490847cc8c54c12a9dae65680be9326a3269d9b7a61d6d19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Web Scraping"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv(\"dev.env\")\n",
    "import os\n",
    "\n",
    "db_name = os.getenv(\"db_name\")\n",
    "db_username = os.getenv(\"db_username\")\n",
    "db_password = os.getenv(\"db_password\")\n",
    "db_host = os.getenv(\"db_host\")\n",
    "db_port = os.getenv(\"db_port\")\n",
    "website = os.getenv(\"website\")\n",
    "city_link = os.getenv(\"city_link\")\n",
    "chrome_path = os.getenv(\"chrome_path\")\n",
    "selenium_chrome_driver_path = os.getenv(\"selenium_chrome_driver_path\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import time\n",
    "import math\n",
    "import numpy as np\n",
    "import os.path\n",
    "import pandas as pd\n",
    "import re\n",
    "import pycld2\n",
    "import nltk\n",
    "from datetime import date, timedelta, datetime\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By \n",
    "from selenium.webdriver.support.ui import WebDriverWait \n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from nltk.corpus import stopwords\n",
    "from TurkishStemmer import TurkishStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "nltk.download('stopwords', quiet=True)\n",
    "\n",
    "stemmer = TurkishStemmer()\n",
    "\n",
    "conn_string = 'host={pghost} port={pgport} dbname={pgdatabase} user={pguser} password={pgpassword}'.format(pgdatabase=db_name,pguser=db_username,pgpassword=db_password,pghost=db_host,pgport=db_port)\n",
    "conn=psycopg2.connect(conn_string)\n",
    "cur=conn.cursor()\n",
    "\n",
    "options = Options()\n",
    "options.binary_location = chrome_path\n",
    "\n",
    "def check_if_table_exists(schema,table):\n",
    "    cur.execute(\"select exists(select * from information_schema.tables where table_schema='{schema}' AND table_name='{table}')\".format(schema=schema, table=table))\n",
    "    return cur.fetchone()[0]\n",
    "\n",
    "def check_if_index_exists(index):\n",
    "    cur.execute(\"SELECT EXISTS(SELECT * FROM PG_CLASS WHERE relname = '{index}')\".format(index=index))\n",
    "    return cur.fetchone()[0]\n",
    "\n",
    "def check_if_file_exists(filename):\n",
    "    return os.path.isfile(filename)\n",
    "\n",
    "def execute_mogrify(conn, df, schema, table):\n",
    "    tuples = [tuple(x) for x in df.to_numpy()]\n",
    "    cols = '\"'+'\",\"'.join(list(df.columns))+'\"'\n",
    "    cursor = conn.cursor()    \n",
    "    try:\n",
    "        for tup in tuples:\n",
    "            query  = \"\"\"INSERT INTO \"{schema}\".\"{table}\"({cols}) VALUES ({values}) ON CONFLICT DO NOTHING\"\"\".format(schema=schema,table=table, cols=cols, values=\",\".join(map(str,tup)))\n",
    "            cursor.execute(query)\n",
    "            conn.commit()\n",
    "    except (Exception, psycopg2.DatabaseError) as error:\n",
    "        print(\"Error: %s\" % error)\n",
    "        conn.rollback()\n",
    "        cursor.close()\n",
    "        return 1\n",
    "    cursor.close()\n",
    "\n",
    "def df_column_conversation(df, column_name, type):\n",
    "    if(type == 'timestamp'):\n",
    "        df[column_name] = df[column_name].apply(lambda x: f\"'{x}'::timestamp\")\n",
    "    if(type == 'text'):\n",
    "        df[column_name] = df[column_name].str.replace(\"'\",\"\").apply(lambda x: f\"'{x}'\")\n",
    "    if(type == 'date'):\n",
    "        df[column_name] = df[column_name].apply(lambda x: f\"'{x}'::date\")\n",
    "    if(type == 'numeric'):\n",
    "        df[column_name] = df[column_name].apply(str).str.replace(',','.')\n",
    "    if(type == 'integer'):\n",
    "        df[column_name] = df[column_name].apply(str).str.replace(',','.').apply(float).astype('Int64').apply(str)\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"[,.\\\"\\'!@#$%^&*(){}?/;`~:<>+=-\\\\]\", \"\", text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Table ODS.EXT_FB_RESTAURANT already exists.\nTable ODS.EXT_FB_MENU already exists.\nTable ODS.EXT_FB_COMMENT already exists.\nTable EDW.DWH_FB_COMMENT already exists.\n"
     ]
    }
   ],
   "source": [
    "if(check_if_table_exists('ODS','EXT_FB_RESTAURANT')):\n",
    "    print('Table ODS.EXT_FB_RESTAURANT already exists.')   \n",
    "else:\n",
    "    start_time = math.trunc(time.time())\n",
    "    cur.execute(\"\"\"\n",
    "    CREATE TABLE \"ODS\".\"EXT_FB_RESTAURANT\"\n",
    "    (\n",
    "    \"RESTAURANT_ID\" text NOT NULL,\n",
    "    \"RESTAURANT_NAME\" text,\n",
    "    \"RESTAURANT_LINK\" text,\n",
    "    \"DATE\" date,    \n",
    "    CONSTRAINT \"RESTAURANT_ID\" UNIQUE (\"RESTAURANT_ID\")\n",
    "    );\n",
    "    \"\"\")\n",
    "    cur.execute('COMMIT;')\n",
    "    end_time = math.trunc(time.time())\n",
    "    print(\"Table ODS.EXT_FB_RESTAURANT created in {execute_time} seconds.\".format(execute_time=end_time-start_time))\n",
    "\n",
    "if(check_if_table_exists('ODS','EXT_FB_MENU')):\n",
    "    print('Table ODS.EXT_FB_MENU already exists.')   \n",
    "else:\n",
    "    start_time = math.trunc(time.time())\n",
    "    cur.execute(\"\"\"\n",
    "    CREATE TABLE \"ODS\".\"EXT_FB_MENU\"\n",
    "    (\n",
    "    \"PRODUCT_ID\" text NOT NULL,\n",
    "    \"RESTAURANT_ID\" text,\n",
    "    \"CATEGORY_NAME\" text,\n",
    "    \"PRODUCT_NAME\" text,\n",
    "    \"PRODUCT_DESCRIPTION\" text,\n",
    "    \"PRODUCT_LISTED_PRICE\" text,\n",
    "    \"PRODUCT_PRICE\" text,\n",
    "    \"DISCOUNT\" boolean,\n",
    "    \"DESIGN_TYPE\" text,\n",
    "    \"DATE\" date,\n",
    "    CONSTRAINT \"PRODUCT_ID\" UNIQUE (\"PRODUCT_ID\")\n",
    "    );\n",
    "    \"\"\")\n",
    "    cur.execute('COMMIT;')\n",
    "    end_time = math.trunc(time.time())\n",
    "    print(\"Table ODS.EXT_FB_MENU created in {execute_time} seconds.\".format(execute_time=end_time-start_time))\n",
    "\n",
    "if(check_if_table_exists('ODS','EXT_FB_COMMENT')):\n",
    "    print('Table ODS.EXT_FB_COMMENT already exists.')   \n",
    "else:\n",
    "    start_time = math.trunc(time.time())\n",
    "    cur.execute(\"\"\"\n",
    "    CREATE TABLE \"ODS\".\"EXT_FB_COMMENT\"\n",
    "    (\n",
    "    \"RESTAURANT_ID\" text,\n",
    "    \"USERNAME\" text,\n",
    "    \"COMMENT_TEXT\" text,\n",
    "    \"COMMENT_DATE\" text,\n",
    "    \"SPEED\" text,\n",
    "    \"SERVING\" text,\n",
    "    \"FLAVOUR\" text,\n",
    "    \"DATE\" date,\n",
    "    CONSTRAINT \"UNIQUE_COMMENTS\" UNIQUE (\"RESTAURANT_ID\", \"USERNAME\", \"COMMENT_TEXT\")\n",
    "    );\n",
    "    \"\"\")\n",
    "    cur.execute('COMMIT;')\n",
    "    end_time = math.trunc(time.time())\n",
    "    print(\"Table ODS.EXT_FB_COMMENT created in {execute_time} seconds.\".format(execute_time=end_time-start_time))\n",
    "\n",
    "if(check_if_table_exists('EDW','DWH_FB_COMMENT')):\n",
    "    print('Table EDW.DWH_FB_COMMENT already exists.')   \n",
    "else:\n",
    "    start_time = math.trunc(time.time())\n",
    "    cur.execute(\"\"\"\n",
    "    CREATE TABLE \"EDW\".\"DWH_FB_COMMENT\"\n",
    "    (\n",
    "    \"RESTAURANT_ID\" text,\n",
    "    \"USERNAME\" text,\n",
    "    \"COMMENT_TEXT\" text,\n",
    "    \"COMMENT_DATE\" date,\n",
    "    \"SPEED\" integer,\n",
    "    \"SERVING\" integer,\n",
    "    \"FLAVOUR\" integer,\n",
    "    \"DATE\" date,\n",
    "    CONSTRAINT \"UNIQUE_COMMENTS\" UNIQUE (\"RESTAURANT_ID\", \"USERNAME\", \"COMMENT_TEXT\")\n",
    "    );\n",
    "    \"\"\")\n",
    "    cur.execute('COMMIT;')\n",
    "    end_time = math.trunc(time.time())\n",
    "    print(\"Table EDW.DWH_FB_COMMENT created in {execute_time} seconds.\".format(execute_time=end_time-start_time))\n",
    "\n",
    "cur.execute(\"\"\"\n",
    "CREATE OR REPLACE FUNCTION public.try_cast(_in text, INOUT _out anyelement)\n",
    "    LANGUAGE 'plpgsql'\n",
    "AS $BODY$\n",
    "BEGIN\n",
    "   EXECUTE format('SELECT %L::%s', $1, pg_typeof(_out))\n",
    "   INTO  _out;\n",
    "EXCEPTION WHEN others THEN\n",
    "   -- do nothing: _out already carries default\n",
    "END\n",
    "$BODY$;\n",
    "\"\"\")\n",
    "cur.execute('COMMIT;')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "datetime.date(2021, 6, 11)"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "cur.execute(\"\"\"\n",
    "WITH DATES AS(\n",
    "SELECT \n",
    "MAX(\"DATE\") AS \"DATE\"\n",
    "FROM \"ODS\".\"EXT_FB_MENU\" EFM\n",
    "UNION ALL\n",
    "SELECT \n",
    "MAX(\"DATE\") AS \"DATE\"\n",
    "FROM \"ODS\".\"EXT_FB_COMMENT\" EFC\n",
    ")\n",
    "SELECT \n",
    "MAX(\"DATE\") AS \"LAST_EXECUTION_DATE\"\n",
    "FROM DATES;\n",
    "\"\"\")\n",
    "last_execution_date = cur.fetchone()[0]\n",
    "last_execution_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "restaurant_list = []\n",
    "end_date = min(date(2021,6,11),(date.today() - timedelta(days=1)))\n",
    "\n",
    "driver = webdriver.Chrome(options=options, executable_path=selenium_chrome_driver_path)\n",
    "if(last_execution_date < end_date):\n",
    "    driver.get(city_link)\n",
    "    time.sleep(5)\n",
    "    for i in range(25):\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(2)\n",
    "    city_restaurant_groups = driver.find_elements_by_class_name(\"restaurant-main-info\")\n",
    "    for restaurant in city_restaurant_groups:\n",
    "        restaurant_name = restaurant.find_element_by_class_name(\"restaurant-display-name\").text\n",
    "        restaurant_name = restaurant_name.replace(\"YENİ \", \"\")\n",
    "        restaurant_link = restaurant.find_element_by_class_name(\"restaurant-display-name\").find_element_by_xpath(\".//a\").get_attribute('href')\n",
    "        restaurant_id = restaurant_link.split(\"/\")[-1]\n",
    "        if(len(restaurant_link) < 2):\n",
    "            continue\n",
    "        restaurant_list.append([restaurant_id,restaurant_name,restaurant_link])\n",
    "    restaurant_df = pd.DataFrame(restaurant_list, columns=[\"RESTAURANT_ID\",\"RESTAURANT_NAME\",\"RESTAURANT_LINK\"])\n",
    "\n",
    "    df_column_conversation(restaurant_df, 'RESTAURANT_ID', 'text')\n",
    "    df_column_conversation(restaurant_df, 'RESTAURANT_NAME', 'text')\n",
    "    df_column_conversation(restaurant_df, 'RESTAURANT_LINK', 'text')    \n",
    "    restaurant_df['DATE'] = \"'\"+ datetime.strftime(date.today(), \"%Y-%m-%d\") + \"'::date\"\n",
    "    execute_mogrify(conn,restaurant_df,\"ODS\",\"EXT_FB_RESTAURANT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_command = \"\"\"\n",
    "    SELECT\n",
    "    \"RESTAURANT_ID\"\n",
    "    FROM \"ODS\".\"EXT_FB_RESTAURANT\" EFR\n",
    "    WHERE 1=1\n",
    "    AND NOT EXISTS(SELECT NULL FROM \"ODS\".\"EXT_FB_MENU\" EFM WHERE EFR.\"RESTAURANT_ID\" = EFM.\"RESTAURANT_ID\");\n",
    "    \"\"\"\n",
    "restaurant_df = pd.read_sql(sql_command,conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(last_execution_date < end_date):\n",
    "    for i in range(len(restaurant_df)):\n",
    "        sublink = restaurant_df.loc[i,\"RESTAURANT_ID\"]\n",
    "        restaurant_link = \"{website}/{sublink}\".format(website=website,sublink=sublink)\n",
    "        \n",
    "        driver.get(restaurant_link)\n",
    "        time.sleep(5)\n",
    "\n",
    "        try:\n",
    "            if(\"sipariş verebilirsiniz.\" in driver.find_element_by_xpath('//*[@id=\"restaurantDetail\"]/div/div[2]/h3').text):\n",
    "                continue\n",
    "            else:\n",
    "                pass\n",
    "        except Exception:\n",
    "            pass\n",
    "        \n",
    "        menu = driver.find_element_by_xpath('//*[@id=\"restaurant_menu\"]')\n",
    "        categories = menu.find_elements_by_xpath('//*[contains(@id,\"menu_\")]')\n",
    "\n",
    "        menu_list = []\n",
    "\n",
    "        for category in categories:\n",
    "            category_name = category.find_element_by_xpath(\".//b\").text\n",
    "            for product in category.find_elements_by_xpath(\".//div[2]/ul/li\"):\n",
    "                try:\n",
    "                    design_type = \"list\"\n",
    "                    try:\n",
    "                        product_id = product.find_elements_by_class_name(\"getProductDetail\")[-1].get_attribute('data-product-id')\n",
    "                        product_name = product.find_elements_by_class_name(\"getProductDetail\")[-1].text\n",
    "                    except:\n",
    "                        product_id = product.find_element_by_xpath(\".//strong\").get_attribute('data-product-id')\n",
    "                        product_name = product.find_element_by_xpath(\".//strong\").text\n",
    "                        design_type = \"card\"\n",
    "                    try:\n",
    "                        product_description = product.find_element_by_class_name(\"product-desc\").text\n",
    "                        product_price = product.find_element_by_class_name(\"price\").text    \n",
    "                    except:\n",
    "                        product_description = product.find_element_by_class_name(\"productInfo\").text\n",
    "                        product_price = product.find_element_by_class_name(\"newPrice\").text\n",
    "                        if(not(design_type==\"card\")):\n",
    "                            design_type = \"box\"\n",
    "                    discount = \"TRUE\"\n",
    "                    try:              \n",
    "                        if(design_type==\"list\"):\n",
    "                            product_listed_price = product.find_element_by_class_name(\"listed-price\").text\n",
    "                        if(design_type in [\"card\",\"box\"]):\n",
    "                            product_listed_price = product.find_element_by_class_name(\"listedPrice\").text\n",
    "                    except:\n",
    "                        product_listed_price = product_price\n",
    "                        discount = \"FALSE\"\n",
    "                    menu_list.append([product_id,sublink,category_name,product_name,product_description,product_listed_price,product_price,discount,design_type])\n",
    "                except:\n",
    "                    continue\n",
    "        menu_df = pd.DataFrame(menu_list, columns=[\"PRODUCT_ID\",\"RESTAURANT_ID\",\"CATEGORY_NAME\",\"PRODUCT_NAME\",\"PRODUCT_DESCRIPTION\",\"PRODUCT_LISTED_PRICE\",\"PRODUCT_PRICE\",\"DISCOUNT\",\"DESIGN_TYPE\"])    \n",
    "        menu_df = menu_df[menu_df['PRODUCT_ID'].str.len() > 0]\n",
    "        menu_df = menu_df[menu_df['PRODUCT_NAME'].str.len() > 0]\n",
    "\n",
    "        df_column_conversation(menu_df, 'PRODUCT_ID', 'text')\n",
    "        df_column_conversation(menu_df, 'RESTAURANT_ID', 'text')\n",
    "        df_column_conversation(menu_df, 'CATEGORY_NAME', 'text')\n",
    "        df_column_conversation(menu_df, 'PRODUCT_NAME', 'text')\n",
    "        df_column_conversation(menu_df, 'PRODUCT_DESCRIPTION', 'text')\n",
    "        df_column_conversation(menu_df, 'PRODUCT_LISTED_PRICE', 'text')\n",
    "        df_column_conversation(menu_df, 'PRODUCT_PRICE', 'text')\n",
    "        df_column_conversation(menu_df, 'DESIGN_TYPE', 'text')\n",
    "        menu_df['DATE'] = \"'\"+ datetime.strftime(date.today(), \"%Y-%m-%d\") + \"'::date\"\n",
    "        execute_mogrify(conn,menu_df,\"ODS\",\"EXT_FB_MENU\")\n",
    "    menu_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                        RESTAURANT_ID\n",
       "37  pizza-lazza-kagithane-sultan-selim-sanayi-mah-...\n",
       "32               apizza-legal-tuzla-orta-mah-istanbul\n",
       "20  kervan-pide-lahmacun-sisli-izzet-pasa-mah-ista...\n",
       "23  azderinn-kantina-pizza-besiktas-arnavutkoy-mah...\n",
       "6               bigs-pizza-tuzla-aydinli-mah-istanbul\n",
       "..                                                ...\n",
       "10      bobbys-burger-kadikoy-dumlupinar-mah-istanbul\n",
       "42  food-hall-istanbul-beyoglu-asmalimescit-mah-is...\n",
       "43    vera-pizza-pasta-bakirkoy-cevizlik-mah-istanbul\n",
       "60       ghost-pizza-kadikoy-caddebostan-mah-istanbul\n",
       "34  pizza-italyanoo-kucukcekmece-atakent-mah-kanun...\n",
       "\n",
       "[79 rows x 1 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>RESTAURANT_ID</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>37</th>\n      <td>pizza-lazza-kagithane-sultan-selim-sanayi-mah-...</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>apizza-legal-tuzla-orta-mah-istanbul</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>kervan-pide-lahmacun-sisli-izzet-pasa-mah-ista...</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>azderinn-kantina-pizza-besiktas-arnavutkoy-mah...</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>bigs-pizza-tuzla-aydinli-mah-istanbul</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>bobbys-burger-kadikoy-dumlupinar-mah-istanbul</td>\n    </tr>\n    <tr>\n      <th>42</th>\n      <td>food-hall-istanbul-beyoglu-asmalimescit-mah-is...</td>\n    </tr>\n    <tr>\n      <th>43</th>\n      <td>vera-pizza-pasta-bakirkoy-cevizlik-mah-istanbul</td>\n    </tr>\n    <tr>\n      <th>60</th>\n      <td>ghost-pizza-kadikoy-caddebostan-mah-istanbul</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>pizza-italyanoo-kucukcekmece-atakent-mah-kanun...</td>\n    </tr>\n  </tbody>\n</table>\n<p>79 rows × 1 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "sql_command = \"\"\"\n",
    "    SELECT\n",
    "    \"RESTAURANT_ID\"\n",
    "    FROM \"ODS\".\"EXT_FB_RESTAURANT\" EFR\n",
    "    WHERE 1=1\n",
    "    AND NOT EXISTS(SELECT NULL FROM \"ODS\".\"EXT_FB_COMMENT\" EFC WHERE EFR.\"RESTAURANT_ID\" = EFC.\"RESTAURANT_ID\");\n",
    "    \"\"\"\n",
    "restaurant_df = pd.read_sql(sql_command,conn)\n",
    "restaurant_df = restaurant_df.sample(frac=1)\n",
    "restaurant_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(last_execution_date < end_date):\n",
    "    for i in range(len(restaurant_df)):\n",
    "        sublink = restaurant_df.loc[i,\"RESTAURANT_ID\"]\n",
    "        last_comment_page_url = \"{website}/{sublink}?section=comments&page=9999\".format(website=website,sublink=sublink)\n",
    "        \n",
    "        driver.get(last_comment_page_url)\n",
    "        time.sleep(0.1)\n",
    "\n",
    "        comments_list = []\n",
    "        \n",
    "        if(sublink not in driver.current_url):\n",
    "            continue\n",
    "\n",
    "        last_comment_page_redirect_url = driver.current_url\n",
    "        last_comment_page_number = int(last_comment_page_redirect_url.replace(\"&status=closed\",\"\").replace(\"{website}/{sublink}?section=comments&page=\".format(website=website,sublink=sublink),\"\"))\n",
    "\n",
    "        for page_number in range(1, last_comment_page_number+1):\n",
    "            current_comment_page_url = \"{website}/{sublink}?section=comments&page={page_number}\".format(website=website,sublink=sublink,page_number=page_number)\n",
    "            driver.get(current_comment_page_url)\n",
    "            time.sleep(1)\n",
    "\n",
    "            try:\n",
    "                if(\"sipariş verebilirsiniz.\" in driver.find_element_by_xpath('//*[@id=\"restaurantDetail\"]/div/div[2]/h3').text):\n",
    "                    continue\n",
    "                else:\n",
    "                    pass\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "            try:\n",
    "                driver.find_element(By.XPATH, '//*[@id=\"alternative-restaurant-popup\"]/div[1]/div[2]/img').click(); #Closing pop-up\n",
    "            except Exception:\n",
    "                pass   \n",
    "\n",
    "            #driver.find_element(By.XPATH, '//*[@id=\"restaurantDetail\"]/div[2]/div[1]/ul/li[4]/a').click(); #Clicking comments\n",
    "\n",
    "            comment_list = driver.find_elements_by_class_name(\"comments-body\")\n",
    "        \n",
    "            for comment in comment_list:\n",
    "                try:\n",
    "                    username = comment.find_element_by_class_name(\"userName\").text\n",
    "                    comment_text = comment.find_element_by_xpath('.//p').text\n",
    "                    comment_date = comment.find_element_by_class_name(\"commentDate\").text\n",
    "                except NoSuchElementException:\n",
    "                    continue\n",
    "                try:\n",
    "                    speed = comment.find_element_by_class_name(\"speed\").text\n",
    "                except NoSuchElementException:\n",
    "                    speed = \"\"\n",
    "                try:                    \n",
    "                    serving = comment.find_element_by_class_name(\"serving\").text\n",
    "                except NoSuchElementException:\n",
    "                    serving = \"\"\n",
    "                try:\n",
    "                    flavour = comment.find_element_by_class_name(\"flavour\").text \n",
    "                except NoSuchElementException:\n",
    "                    flavour = \"\"\n",
    "                comments_list.append([sublink, username, comment_text, comment_date, speed, serving, flavour])\n",
    "        comment_df = pd.DataFrame(comments_list, columns=[\"RESTAURANT_ID\",\"USERNAME\",\"COMMENT_TEXT\",\"COMMENT_DATE\",\"SPEED\",\"SERVING\",\"FLAVOUR\"])\n",
    "        df_column_conversation(comment_df, 'RESTAURANT_ID', 'text')\n",
    "        df_column_conversation(comment_df, 'USERNAME', 'text')\n",
    "        df_column_conversation(comment_df, 'COMMENT_TEXT', 'text')\n",
    "        df_column_conversation(comment_df, 'COMMENT_DATE', 'text')\n",
    "        df_column_conversation(comment_df, 'SPEED', 'text')\n",
    "        df_column_conversation(comment_df, 'SERVING', 'text')\n",
    "        df_column_conversation(comment_df, 'FLAVOUR', 'text')\n",
    "        comment_df['DATE'] = \"'\"+ datetime.strftime(date.today(), \"%Y-%m-%d\") + \"'::date\"\n",
    "        execute_mogrify(conn,comment_df,\"ODS\",\"EXT_FB_COMMENT\")\n",
    "    comment_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.quit()"
   ]
  },
  {
   "source": [
    "# Data Preprocessing"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(last_execution_date < end_date):\n",
    "    sql_command = \"\"\"\n",
    "        WITH CLEAN_DATA AS(\n",
    "        SELECT\n",
    "        EFC.\"RESTAURANT_ID\",\n",
    "        EFC.\"USERNAME\",\n",
    "        LOWER(EFC.\"COMMENT_TEXT\") AS \"COMMENT_TEXT\",\n",
    "        EFC.\"COMMENT_DATE\",\n",
    "        TRY_CAST(REGEXP_REPLACE(EFC.\"SPEED\", '\\D','','g'),NULL::INTEGER) AS \"SPEED\",\n",
    "        TRY_CAST(REGEXP_REPLACE(EFC.\"SERVING\", '\\D','','g'),NULL::INTEGER) AS \"SERVING\",\n",
    "        TRY_CAST(REGEXP_REPLACE(EFC.\"FLAVOUR\", '\\D','','g'),NULL::INTEGER) AS \"FLAVOUR\",\n",
    "        EFC.\"DATE\",\n",
    "        REGEXP_REPLACE(EFC.\"COMMENT_DATE\", '\\D','','g')||' '||REPLACE(REPLACE(REPLACE(REGEXP_REPLACE(REPLACE(EFC.\"COMMENT_DATE\",' önce',''), '[^[:alpha:]]', '', 'g'),'ay','month'),'bugün','today'),'gün','day') AS \"COMMENT_DATE_INTERVAL\"\n",
    "        FROM \"ODS\".\"EXT_FB_COMMENT\" EFC\n",
    "        WHERE 1=1\n",
    "        AND EFC.\"USERNAME\" <> 'Yemeksepeti'\n",
    "        )\n",
    "        SELECT\n",
    "        CD.\"RESTAURANT_ID\",\n",
    "        CD.\"USERNAME\",\n",
    "        CD.\"COMMENT_TEXT\",\n",
    "        CASE WHEN CD.\"COMMENT_DATE_INTERVAL\" = ' today' THEN CD.\"DATE\" ELSE CD.\"DATE\" - CAST(CD.\"COMMENT_DATE_INTERVAL\" AS INTERVAL) END::date AS \"COMMENT_DATE\",\n",
    "        CD.\"SPEED\",\n",
    "        CD.\"SERVING\",\n",
    "        CD.\"FLAVOUR\",\n",
    "        CD.\"DATE\"\n",
    "        FROM CLEAN_DATA CD;\n",
    "        \"\"\"\n",
    "    comment_df = pd.read_sql(sql_command,conn)\n",
    "    comment_df['COMMENT_TEXT'] = comment_df['COMMENT_TEXT'].apply(clean_text)\n",
    "    comment_df\n",
    "    df_column_conversation(comment_df, 'RESTAURANT_ID', 'text')\n",
    "    df_column_conversation(comment_df, 'USERNAME', 'text')\n",
    "    df_column_conversation(comment_df, 'COMMENT_TEXT', 'text')\n",
    "    df_column_conversation(comment_df, 'COMMENT_DATE', 'date')\n",
    "    df_column_conversation(comment_df, 'SPEED', 'integer')\n",
    "    df_column_conversation(comment_df, 'SERVING', 'integer')\n",
    "    df_column_conversation(comment_df, 'FLAVOUR', 'integer')\n",
    "    df_column_conversation(comment_df, 'DATE', 'date')\n",
    "    comment_df.replace('<NA>', 'NULL', inplace=True)\n",
    "    execute_mogrify(conn,comment_df,\"EDW\",\"DWH_FB_COMMENT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                     RESTAURANT_ID USERNAME  \\\n",
       "0       magic-akademi-kartal-esentepe-mah-istanbul     ...i   \n",
       "1       magic-akademi-kartal-esentepe-mah-istanbul     ...3   \n",
       "2       magic-akademi-kartal-esentepe-mah-istanbul     ...0   \n",
       "3       magic-akademi-kartal-esentepe-mah-istanbul     ...t   \n",
       "4       magic-akademi-kartal-esentepe-mah-istanbul     ...e   \n",
       "...                                            ...      ...   \n",
       "271838  magic-akademi-kartal-esentepe-mah-istanbul     ...1   \n",
       "271839  magic-akademi-kartal-esentepe-mah-istanbul     ...d   \n",
       "271840  magic-akademi-kartal-esentepe-mah-istanbul     ...k   \n",
       "271841  magic-akademi-kartal-esentepe-mah-istanbul     ...7   \n",
       "271842  magic-akademi-kartal-esentepe-mah-istanbul     ...l   \n",
       "\n",
       "                                             COMMENT_TEXT COMMENT_DATE  SPEED  \\\n",
       "0       i̇lk kez sipariş verdim bu restauranttan patat...   2021-01-10   10.0   \n",
       "1       her söyledigimde somon daha da kötüleşiyor bu ...   2021-01-10    9.0   \n",
       "2                                                     itu   2021-01-10    8.0   \n",
       "3          18 dkda kapıdaydi sıcak ve lezzetli süpersiniz   2021-01-10   10.0   \n",
       "4       dağ kekikli tavuğun yanında gelen makarna bild...   2021-01-10   10.0   \n",
       "...                                                   ...          ...    ...   \n",
       "271838        anladık ki hamburgerler kötü pizzadan devam   2021-01-10    5.0   \n",
       "271839  tiramisu malesef rezaletti kreması ekşimişti y...   2021-01-10    1.0   \n",
       "271840     dağ kekikli tavuk inanılmaz güzel bağımlısıyım   2021-01-10   10.0   \n",
       "271841  waffle söyledik kalın bir hamur üzerine 6 7 kü...   2021-01-10    6.0   \n",
       "271842  pizza adana börek ve pasta nefisti teşekkür ed...   2021-01-10   10.0   \n",
       "\n",
       "        SERVING  FLAVOUR        DATE  \n",
       "0             5        8  2021-06-10  \n",
       "1             6        4  2021-06-10  \n",
       "2             8        8  2021-06-10  \n",
       "3            10       10  2021-06-10  \n",
       "4             6        3  2021-06-10  \n",
       "...         ...      ...         ...  \n",
       "271838        5        5  2021-06-10  \n",
       "271839        1        1  2021-06-10  \n",
       "271840       10       10  2021-06-10  \n",
       "271841        4        3  2021-06-10  \n",
       "271842       10        9  2021-06-10  \n",
       "\n",
       "[271843 rows x 8 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>RESTAURANT_ID</th>\n      <th>USERNAME</th>\n      <th>COMMENT_TEXT</th>\n      <th>COMMENT_DATE</th>\n      <th>SPEED</th>\n      <th>SERVING</th>\n      <th>FLAVOUR</th>\n      <th>DATE</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>magic-akademi-kartal-esentepe-mah-istanbul</td>\n      <td>...i</td>\n      <td>i̇lk kez sipariş verdim bu restauranttan patat...</td>\n      <td>2021-01-10</td>\n      <td>10.0</td>\n      <td>5</td>\n      <td>8</td>\n      <td>2021-06-10</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>magic-akademi-kartal-esentepe-mah-istanbul</td>\n      <td>...3</td>\n      <td>her söyledigimde somon daha da kötüleşiyor bu ...</td>\n      <td>2021-01-10</td>\n      <td>9.0</td>\n      <td>6</td>\n      <td>4</td>\n      <td>2021-06-10</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>magic-akademi-kartal-esentepe-mah-istanbul</td>\n      <td>...0</td>\n      <td>itu</td>\n      <td>2021-01-10</td>\n      <td>8.0</td>\n      <td>8</td>\n      <td>8</td>\n      <td>2021-06-10</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>magic-akademi-kartal-esentepe-mah-istanbul</td>\n      <td>...t</td>\n      <td>18 dkda kapıdaydi sıcak ve lezzetli süpersiniz</td>\n      <td>2021-01-10</td>\n      <td>10.0</td>\n      <td>10</td>\n      <td>10</td>\n      <td>2021-06-10</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>magic-akademi-kartal-esentepe-mah-istanbul</td>\n      <td>...e</td>\n      <td>dağ kekikli tavuğun yanında gelen makarna bild...</td>\n      <td>2021-01-10</td>\n      <td>10.0</td>\n      <td>6</td>\n      <td>3</td>\n      <td>2021-06-10</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>271838</th>\n      <td>magic-akademi-kartal-esentepe-mah-istanbul</td>\n      <td>...1</td>\n      <td>anladık ki hamburgerler kötü pizzadan devam</td>\n      <td>2021-01-10</td>\n      <td>5.0</td>\n      <td>5</td>\n      <td>5</td>\n      <td>2021-06-10</td>\n    </tr>\n    <tr>\n      <th>271839</th>\n      <td>magic-akademi-kartal-esentepe-mah-istanbul</td>\n      <td>...d</td>\n      <td>tiramisu malesef rezaletti kreması ekşimişti y...</td>\n      <td>2021-01-10</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2021-06-10</td>\n    </tr>\n    <tr>\n      <th>271840</th>\n      <td>magic-akademi-kartal-esentepe-mah-istanbul</td>\n      <td>...k</td>\n      <td>dağ kekikli tavuk inanılmaz güzel bağımlısıyım</td>\n      <td>2021-01-10</td>\n      <td>10.0</td>\n      <td>10</td>\n      <td>10</td>\n      <td>2021-06-10</td>\n    </tr>\n    <tr>\n      <th>271841</th>\n      <td>magic-akademi-kartal-esentepe-mah-istanbul</td>\n      <td>...7</td>\n      <td>waffle söyledik kalın bir hamur üzerine 6 7 kü...</td>\n      <td>2021-01-10</td>\n      <td>6.0</td>\n      <td>4</td>\n      <td>3</td>\n      <td>2021-06-10</td>\n    </tr>\n    <tr>\n      <th>271842</th>\n      <td>magic-akademi-kartal-esentepe-mah-istanbul</td>\n      <td>...l</td>\n      <td>pizza adana börek ve pasta nefisti teşekkür ed...</td>\n      <td>2021-01-10</td>\n      <td>10.0</td>\n      <td>10</td>\n      <td>9</td>\n      <td>2021-06-10</td>\n    </tr>\n  </tbody>\n</table>\n<p>271843 rows × 8 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "sql_command = \"\"\"\n",
    "    SELECT\n",
    "    *\n",
    "    FROM \"EDW\".\"DWH_FB_COMMENT\" EFR;\n",
    "    \"\"\"\n",
    "comment_df = pd.read_sql(sql_command,conn)\n",
    "comment_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                     RESTAURANT_ID USERNAME  \\\n",
       "0       magic-akademi-kartal-esentepe-mah-istanbul     ...i   \n",
       "1       magic-akademi-kartal-esentepe-mah-istanbul     ...3   \n",
       "2       magic-akademi-kartal-esentepe-mah-istanbul     ...0   \n",
       "3       magic-akademi-kartal-esentepe-mah-istanbul     ...t   \n",
       "4       magic-akademi-kartal-esentepe-mah-istanbul     ...e   \n",
       "...                                            ...      ...   \n",
       "271838  magic-akademi-kartal-esentepe-mah-istanbul     ...1   \n",
       "271839  magic-akademi-kartal-esentepe-mah-istanbul     ...d   \n",
       "271840  magic-akademi-kartal-esentepe-mah-istanbul     ...k   \n",
       "271841  magic-akademi-kartal-esentepe-mah-istanbul     ...7   \n",
       "271842  magic-akademi-kartal-esentepe-mah-istanbul     ...l   \n",
       "\n",
       "                                             COMMENT_TEXT COMMENT_DATE  SPEED  \\\n",
       "0       i̇lk sipariş verdim restauranttan patates sıca...   2021-01-10   10.0   \n",
       "1       söyledigimde somon kötüleşiyor sefer fettucini...   2021-01-10    9.0   \n",
       "2                                                     itu   2021-01-10    8.0   \n",
       "3             18 dkda kapıdaydi sıcak lezzetli süpersiniz   2021-01-10   10.0   \n",
       "4       dağ kekikli tavuğun yanında gelen makarna bild...   2021-01-10   10.0   \n",
       "...                                                   ...          ...    ...   \n",
       "271838           anladık hamburgerler kötü pizzadan devam   2021-01-10    5.0   \n",
       "271839  tiramisu malesef rezaletti kreması ekşimişti y...   2021-01-10    1.0   \n",
       "271840     dağ kekikli tavuk inanılmaz güzel bağımlısıyım   2021-01-10   10.0   \n",
       "271841  waffle söyledik kalın bir hamur üzerine 6 7 kü...   2021-01-10    6.0   \n",
       "271842    pizza adana börek pasta nefisti teşekkür ederiz   2021-01-10   10.0   \n",
       "\n",
       "        SERVING  FLAVOUR        DATE  \n",
       "0             5        8  2021-06-10  \n",
       "1             6        4  2021-06-10  \n",
       "2             8        8  2021-06-10  \n",
       "3            10       10  2021-06-10  \n",
       "4             6        3  2021-06-10  \n",
       "...         ...      ...         ...  \n",
       "271838        5        5  2021-06-10  \n",
       "271839        1        1  2021-06-10  \n",
       "271840       10       10  2021-06-10  \n",
       "271841        4        3  2021-06-10  \n",
       "271842       10        9  2021-06-10  \n",
       "\n",
       "[271843 rows x 8 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>RESTAURANT_ID</th>\n      <th>USERNAME</th>\n      <th>COMMENT_TEXT</th>\n      <th>COMMENT_DATE</th>\n      <th>SPEED</th>\n      <th>SERVING</th>\n      <th>FLAVOUR</th>\n      <th>DATE</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>magic-akademi-kartal-esentepe-mah-istanbul</td>\n      <td>...i</td>\n      <td>i̇lk sipariş verdim restauranttan patates sıca...</td>\n      <td>2021-01-10</td>\n      <td>10.0</td>\n      <td>5</td>\n      <td>8</td>\n      <td>2021-06-10</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>magic-akademi-kartal-esentepe-mah-istanbul</td>\n      <td>...3</td>\n      <td>söyledigimde somon kötüleşiyor sefer fettucini...</td>\n      <td>2021-01-10</td>\n      <td>9.0</td>\n      <td>6</td>\n      <td>4</td>\n      <td>2021-06-10</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>magic-akademi-kartal-esentepe-mah-istanbul</td>\n      <td>...0</td>\n      <td>itu</td>\n      <td>2021-01-10</td>\n      <td>8.0</td>\n      <td>8</td>\n      <td>8</td>\n      <td>2021-06-10</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>magic-akademi-kartal-esentepe-mah-istanbul</td>\n      <td>...t</td>\n      <td>18 dkda kapıdaydi sıcak lezzetli süpersiniz</td>\n      <td>2021-01-10</td>\n      <td>10.0</td>\n      <td>10</td>\n      <td>10</td>\n      <td>2021-06-10</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>magic-akademi-kartal-esentepe-mah-istanbul</td>\n      <td>...e</td>\n      <td>dağ kekikli tavuğun yanında gelen makarna bild...</td>\n      <td>2021-01-10</td>\n      <td>10.0</td>\n      <td>6</td>\n      <td>3</td>\n      <td>2021-06-10</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>271838</th>\n      <td>magic-akademi-kartal-esentepe-mah-istanbul</td>\n      <td>...1</td>\n      <td>anladık hamburgerler kötü pizzadan devam</td>\n      <td>2021-01-10</td>\n      <td>5.0</td>\n      <td>5</td>\n      <td>5</td>\n      <td>2021-06-10</td>\n    </tr>\n    <tr>\n      <th>271839</th>\n      <td>magic-akademi-kartal-esentepe-mah-istanbul</td>\n      <td>...d</td>\n      <td>tiramisu malesef rezaletti kreması ekşimişti y...</td>\n      <td>2021-01-10</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2021-06-10</td>\n    </tr>\n    <tr>\n      <th>271840</th>\n      <td>magic-akademi-kartal-esentepe-mah-istanbul</td>\n      <td>...k</td>\n      <td>dağ kekikli tavuk inanılmaz güzel bağımlısıyım</td>\n      <td>2021-01-10</td>\n      <td>10.0</td>\n      <td>10</td>\n      <td>10</td>\n      <td>2021-06-10</td>\n    </tr>\n    <tr>\n      <th>271841</th>\n      <td>magic-akademi-kartal-esentepe-mah-istanbul</td>\n      <td>...7</td>\n      <td>waffle söyledik kalın bir hamur üzerine 6 7 kü...</td>\n      <td>2021-01-10</td>\n      <td>6.0</td>\n      <td>4</td>\n      <td>3</td>\n      <td>2021-06-10</td>\n    </tr>\n    <tr>\n      <th>271842</th>\n      <td>magic-akademi-kartal-esentepe-mah-istanbul</td>\n      <td>...l</td>\n      <td>pizza adana börek pasta nefisti teşekkür ederiz</td>\n      <td>2021-01-10</td>\n      <td>10.0</td>\n      <td>10</td>\n      <td>9</td>\n      <td>2021-06-10</td>\n    </tr>\n  </tbody>\n</table>\n<p>271843 rows × 8 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "stop_words = [element for element in stopwords.words('turkish') if element not in ['çok','eğer','gibi','hiç','niçin','niye','sanki','yani','en','az','birkaç','bazı','aslında','neden','hepsi']]\n",
    "comment_df['COMMENT_TEXT'] = comment_df['COMMENT_TEXT'].apply(lambda x: ' '.join([word for word in x.lower().split() if word not in (stop_words)]))\n",
    "#comment_df['COMMENT_TEXT'] = comment_df['COMMENT_TEXT'].apply(lambda x: ' '.join([stemmer.stem(word) for word in x.split()]))\n",
    "comment_df"
   ]
  },
  {
   "source": [
    "# Machine Learning"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Bag of Words"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Gaussian Naive Bayes"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-14-3204ce730710>:3: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  not_null_df = comment_df[0:10000][pd.notnull(comment_df[label])]\n",
      "Total Features after vectorizing: 2733\n",
      "Accuracy Score for SPEED: 31.33%\n",
      "F1 Score for SPEED: 31.33%\n",
      "Precision Score for SPEED: 31.33%\n",
      "Total Features after vectorizing: 4003\n",
      "<ipython-input-14-3204ce730710>:3: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  not_null_df = comment_df[0:10000][pd.notnull(comment_df[label])]\n",
      "Accuracy Score for SERVING: 31.00%\n",
      "F1 Score for SERVING: 31.00%\n",
      "Precision Score for SERVING: 31.00%\n",
      "Total Features after vectorizing: 4003\n",
      "<ipython-input-14-3204ce730710>:3: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  not_null_df = comment_df[0:10000][pd.notnull(comment_df[label])]\n",
      "Accuracy Score for FLAVOUR: 28.87%\n",
      "F1 Score for FLAVOUR: 28.87%\n",
      "Precision Score for FLAVOUR: 28.87%\n"
     ]
    }
   ],
   "source": [
    "for label in ['SPEED','SERVING','FLAVOUR']:\n",
    "    model = CountVectorizer(min_df=3)\n",
    "    not_null_df = comment_df[0:10000][pd.notnull(comment_df[label])]\n",
    "    features = model.fit_transform(not_null_df['COMMENT_TEXT'].values).todense()\n",
    "    labels = not_null_df[label].values\n",
    "    print(\"Total Features after vectorizing: {total_features}\".format(total_features = np.shape(features)[1]))\n",
    "    #print(np.shape(labels))\n",
    "\n",
    "    features_train, features_test, labels_train, labels_test = train_test_split(features, labels, test_size = 0.3, random_state = 9)\n",
    "\n",
    "    model = GaussianNB()\n",
    "    model.fit(features_train, labels_train)\n",
    "\n",
    "    label_prediction = model.predict(features_test)\n",
    "\n",
    "    print(\"Accuracy Score for {label}: {accuracy_score:0.2f}%\".format(accuracy_score = accuracy_score(labels_test, label_prediction)*100, label=label))\n",
    "    print(\"F1 Score for {label}: {f1_score:0.2f}%\".format(f1_score = f1_score(labels_test, label_prediction, average='micro')*100, label=label))\n",
    "    print(\"Precision Score for {label}: {precision_score:0.2f}%\".format(precision_score  = precision_score(labels_test, label_prediction, average='micro')*100, label=label))"
   ]
  },
  {
   "source": [
    "### Support Vector Machines"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "#### C-Support Vector Classification"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Total Features after vectorizing: 2733\n",
      "<ipython-input-15-f95b5dda4d7a>:3: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  not_null_df = comment_df[0:10000][pd.notnull(comment_df[label])]\n",
      "Accuracy Score for SPEED: 64.19%\n",
      "F1 Score for SPEED: 64.19%\n",
      "Precision Score for SPEED: 64.19%\n",
      "Total Features after vectorizing: 4003\n",
      "<ipython-input-15-f95b5dda4d7a>:3: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  not_null_df = comment_df[0:10000][pd.notnull(comment_df[label])]\n",
      "Accuracy Score for SERVING: 64.73%\n",
      "F1 Score for SERVING: 64.73%\n",
      "Precision Score for SERVING: 64.73%\n",
      "<ipython-input-15-f95b5dda4d7a>:3: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  not_null_df = comment_df[0:10000][pd.notnull(comment_df[label])]\n",
      "Total Features after vectorizing: 4003\n",
      "Accuracy Score for FLAVOUR: 62.00%\n",
      "F1 Score for FLAVOUR: 62.00%\n",
      "Precision Score for FLAVOUR: 62.00%\n"
     ]
    }
   ],
   "source": [
    "for label in ['SPEED','SERVING','FLAVOUR']:\n",
    "    model = CountVectorizer(min_df=3)\n",
    "    not_null_df = comment_df[0:10000][pd.notnull(comment_df[label])]\n",
    "    features = model.fit_transform(not_null_df['COMMENT_TEXT'].values).todense()\n",
    "    labels = not_null_df[label].values\n",
    "    print(\"Total Features after vectorizing: {total_features}\".format(total_features = np.shape(features)[1]))\n",
    "\n",
    "    features_train, features_test, labels_train, labels_test = train_test_split(features, labels, test_size = 0.3, random_state = 9)\n",
    "\n",
    "    model = SVC()\n",
    "    model.fit(features_train, labels_train)\n",
    "\n",
    "    label_prediction = model.predict(features_test)\n",
    "\n",
    "    print(\"Accuracy Score for {label}: {accuracy_score:0.2f}%\".format(accuracy_score = accuracy_score(labels_test, label_prediction)*100, label=label))\n",
    "    print(\"F1 Score for {label}: {f1_score:0.2f}%\".format(f1_score = f1_score(labels_test, label_prediction, average='micro')*100, label=label))\n",
    "    print(\"Precision Score for {label}: {precision_score:0.2f}%\".format(precision_score  = precision_score(labels_test, label_prediction, average='micro')*100, label=label))"
   ]
  },
  {
   "source": [
    "#### Linear Support Vector Classification"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Total Features after vectorizing: 2733\n",
      "<ipython-input-16-e75e2f9c6e01>:3: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  not_null_df = comment_df[0:10000][pd.notnull(comment_df[label])]\n",
      "Accuracy Score for SPEED: 60.05%\n",
      "F1 Score for SPEED: 60.05%\n",
      "Precision Score for SPEED: 60.05%\n",
      "Total Features after vectorizing: 4003\n",
      "<ipython-input-16-e75e2f9c6e01>:3: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  not_null_df = comment_df[0:10000][pd.notnull(comment_df[label])]\n",
      "Accuracy Score for SERVING: 61.63%\n",
      "F1 Score for SERVING: 61.63%\n",
      "Precision Score for SERVING: 61.63%\n",
      "Total Features after vectorizing: 4003\n",
      "<ipython-input-16-e75e2f9c6e01>:3: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  not_null_df = comment_df[0:10000][pd.notnull(comment_df[label])]\n",
      "Accuracy Score for FLAVOUR: 58.20%\n",
      "F1 Score for FLAVOUR: 58.20%\n",
      "Precision Score for FLAVOUR: 58.20%\n"
     ]
    }
   ],
   "source": [
    "for label in ['SPEED','SERVING','FLAVOUR']:\n",
    "    model = CountVectorizer(min_df=3)\n",
    "    not_null_df = comment_df[0:10000][pd.notnull(comment_df[label])]\n",
    "    features = model.fit_transform(not_null_df['COMMENT_TEXT'].values).todense()\n",
    "    labels = not_null_df[label].values\n",
    "    print(\"Total Features after vectorizing: {total_features}\".format(total_features = np.shape(features)[1]))\n",
    "\n",
    "    features_train, features_test, labels_train, labels_test = train_test_split(features, labels, test_size = 0.3, random_state = 9)\n",
    "\n",
    "    model = LinearSVC()\n",
    "    model.fit(features_train, labels_train)\n",
    "\n",
    "    label_prediction = model.predict(features_test)\n",
    "\n",
    "    print(\"Accuracy Score for {label}: {accuracy_score:0.2f}%\".format(accuracy_score = accuracy_score(labels_test, label_prediction)*100, label=label))\n",
    "    print(\"F1 Score for {label}: {f1_score:0.2f}%\".format(f1_score = f1_score(labels_test, label_prediction, average='micro')*100, label=label))\n",
    "    print(\"Precision Score for {label}: {precision_score:0.2f}%\".format(precision_score  = precision_score(labels_test, label_prediction, average='micro')*100, label=label))"
   ]
  },
  {
   "source": [
    "### Decision Tree Classifier"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Total Features after vectorizing: 2733\n",
      "<ipython-input-17-39bfdc06108a>:3: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  not_null_df = comment_df[0:10000][pd.notnull(comment_df[label])]\n",
      "Best parameters: {'max_depth': 14, 'min_samples_split': 2}\n",
      "Accuracy Score for SPEED: 63.60%\n",
      "F1 Score for SPEED: 63.60%\n",
      "Precision Score for SPEED: 63.60%\n",
      "Total Features after vectorizing: 4003\n",
      "<ipython-input-17-39bfdc06108a>:3: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  not_null_df = comment_df[0:10000][pd.notnull(comment_df[label])]\n",
      "Best parameters: {'max_depth': 10, 'min_samples_split': 3}\n",
      "Accuracy Score for SERVING: 63.23%\n",
      "F1 Score for SERVING: 63.23%\n",
      "Precision Score for SERVING: 63.23%\n",
      "Total Features after vectorizing: 4003<ipython-input-17-39bfdc06108a>:3: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  not_null_df = comment_df[0:10000][pd.notnull(comment_df[label])]\n",
      "\n",
      "Best parameters: {'max_depth': 13, 'min_samples_split': 2}\n",
      "Accuracy Score for FLAVOUR: 59.33%\n",
      "F1 Score for FLAVOUR: 59.33%\n",
      "Precision Score for FLAVOUR: 59.33%\n"
     ]
    }
   ],
   "source": [
    "for label in ['SPEED','SERVING','FLAVOUR']:\n",
    "    model = CountVectorizer(min_df=3)\n",
    "    not_null_df = comment_df[0:10000][pd.notnull(comment_df[label])]\n",
    "    features = model.fit_transform(not_null_df['COMMENT_TEXT'].values).todense()\n",
    "    labels = not_null_df[label].values\n",
    "    print(\"Total Features after vectorizing: {total_features}\".format(total_features = np.shape(features)[1]))\n",
    "\n",
    "    features_train, features_test, labels_train, labels_test = train_test_split(features, labels, test_size = 0.3, random_state = 9)\n",
    "\n",
    "    params = {\n",
    "        'max_depth': [10,13,14,15],\n",
    "        'min_samples_split': [2,3,4]\n",
    "        }\n",
    "\n",
    "    gscv = GridSearchCV(DecisionTreeClassifier(), params, cv=5)\n",
    "    gscv.fit(features_train, labels_train)\n",
    "    print(\"Best parameters: {best_parameters}\".format(best_parameters = gscv.best_params_))\n",
    "\n",
    "    model = gscv.best_estimator_\n",
    "    model.fit(features_train, labels_train)\n",
    "\n",
    "    label_prediction = model.predict(features_test)\n",
    "\n",
    "    print(\"Accuracy Score for {label}: {accuracy_score:0.2f}%\".format(accuracy_score = accuracy_score(labels_test, label_prediction)*100, label=label))\n",
    "    print(\"F1 Score for {label}: {f1_score:0.2f}%\".format(f1_score = f1_score(labels_test, label_prediction, average='micro')*100, label=label))\n",
    "    print(\"Precision Score for {label}: {precision_score:0.2f}%\".format(precision_score  = precision_score(labels_test, label_prediction, average='micro')*100, label=label))"
   ]
  },
  {
   "source": [
    "### Logistic Regression"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Total Features after vectorizing: 2619\n",
      "<ipython-input-18-bd0b3e30edb2>:3: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  not_null_df = comment_df[0:9600][pd.notnull(comment_df[label])]\n",
      "Accuracy Score for SPEED: 63.19%\n",
      "F1 Score for SPEED: 63.19%\n",
      "Precision Score for SPEED: 63.19%\n",
      "Total Features after vectorizing: 3913\n",
      "<ipython-input-18-bd0b3e30edb2>:3: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  not_null_df = comment_df[0:9600][pd.notnull(comment_df[label])]\n",
      "Accuracy Score for SERVING: 64.90%\n",
      "F1 Score for SERVING: 64.90%\n",
      "Precision Score for SERVING: 64.90%\n",
      "Total Features after vectorizing: 3913\n",
      "<ipython-input-18-bd0b3e30edb2>:3: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  not_null_df = comment_df[0:9600][pd.notnull(comment_df[label])]\n",
      "Accuracy Score for FLAVOUR: 63.12%\n",
      "F1 Score for FLAVOUR: 63.12%\n",
      "Precision Score for FLAVOUR: 63.12%\n"
     ]
    }
   ],
   "source": [
    "for label in ['SPEED','SERVING','FLAVOUR']:\n",
    "    model = CountVectorizer(min_df=3)\n",
    "    not_null_df = comment_df[0:9600][pd.notnull(comment_df[label])]\n",
    "    features = model.fit_transform(not_null_df['COMMENT_TEXT'].values).todense()\n",
    "    labels = not_null_df[label].values\n",
    "    print(\"Total Features after vectorizing: {total_features}\".format(total_features = np.shape(features)[1]))\n",
    "\n",
    "    features_train, features_test, labels_train, labels_test = train_test_split(features, labels, test_size = 0.3, random_state = 9)\n",
    "\n",
    "    model = LogisticRegression(penalty='l2', C=1.2, n_jobs=-1)\n",
    "    model.fit(features_train, labels_train)\n",
    "\n",
    "    label_prediction = model.predict(features_test)\n",
    "\n",
    "    print(\"Accuracy Score for {label}: {accuracy_score:0.2f}%\".format(accuracy_score = accuracy_score(labels_test, label_prediction)*100, label=label))\n",
    "    print(\"F1 Score for {label}: {f1_score:0.2f}%\".format(f1_score = f1_score(labels_test, label_prediction, average='micro')*100, label=label))\n",
    "    print(\"Precision Score for {label}: {precision_score:0.2f}%\".format(precision_score  = precision_score(labels_test, label_prediction, average='micro')*100, label=label))"
   ]
  },
  {
   "source": [
    "## Bag of Words with TF-IDF Vectorizer"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Gaussian Naive Bayes"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Total Features after vectorizing: 2733\n",
      "<ipython-input-19-b67fda193b23>:3: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  not_null_df = comment_df[0:10000][pd.notnull(comment_df[label])]\n",
      "Accuracy Score for SPEED: 31.43%\n",
      "F1 Score for SPEED: 31.43%\n",
      "Precision Score for SPEED: 31.43%\n",
      "Total Features after vectorizing: 4003\n",
      "<ipython-input-19-b67fda193b23>:3: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  not_null_df = comment_df[0:10000][pd.notnull(comment_df[label])]\n",
      "Accuracy Score for SERVING: 31.40%\n",
      "F1 Score for SERVING: 31.40%\n",
      "Precision Score for SERVING: 31.40%\n",
      "Total Features after vectorizing: 4003\n",
      "<ipython-input-19-b67fda193b23>:3: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  not_null_df = comment_df[0:10000][pd.notnull(comment_df[label])]\n",
      "Accuracy Score for FLAVOUR: 28.57%\n",
      "F1 Score for FLAVOUR: 28.57%\n",
      "Precision Score for FLAVOUR: 28.57%\n"
     ]
    }
   ],
   "source": [
    "for label in ['SPEED','SERVING','FLAVOUR']:\n",
    "    model = TfidfVectorizer(min_df=3)\n",
    "    not_null_df = comment_df[0:10000][pd.notnull(comment_df[label])]\n",
    "    features = model.fit_transform(not_null_df['COMMENT_TEXT'].values).todense()\n",
    "    labels = not_null_df[label].values\n",
    "    print(\"Total Features after vectorizing: {total_features}\".format(total_features = np.shape(features)[1]))\n",
    "    #print(np.shape(labels))\n",
    "\n",
    "    features_train, features_test, labels_train, labels_test = train_test_split(features, labels, test_size = 0.3, random_state = 9)\n",
    "\n",
    "    model = GaussianNB()\n",
    "    model.fit(features_train, labels_train)\n",
    "\n",
    "    label_prediction = model.predict(features_test)\n",
    "\n",
    "    print(\"Accuracy Score for {label}: {accuracy_score:0.2f}%\".format(accuracy_score = accuracy_score(labels_test, label_prediction)*100, label=label))\n",
    "    print(\"F1 Score for {label}: {f1_score:0.2f}%\".format(f1_score = f1_score(labels_test, label_prediction, average='micro')*100, label=label))\n",
    "    print(\"Precision Score for {label}: {precision_score:0.2f}%\".format(precision_score  = precision_score(labels_test, label_prediction, average='micro')*100, label=label))"
   ]
  },
  {
   "source": [
    "### Support Vector Machines"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "#### C-Support Vector Classification"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Total Features after vectorizing: 2733\n",
      "<ipython-input-20-b836e0614bf6>:3: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  not_null_df = comment_df[0:10000][pd.notnull(comment_df[label])]\n",
      "Best parameters: {'C': 1.5, 'kernel': 'rbf'}\n",
      "Accuracy Score for SPEED: 65.76%\n",
      "F1 Score for SPEED: 65.76%\n",
      "Precision Score for SPEED: 65.76%\n",
      "Total Features after vectorizing: 4003\n",
      "<ipython-input-20-b836e0614bf6>:3: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  not_null_df = comment_df[0:10000][pd.notnull(comment_df[label])]\n",
      "Best parameters: {'C': 1.5, 'kernel': 'rbf'}\n",
      "Accuracy Score for SERVING: 66.67%\n",
      "F1 Score for SERVING: 66.67%\n",
      "Precision Score for SERVING: 66.67%\n",
      "Total Features after vectorizing: 4003\n",
      "<ipython-input-20-b836e0614bf6>:3: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  not_null_df = comment_df[0:10000][pd.notnull(comment_df[label])]\n",
      "Best parameters: {'C': 1.5, 'kernel': 'rbf'}\n",
      "Accuracy Score for FLAVOUR: 63.53%\n",
      "F1 Score for FLAVOUR: 63.53%\n",
      "Precision Score for FLAVOUR: 63.53%\n"
     ]
    }
   ],
   "source": [
    "for label in ['SPEED','SERVING','FLAVOUR']:\n",
    "    model = TfidfVectorizer(min_df=3)\n",
    "    not_null_df = comment_df[0:10000][pd.notnull(comment_df[label])]\n",
    "    features = model.fit_transform(not_null_df['COMMENT_TEXT'].values).todense()\n",
    "    labels = not_null_df[label].values\n",
    "    print(\"Total Features after vectorizing: {total_features}\".format(total_features = np.shape(features)[1]))\n",
    "\n",
    "    features_train, features_test, labels_train, labels_test = train_test_split(features, labels, test_size = 0.3, random_state = 9)\n",
    "\n",
    "    params = {\n",
    "        'C': [1.5],\n",
    "        #'C': [1.4,1.5,1.6],\n",
    "        'kernel': ['rbf']\n",
    "        #'kernel': ['linear','rbf','sigmoid']\n",
    "        }\n",
    "\n",
    "    gscv = GridSearchCV(SVC(), params, cv=5)\n",
    "    gscv.fit(features_train, labels_train)\n",
    "    print(\"Best parameters: {best_parameters}\".format(best_parameters = gscv.best_params_))\n",
    "\n",
    "    model = gscv.best_estimator_\n",
    "    model.fit(features_train, labels_train)\n",
    "\n",
    "    label_prediction = model.predict(features_test)\n",
    "\n",
    "    print(\"Accuracy Score for {label}: {accuracy_score:0.2f}%\".format(accuracy_score = accuracy_score(labels_test, label_prediction)*100, label=label))\n",
    "    print(\"F1 Score for {label}: {f1_score:0.2f}%\".format(f1_score = f1_score(labels_test, label_prediction, average='micro')*100, label=label))\n",
    "    print(\"Precision Score for {label}: {precision_score:0.2f}%\".format(precision_score  = precision_score(labels_test, label_prediction, average='micro')*100, label=label))"
   ]
  },
  {
   "source": [
    "#### Linear Support Vector Classification"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Total Features after vectorizing: 2733\n",
      "<ipython-input-21-19bdb136a765>:3: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  not_null_df = comment_df[0:10000][pd.notnull(comment_df[label])]\n",
      "Accuracy Score for SPEED: 63.05%\n",
      "F1 Score for SPEED: 63.05%\n",
      "Precision Score for SPEED: 63.05%\n",
      "Total Features after vectorizing: 4003\n",
      "<ipython-input-21-19bdb136a765>:3: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  not_null_df = comment_df[0:10000][pd.notnull(comment_df[label])]\n",
      "Accuracy Score for SERVING: 65.10%\n",
      "F1 Score for SERVING: 65.10%\n",
      "Precision Score for SERVING: 65.10%\n",
      "Total Features after vectorizing: 4003\n",
      "<ipython-input-21-19bdb136a765>:3: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  not_null_df = comment_df[0:10000][pd.notnull(comment_df[label])]\n",
      "Accuracy Score for FLAVOUR: 61.67%\n",
      "F1 Score for FLAVOUR: 61.67%\n",
      "Precision Score for FLAVOUR: 61.67%\n"
     ]
    }
   ],
   "source": [
    "for label in ['SPEED','SERVING','FLAVOUR']:\n",
    "    model = TfidfVectorizer(min_df=3)\n",
    "    not_null_df = comment_df[0:10000][pd.notnull(comment_df[label])]\n",
    "    features = model.fit_transform(not_null_df['COMMENT_TEXT'].values).todense()\n",
    "    labels = not_null_df[label].values\n",
    "    print(\"Total Features after vectorizing: {total_features}\".format(total_features = np.shape(features)[1]))\n",
    "\n",
    "    features_train, features_test, labels_train, labels_test = train_test_split(features, labels, test_size = 0.3, random_state = 9)\n",
    "\n",
    "    model = LinearSVC()\n",
    "    model.fit(features_train, labels_train)\n",
    "\n",
    "    label_prediction = model.predict(features_test)\n",
    "\n",
    "    print(\"Accuracy Score for {label}: {accuracy_score:0.2f}%\".format(accuracy_score = accuracy_score(labels_test, label_prediction)*100, label=label))\n",
    "    print(\"F1 Score for {label}: {f1_score:0.2f}%\".format(f1_score = f1_score(labels_test, label_prediction, average='micro')*100, label=label))\n",
    "    print(\"Precision Score for {label}: {precision_score:0.2f}%\".format(precision_score  = precision_score(labels_test, label_prediction, average='micro')*100, label=label))"
   ]
  },
  {
   "source": [
    "### Decision Tree Classifier"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Total Features after vectorizing: 2619\n",
      "<ipython-input-22-f256257235fc>:3: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  not_null_df = comment_df[0:9600][pd.notnull(comment_df[label])]\n",
      "Best parameters: {'max_depth': 10, 'min_samples_split': 2}\n",
      "Accuracy Score for SPEED: 62.93%\n",
      "F1 Score for SPEED: 62.93%\n",
      "Precision Score for SPEED: 62.93%\n",
      "Total Features after vectorizing: 3913\n",
      "<ipython-input-22-f256257235fc>:3: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  not_null_df = comment_df[0:9600][pd.notnull(comment_df[label])]\n",
      "Best parameters: {'max_depth': 9, 'min_samples_split': 2}\n",
      "Accuracy Score for SERVING: 61.91%\n",
      "F1 Score for SERVING: 61.91%\n",
      "Precision Score for SERVING: 61.91%\n",
      "Total Features after vectorizing: 3913\n",
      "<ipython-input-22-f256257235fc>:3: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  not_null_df = comment_df[0:9600][pd.notnull(comment_df[label])]\n",
      "Best parameters: {'max_depth': 9, 'min_samples_split': 3}\n",
      "Accuracy Score for FLAVOUR: 59.93%\n",
      "F1 Score for FLAVOUR: 59.93%\n",
      "Precision Score for FLAVOUR: 59.93%\n"
     ]
    }
   ],
   "source": [
    "for label in ['SPEED','SERVING','FLAVOUR']:\n",
    "    model = TfidfVectorizer(min_df=3)\n",
    "    not_null_df = comment_df[0:9600][pd.notnull(comment_df[label])]\n",
    "    features = model.fit_transform(not_null_df['COMMENT_TEXT'].values).todense()\n",
    "    labels = not_null_df[label].values\n",
    "    print(\"Total Features after vectorizing: {total_features}\".format(total_features = np.shape(features)[1]))\n",
    "\n",
    "    features_train, features_test, labels_train, labels_test = train_test_split(features, labels, test_size = 0.3, random_state = 9)\n",
    "\n",
    "    params = {\n",
    "        'max_depth': [9,10,11],\n",
    "        'min_samples_split': [2,3]\n",
    "        }\n",
    "\n",
    "    gscv = GridSearchCV(DecisionTreeClassifier(), params, cv=5)\n",
    "    gscv.fit(features_train, labels_train)\n",
    "    print(\"Best parameters: {best_parameters}\".format(best_parameters = gscv.best_params_))\n",
    "\n",
    "    model = gscv.best_estimator_\n",
    "    model.fit(features_train, labels_train)\n",
    "\n",
    "    label_prediction = model.predict(features_test)\n",
    "\n",
    "    print(\"Accuracy Score for {label}: {accuracy_score:0.2f}%\".format(accuracy_score = accuracy_score(labels_test, label_prediction)*100, label=label))\n",
    "    print(\"F1 Score for {label}: {f1_score:0.2f}%\".format(f1_score = f1_score(labels_test, label_prediction, average='micro')*100, label=label))\n",
    "    print(\"Precision Score for {label}: {precision_score:0.2f}%\".format(precision_score  = precision_score(labels_test, label_prediction, average='micro')*100, label=label))"
   ]
  },
  {
   "source": [
    "### Logistic Regression"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Total Features after vectorizing: 2619\n",
      "<ipython-input-23-d41c2553ecea>:3: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  not_null_df = comment_df[0:9600][pd.notnull(comment_df[label])]\n",
      "Accuracy Score for SPEED: 65.71%\n",
      "F1 Score for SPEED: 65.71%\n",
      "Precision Score for SPEED: 65.71%\n",
      "Total Features after vectorizing: 3913\n",
      "<ipython-input-23-d41c2553ecea>:3: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  not_null_df = comment_df[0:9600][pd.notnull(comment_df[label])]\n",
      "Accuracy Score for SERVING: 65.73%\n",
      "F1 Score for SERVING: 65.73%\n",
      "Precision Score for SERVING: 65.73%\n",
      "Total Features after vectorizing: 3913\n",
      "<ipython-input-23-d41c2553ecea>:3: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  not_null_df = comment_df[0:9600][pd.notnull(comment_df[label])]\n",
      "Accuracy Score for FLAVOUR: 63.96%\n",
      "F1 Score for FLAVOUR: 63.96%\n",
      "Precision Score for FLAVOUR: 63.96%\n"
     ]
    }
   ],
   "source": [
    "for label in ['SPEED','SERVING','FLAVOUR']:\n",
    "    model = TfidfVectorizer(min_df=3)\n",
    "    not_null_df = comment_df[0:9600][pd.notnull(comment_df[label])]\n",
    "    features = model.fit_transform(not_null_df['COMMENT_TEXT'].values).todense()\n",
    "    labels = not_null_df[label].values\n",
    "    print(\"Total Features after vectorizing: {total_features}\".format(total_features = np.shape(features)[1]))\n",
    "\n",
    "    features_train, features_test, labels_train, labels_test = train_test_split(features, labels, test_size = 0.3, random_state = 9)\n",
    "\n",
    "    model = LogisticRegression(penalty='l2', C=1.2, n_jobs=-1)\n",
    "    model.fit(features_train, labels_train)\n",
    "\n",
    "    label_prediction = model.predict(features_test)\n",
    "\n",
    "    print(\"Accuracy Score for {label}: {accuracy_score:0.2f}%\".format(accuracy_score = accuracy_score(labels_test, label_prediction)*100, label=label))\n",
    "    print(\"F1 Score for {label}: {f1_score:0.2f}%\".format(f1_score = f1_score(labels_test, label_prediction, average='micro')*100, label=label))\n",
    "    print(\"Precision Score for {label}: {precision_score:0.2f}%\".format(precision_score  = precision_score(labels_test, label_prediction, average='micro')*100, label=label))"
   ]
  },
  {
   "source": [
    "## Markov Chains"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                   RESTAURANT_ID  \\\n",
       "0    pizza-bulls-uskudar-altunizade-mah-istanbul   \n",
       "1         pizza-bulls-uskudar-ferah-mah-istanbul   \n",
       "2  pizza-bulls-kartal-soganlik-yeni-mah-istanbul   \n",
       "3       pizza-bulls-umraniye-cakmak-mah-istanbul   \n",
       "4        pizza-bulls-atasehir-fetih-mah-istanbul   \n",
       "\n",
       "                                         all_comment  comment_count  \n",
       "0  lezzeti eskisi gibi gelmedi bize. fark ödeyip ...           2293  \n",
       "1  her şey çok güzeldi. elinize sağlık. hizli ve ...           1764  \n",
       "2  cok pahali olmasi disinda bir problem yok gibi...           1743  \n",
       "3  çok lezzetli güvenle çoçuguma yedirebiliyorum ...           1582  \n",
       "4  servis ve hız 10 üzerinden 20.. bu siparişi is...           1277  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>RESTAURANT_ID</th>\n      <th>all_comment</th>\n      <th>comment_count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>pizza-bulls-uskudar-altunizade-mah-istanbul</td>\n      <td>lezzeti eskisi gibi gelmedi bize. fark ödeyip ...</td>\n      <td>2293</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>pizza-bulls-uskudar-ferah-mah-istanbul</td>\n      <td>her şey çok güzeldi. elinize sağlık. hizli ve ...</td>\n      <td>1764</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>pizza-bulls-kartal-soganlik-yeni-mah-istanbul</td>\n      <td>cok pahali olmasi disinda bir problem yok gibi...</td>\n      <td>1743</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>pizza-bulls-umraniye-cakmak-mah-istanbul</td>\n      <td>çok lezzetli güvenle çoçuguma yedirebiliyorum ...</td>\n      <td>1582</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>pizza-bulls-atasehir-fetih-mah-istanbul</td>\n      <td>servis ve hız 10 üzerinden 20.. bu siparişi is...</td>\n      <td>1277</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    "sql_command = \"\"\"\n",
    "    WITH COMMENTS AS(\n",
    "    SELECT \"RESTAURANT_ID\",\n",
    "    STRING_AGG(LOWER(\"COMMENT_TEXT\"), ' ') AS ALL_COMMENT,\n",
    "    COUNT(\"COMMENT_TEXT\") AS COMMENT_COUNT\n",
    "    FROM \"ODS\".\"EXT_FB_COMMENT\" EFC\n",
    "    GROUP BY \"RESTAURANT_ID\"\n",
    "    )\n",
    "    SELECT * \n",
    "    FROM COMMENTS\n",
    "    ORDER BY COMMENT_COUNT DESC;\n",
    "    \"\"\"\n",
    "restaurant_df = pd.read_sql(sql_command,conn)\n",
    "restaurant_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def make_markov_model(cleaned_stories, n_gram=2):\n",
    "    markov_model = {}\n",
    "    for i in range(len(cleaned_stories)-n_gram-1):\n",
    "        curr_state, next_state = \"\", \"\"\n",
    "        for j in range(n_gram):\n",
    "            curr_state += cleaned_stories[i+j] + \" \"\n",
    "            next_state += cleaned_stories[i+j+n_gram] + \" \"\n",
    "        curr_state = curr_state[:-1]\n",
    "        next_state = next_state[:-1]\n",
    "        if curr_state not in markov_model:\n",
    "            markov_model[curr_state] = {}\n",
    "            markov_model[curr_state][next_state] = 1\n",
    "        else:\n",
    "            if next_state in markov_model[curr_state]:\n",
    "                markov_model[curr_state][next_state] += 1\n",
    "            else:\n",
    "                markov_model[curr_state][next_state] = 1\n",
    "    \n",
    "    # calculating transition probabilities\n",
    "    for curr_state, transition in markov_model.items():\n",
    "        total = sum(transition.values())\n",
    "        for state, count in transition.items():\n",
    "            markov_model[curr_state][state] = count/total\n",
    "        \n",
    "    return markov_model\n",
    "\n",
    "def generate_story(markov_model, limit=100, start='my god'):\n",
    "    n = 0\n",
    "    curr_state = start\n",
    "    next_state = None\n",
    "    story = \"\"\n",
    "    story+=curr_state+\" \"\n",
    "    while n<limit:\n",
    "        next_state = random.choices(list(markov_model[curr_state].keys()),\n",
    "                                    list(markov_model[curr_state].values()))\n",
    "        \n",
    "        curr_state = next_state[0]\n",
    "        story+=curr_state+\" \"\n",
    "        n+=1\n",
    "    return story"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.  yemek çok güzeldi semih beye çok teşekkür ederim hizliydi tesekkurler i̇lgileri ve kibarlıkları için teşekkürler sanırım ismi bilal idi yanlış hatırlıo da olabilirim çok teşekkürler i̇smini yanlis hatirliyor olabilirim ama bilal beye teşekkürler gerek hızı gerek lezzeti ile oldukça kaliteli bir firma \n1.  yemek çok lezzetliydi ve vaktinde geldi bilal beye ilgisinden ve ikramından dolayı ayrıca teşekkür ediyorum harika bir pizza deneyimi hızı ve güler yüzlü harikasınız sonsuza kadar sipariş vereceğim tek pizzacı burası tad on numara her şey çok güzeldi çok hızlı hem de \n2.  yemek çok güzeldi semih beye çok teşekkürler her şey çok güzeldi ama keşke sufleleri de gönderseydiniz alperen bey sagolsun pizza sufle cok guzeldi atacan bey e cok tesekkurler her zaman ki mükemmeldi emeğiniz icin teşekkür ederiz sanirim zincir pizzacilar arasında en iyisi \n3.  yemek çok güzeldi semih beye teşekkürler cok hizli ve saygiliydi kuryeniz mustafa beye nezaketi ve güleryüzü için teşekkürler atakan bey i̇lgi ve alakanız için tşekkür ederim i̇lginize teşekkürler blal bey i̇lk defa oluyor şaşırdık biz de kurye arkadaşa teşekkür ederim mutlu yıllar \n4.  yemek çok lezzetliydi ve hızlı ulaştı servisi yapan arkadaş ali gayet kibardı pizza beklediğimden lezzetliydi teşekkür ederiz deniz ürünlü pizzası bu bölgenin en iyisiydi diyebilirim özellikle kentuncky pizza birde nezaketiniz ve ikramınızdan dolayı teşekkür ederiz semih beye ikramı için de güzeldi harika \n5.  yemek çok lezzetliydi ve her şey harikaydı notlar okunmuştu ayrıca ikram için teşekkürler atakan beye çok teşekkür ederiz çok lezzetli ve çıtır çıtır ayrıca damla hanıma ilgisi için teşekkürler yarım saat olmadan sipariş sıcacık şekilde geldi süreçle ilgili ilgi ve alaka çok \n6.  yemek çok lezzetliydi ve getiren arkadasta cok hizli ve saygiliydi kuryeniz mustafa beye teşekkür ediyoruz her zamanki gibi çok güzel her sipasirimizde en az bir bazen de iki sefer hem hızlı hem de hijyenik teşekkürler hem pizzaları güzel hem de özeni için \n7.  yemek çok lezzetliydi ve her şey çok güzeldi ilgisi ve tatlı ikramı için ayrıca teşekkür ederiz ikram sufle için da atakan beye teşekkürler i̇lgisi için semih bey e ikram için arkadaşa tekrardan teşekkürler i̇lgi alaka ve hediye tatlı için teşekkürler özellikle kurye \n8.  yemek çok güzeldi semih beyin özel ilgisi için teşekkür ederim gayet guzeldi tesekkurler new york pizzasını denedim lezzetliydi kenar sos benlik değildi sanırım mayonezli bir sos pizza baharatı ve pizza gayet başarılıydı tavsiye ederim efsane lezzetin sıcacık ve lezzetliydi sufle ikramınız için \n9.  yemek çok güzeldi semih beyin özel ilgisi bu müthiş tadı ve hizmeti daha da değerli hale getirdi biraz geç geldi yaklaşık 1 saati buldu tadı yerindeydi çok hızlı geldi kurye cumali beye tatlı ikramı yapmak istiyoruz demeniz çok büyük incelik soğuk sufle \n10.  yemek çok güzeldi semih beyin özel ilgisi için teşekkür ederim çokmiyiyidi dumanı üstündeyken geliyor resmen bir de her şey için teşekkürler sıcak geldi lezzetli pizza bilal beyin ilgisine çok teşekkür ederiz kurye cumali beye teşekkürler çok hoş çok kötüydü tadı olsun malzemelerin \n11.  yemek çok lezzetliydi ve restoran bana çok yakın olmamasına rağmen sıcaktı da soğan halkaları da ayrıca güler yüzü çok memnun kaldık her zaman ki gibi 1010 bir pizzaydı paketler özenliydi çok hızlı ve çok lezzetliydi i̇lgilisi için öncelikle cumali beye teşekkürler çok \n12.  yemek çok lezzetliydi ve her şey çok güzeldi i̇kram için teşekkürler i̇lginiz ve güzel yüzünden dolayı özellikle çok teşekkür ederim mis mis mustafa beyin servisi çok iyiydi teşekkür ediyorum kendisine mükemmell öncelikle bilal bey size ayrıca teşekkür ederim pizza harikaydıı muhtesem pizza \n13.  yemek çok güzeldi semih bey harikasınız sıcak geldi jambon olmasin misir olsun demistim tersini yapmislar kralını bozar çok iyi lezzet ve çok soğuktu aç olmasaydım iade edecektim pizza çok güzeldi ayrıca yardımlarından dolayı altunizade bulls personeli bilal bey her şey olması gerektiği \n14.  yemek çok lezzetliydi ve kuriyeniz atakan bey çok nezaketliydi i̇kramımız için teşekkür ederim kolay gelsin her şey çok iyiydi patates pizza çıtır tavuk hepsi sıcacık gelmişti çok memnun etti ancak pizzanın lezzetine verdiğim puan tamamen pizza bullsa yöneliktir atakan beyin servisten memnun \n15.  yemek çok güzeldi semih bey harikasınız sıcak geldi atakana teşekkürler her zamanki gibi oldukça hızlı bir siparişti i̇kramınız için de teşekkür ederiz bilal bey herşey için sufleler harikaydı ayrıca atakan beye tatlı için teşekkürler 3 her zamanki gibi ellerinize sağlık lezzet ve \n16.  yemek çok lezzetliydi ve her şey güzeldi teşekkürler gerçekten çok kötüydü en kısa sürede geldi ve lezzetliydi tatlı ikramı için de ayrıca teşekkür ederim atakan beye ilgisinden dolayı teşekkür ederim çok hızlı ve güzeldi ellerinize sağlık sıcacık gelen pizzamız ve suflemiz için \n17.  yemek çok lezzetliydi ve vaktinde geldi bilal beye ilgisinden dolayi tesekkurler lezzetliydi ve getiren cumali beye teşekkür ederiz yemeksepetinde üsküdarın en iyi pizza demekten başka bir malzemenin yada pizza sosunun tadını alamadım i̇ki dilim yiyip bırakmak zorunda kaldım belki müsait değilim neden \n18.  yemek çok güzeldi semih beyin özel ilgisi bu müthiş tadı ve hizmeti daha da sipariş vermem bullstan çok teşekkür ederiz lezzetli ve hızlı geliyor lezzeti de gayet tatmin edicidir buffalo sos yerine barbekü sos geldi onu istesem o şekilde sipariş verirdim zaten \n19.  yemek çok lezzetliydi ve hızlıydı tesekkurler çok hızlı sıcacık geldi yemeğimiz üstelik yola çıkmadan önce arayıp bilgi verdi ayrica ikram olarak 2 sufle yolladi hiz ve lezzet 10 numaraydi bilal beye ilgileri ve ikramlari icin cok tesekkurler her seyiyle on numara her \n"
     ]
    }
   ],
   "source": [
    "restaurant_df['clean_comment'] = restaurant_df['all_comment'].apply(clean_text)\n",
    "text = restaurant_df.loc[0]['clean_comment'].split()\n",
    "\n",
    "markov_model = make_markov_model(text)\n",
    "\n",
    "for i in range(20):\n",
    "    print(str(i)+\". \", generate_story(markov_model, start=\"yemek çok\", limit=20))"
   ]
  },
  {
   "source": [
    "# Sources\n",
    "\n",
    " 1. [Selenium Documentation](https://selenium-python.readthedocs.io/)\n",
    " 2. [Selenium choose element by partial id](https://stackoverflow.com/questions/15845563/choose-element-by-partial-id-using-selenium-with-python)\n",
    " 3. [Selenium scroll down to end of the page](https://pythonbasics.org/selenium-scroll-down/)\n",
    " 4. [Selenium click button](https://stackoverflow.com/questions/52405456/selenium-how-to-click-on-javascript-button/52405550)\n",
    " 5. [Markov Chains](https://www.kaggle.com/orion99/markov-chain-nlp)\n",
    " 6. [Bag of Words](https://github.com/Suji04/NormalizedNerd/blob/master/Introduction%20to%20NLP/Bag%20of%20Words%20%2B%20TF-IDF.ipynb)\n",
    " 7. [Turkish Porter Stemmer](https://github.com/otuncelli/turkish-stemmer-python)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}