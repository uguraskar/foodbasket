{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.0 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "0e8f02916ce4ec57490847cc8c54c12a9dae65680be9326a3269d9b7a61d6d19"
   }
  },
  "interpreter": {
   "hash": "0e8f02916ce4ec57490847cc8c54c12a9dae65680be9326a3269d9b7a61d6d19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Web Scraping"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv(\"dev.env\")\n",
    "import os\n",
    "\n",
    "db_name = os.getenv(\"db_name\")\n",
    "db_username = os.getenv(\"db_username\")\n",
    "db_password = os.getenv(\"db_password\")\n",
    "db_host = os.getenv(\"db_host\")\n",
    "db_port = os.getenv(\"db_port\")\n",
    "website = os.getenv(\"website\")\n",
    "city_link = os.getenv(\"city_link\")\n",
    "chrome_path = os.getenv(\"chrome_path\")\n",
    "selenium_chrome_driver_path = os.getenv(\"selenium_chrome_driver_path\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import time\n",
    "import math\n",
    "import numpy as np\n",
    "import os.path\n",
    "import pandas as pd\n",
    "import re\n",
    "import pycld2\n",
    "import nltk\n",
    "import joblib\n",
    "import warnings\n",
    "import urllib.request\n",
    "import io\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from datetime import date, timedelta, datetime\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By \n",
    "from selenium.webdriver.support.ui import WebDriverWait \n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from nltk.corpus import stopwords\n",
    "from TurkishStemmer import TurkishStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from PIL import Image\n",
    "from keras.utils import np_utils\n",
    "from keras.layers.core import Dense, Activation, Dropout, Flatten\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from keras.optimizers import SGD, RMSprop\n",
    "from keras.utils import np_utils\n",
    "from sklearn import metrics\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "nltk.download('stopwords', quiet=True)\n",
    "\n",
    "stemmer = TurkishStemmer()\n",
    "\n",
    "conn_string = 'host={pghost} port={pgport} dbname={pgdatabase} user={pguser} password={pgpassword}'.format(pgdatabase=db_name,pguser=db_username,pgpassword=db_password,pghost=db_host,pgport=db_port)\n",
    "conn=psycopg2.connect(conn_string)\n",
    "cur=conn.cursor()\n",
    "\n",
    "options = Options()\n",
    "options.binary_location = chrome_path\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def check_if_table_exists(schema,table):\n",
    "    cur.execute(\"select exists(select * from information_schema.tables where table_schema='{schema}' AND table_name='{table}')\".format(schema=schema, table=table))\n",
    "    return cur.fetchone()[0]\n",
    "\n",
    "def check_if_index_exists(index):\n",
    "    cur.execute(\"SELECT EXISTS(SELECT * FROM PG_CLASS WHERE relname = '{index}')\".format(index=index))\n",
    "    return cur.fetchone()[0]\n",
    "\n",
    "def check_if_file_exists(filename):\n",
    "    return os.path.isfile(filename)\n",
    "\n",
    "def execute_mogrify(conn, df, schema, table):\n",
    "    tuples = [tuple(x) for x in df.to_numpy()]\n",
    "    cols = '\"'+'\",\"'.join(list(df.columns))+'\"'\n",
    "    cursor = conn.cursor()    \n",
    "    try:\n",
    "        for tup in tuples:\n",
    "            query  = \"\"\"INSERT INTO \"{schema}\".\"{table}\"({cols}) VALUES ({values}) ON CONFLICT DO NOTHING\"\"\".format(schema=schema,table=table, cols=cols, values=\",\".join(map(str,tup)))\n",
    "            cursor.execute(query)\n",
    "            conn.commit()\n",
    "    except (Exception, psycopg2.DatabaseError) as error:\n",
    "        print(\"Error: %s\" % error)\n",
    "        conn.rollback()\n",
    "        cursor.close()\n",
    "        return 1\n",
    "    cursor.close()\n",
    "\n",
    "def df_column_conversation(df, column_name, type):\n",
    "    if(type == 'timestamp'):\n",
    "        df[column_name] = df[column_name].apply(lambda x: f\"'{x}'::timestamp\")\n",
    "    if(type == 'text'):\n",
    "        df[column_name] = df[column_name].str.replace(\"'\",\"\").apply(lambda x: f\"'{x}'\")\n",
    "    if(type == 'date'):\n",
    "        df[column_name] = df[column_name].apply(lambda x: f\"'{x}'::date\")\n",
    "    if(type == 'numeric'):\n",
    "        df[column_name] = df[column_name].apply(str).str.replace(',','.')\n",
    "    if(type == 'integer'):\n",
    "        df[column_name] = df[column_name].apply(str).str.replace(',','.').apply(float).astype('Int64').apply(str)\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"[,.\\\"\\'!@#$%^&*(){}?/;`~:<>+=-\\\\]\", \"\", text)\n",
    "    return text\n",
    "\n",
    "def webpage_scroll_down(driver, scroll_speed):\n",
    "    total_height = int(driver.execute_script(\"return document.body.scrollHeight\"))\n",
    "    for i in range(1, total_height, scroll_speed):\n",
    "        driver.execute_script(\"window.scrollTo(0, {});\".format(i))\n",
    "\n",
    "def byte_image_to_numpy_array(byte_image, image_size):\n",
    "    return cv2.resize(np.array(Image.open(io.BytesIO(byte_image))), (image_size, image_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Table ODS.EXT_FB_RESTAURANT already exists.\nTable ODS.EXT_FB_MENU already exists.\nTable ODS.EXT_FB_COMMENT already exists.\nTable ODS.EXT_FB_PRODUCT_IMAGE already exists.\nTable ODS.EXT_FB_PRODUCT_IMAGE_SOURCE already exists.\nTable EDW.DWH_FB_COMMENT already exists.\n"
     ]
    }
   ],
   "source": [
    "if(check_if_table_exists('ODS','EXT_FB_RESTAURANT')):\n",
    "    print('Table ODS.EXT_FB_RESTAURANT already exists.')   \n",
    "else:\n",
    "    start_time = math.trunc(time.time())\n",
    "    cur.execute(\"\"\"\n",
    "    CREATE TABLE \"ODS\".\"EXT_FB_RESTAURANT\"\n",
    "    (\n",
    "    \"RESTAURANT_ID\" text NOT NULL,\n",
    "    \"RESTAURANT_NAME\" text,\n",
    "    \"RESTAURANT_LINK\" text,\n",
    "    \"DATE\" date,    \n",
    "    CONSTRAINT \"RESTAURANT_ID\" UNIQUE (\"RESTAURANT_ID\")\n",
    "    );\n",
    "    \"\"\")\n",
    "    cur.execute('COMMIT;')\n",
    "    end_time = math.trunc(time.time())\n",
    "    print(\"Table ODS.EXT_FB_RESTAURANT created in {execute_time} seconds.\".format(execute_time=end_time-start_time))\n",
    "\n",
    "if(check_if_table_exists('ODS','EXT_FB_MENU')):\n",
    "    print('Table ODS.EXT_FB_MENU already exists.')   \n",
    "else:\n",
    "    start_time = math.trunc(time.time())\n",
    "    cur.execute(\"\"\"\n",
    "    CREATE TABLE \"ODS\".\"EXT_FB_MENU\"\n",
    "    (\n",
    "    \"PRODUCT_ID\" text NOT NULL,\n",
    "    \"RESTAURANT_ID\" text,\n",
    "    \"CATEGORY_NAME\" text,\n",
    "    \"PRODUCT_NAME\" text,\n",
    "    \"PRODUCT_DESCRIPTION\" text,\n",
    "    \"PRODUCT_LISTED_PRICE\" text,\n",
    "    \"PRODUCT_PRICE\" text,\n",
    "    \"DISCOUNT\" boolean,\n",
    "    \"DESIGN_TYPE\" text,\n",
    "    \"DATE\" date,\n",
    "    CONSTRAINT \"PRODUCT_ID\" UNIQUE (\"PRODUCT_ID\")\n",
    "    );\n",
    "    \"\"\")\n",
    "    cur.execute('COMMIT;')\n",
    "    end_time = math.trunc(time.time())\n",
    "    print(\"Table ODS.EXT_FB_MENU created in {execute_time} seconds.\".format(execute_time=end_time-start_time))\n",
    "\n",
    "if(check_if_table_exists('ODS','EXT_FB_COMMENT')):\n",
    "    print('Table ODS.EXT_FB_COMMENT already exists.')   \n",
    "else:\n",
    "    start_time = math.trunc(time.time())\n",
    "    cur.execute(\"\"\"\n",
    "    CREATE TABLE \"ODS\".\"EXT_FB_COMMENT\"\n",
    "    (\n",
    "    \"RESTAURANT_ID\" text,\n",
    "    \"USERNAME\" text,\n",
    "    \"COMMENT_TEXT\" text,\n",
    "    \"COMMENT_DATE\" text,\n",
    "    \"SPEED\" text,\n",
    "    \"SERVING\" text,\n",
    "    \"FLAVOUR\" text,\n",
    "    \"DATE\" date,\n",
    "    CONSTRAINT \"UNIQUE_COMMENTS\" UNIQUE (\"RESTAURANT_ID\", \"USERNAME\", \"COMMENT_TEXT\")\n",
    "    );\n",
    "    \"\"\")\n",
    "    cur.execute('COMMIT;')\n",
    "    end_time = math.trunc(time.time())\n",
    "    print(\"Table ODS.EXT_FB_COMMENT created in {execute_time} seconds.\".format(execute_time=end_time-start_time))\n",
    "\n",
    "if(check_if_table_exists('ODS','EXT_FB_PRODUCT_IMAGE')):\n",
    "    print('Table ODS.EXT_FB_PRODUCT_IMAGE already exists.')   \n",
    "else:\n",
    "    start_time = math.trunc(time.time())\n",
    "    cur.execute(\"\"\"\n",
    "    CREATE TABLE \"ODS\".\"EXT_FB_PRODUCT_IMAGE\"\n",
    "    (\n",
    "    \"PRODUCT_ID\" text,\n",
    "    \"RESTAURANT_ID\" text,\n",
    "    \"IMAGE_LINK\" text,\n",
    "    \"DATE\" date,\n",
    "    CONSTRAINT \"UNIQUE_IMAGES\" UNIQUE (\"PRODUCT_ID\", \"RESTAURANT_ID\")\n",
    "    );\n",
    "    \"\"\")\n",
    "    cur.execute('COMMIT;')\n",
    "    end_time = math.trunc(time.time())\n",
    "    print(\"Table ODS.EXT_FB_PRODUCT_IMAGE created in {execute_time} seconds.\".format(execute_time=end_time-start_time))\n",
    "\n",
    "if(check_if_table_exists('ODS','EXT_FB_PRODUCT_IMAGE_SOURCE')):\n",
    "    print('Table ODS.EXT_FB_PRODUCT_IMAGE_SOURCE already exists.')   \n",
    "else:\n",
    "    start_time = math.trunc(time.time())\n",
    "    cur.execute(\"\"\"\n",
    "    CREATE TABLE \"ODS\".\"EXT_FB_PRODUCT_IMAGE_SOURCE\"\n",
    "    (\n",
    "    \"IMAGE_LINK\" text NOT NULL,\n",
    "    \"SOURCE\" bytea,\n",
    "    CONSTRAINT \"UNIQUE_SOURCE\" PRIMARY KEY (\"IMAGE_LINK\")\n",
    "    );\n",
    "    \"\"\")\n",
    "    cur.execute('COMMIT;')\n",
    "    end_time = math.trunc(time.time())\n",
    "    print(\"Table ODS.EXT_FB_PRODUCT_IMAGE_SOURCE created in {execute_time} seconds.\".format(execute_time=end_time-start_time))\n",
    "\n",
    "if(check_if_table_exists('EDW','DWH_FB_COMMENT')):\n",
    "    print('Table EDW.DWH_FB_COMMENT already exists.')   \n",
    "else:\n",
    "    start_time = math.trunc(time.time())\n",
    "    cur.execute(\"\"\"\n",
    "    CREATE TABLE \"EDW\".\"DWH_FB_COMMENT\"\n",
    "    (\n",
    "    \"RESTAURANT_ID\" text,\n",
    "    \"USERNAME\" text,\n",
    "    \"COMMENT_TEXT\" text,\n",
    "    \"COMMENT_DATE\" date,\n",
    "    \"SPEED\" integer,\n",
    "    \"SERVING\" integer,\n",
    "    \"FLAVOUR\" integer,\n",
    "    \"DATE\" date,\n",
    "    CONSTRAINT \"UNIQUE_COMMENTS\" UNIQUE (\"RESTAURANT_ID\", \"USERNAME\", \"COMMENT_TEXT\")\n",
    "    );\n",
    "    \"\"\")\n",
    "    cur.execute('COMMIT;')\n",
    "    end_time = math.trunc(time.time())\n",
    "    print(\"Table EDW.DWH_FB_COMMENT created in {execute_time} seconds.\".format(execute_time=end_time-start_time))\n",
    "\n",
    "cur.execute(\"\"\"\n",
    "CREATE OR REPLACE FUNCTION public.try_cast(_in text, INOUT _out anyelement)\n",
    "    LANGUAGE 'plpgsql'\n",
    "AS $BODY$\n",
    "BEGIN\n",
    "   EXECUTE format('SELECT %L::%s', $1, pg_typeof(_out))\n",
    "   INTO  _out;\n",
    "EXCEPTION WHEN others THEN\n",
    "   -- do nothing: _out already carries default\n",
    "END\n",
    "$BODY$;\n",
    "\"\"\")\n",
    "cur.execute('COMMIT;')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "datetime.date(2021, 6, 11)"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "cur.execute(\"\"\"\n",
    "WITH DATES AS(\n",
    "SELECT \n",
    "MAX(\"DATE\") AS \"DATE\"\n",
    "FROM \"ODS\".\"EXT_FB_MENU\" EFM\n",
    "UNION ALL\n",
    "SELECT \n",
    "MAX(\"DATE\") AS \"DATE\"\n",
    "FROM \"ODS\".\"EXT_FB_COMMENT\" EFC\n",
    ")\n",
    "SELECT \n",
    "MAX(\"DATE\") AS \"LAST_EXECUTION_DATE\"\n",
    "FROM DATES;\n",
    "\"\"\")\n",
    "last_execution_date = cur.fetchone()[0]\n",
    "last_execution_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "restaurant_list = []\n",
    "end_date = min(date(2021,6,11),(date.today() - timedelta(days=1)))\n",
    "\n",
    "driver = webdriver.Chrome(options=options, executable_path=selenium_chrome_driver_path)\n",
    "if(last_execution_date < end_date):\n",
    "    driver.get(city_link)\n",
    "    time.sleep(5)\n",
    "    for i in range(25):\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(2)\n",
    "    city_restaurant_groups = driver.find_elements_by_class_name(\"restaurant-main-info\")\n",
    "    for restaurant in city_restaurant_groups:\n",
    "        restaurant_name = restaurant.find_element_by_class_name(\"restaurant-display-name\").text\n",
    "        restaurant_name = restaurant_name.replace(\"YENİ \", \"\")\n",
    "        restaurant_link = restaurant.find_element_by_class_name(\"restaurant-display-name\").find_element_by_xpath(\".//a\").get_attribute('href')\n",
    "        restaurant_id = restaurant_link.split(\"/\")[-1]\n",
    "        if(len(restaurant_link) < 2):\n",
    "            continue\n",
    "        restaurant_list.append([restaurant_id,restaurant_name,restaurant_link])\n",
    "    restaurant_df = pd.DataFrame(restaurant_list, columns=[\"RESTAURANT_ID\",\"RESTAURANT_NAME\",\"RESTAURANT_LINK\"])\n",
    "\n",
    "    df_column_conversation(restaurant_df, 'RESTAURANT_ID', 'text')\n",
    "    df_column_conversation(restaurant_df, 'RESTAURANT_NAME', 'text')\n",
    "    df_column_conversation(restaurant_df, 'RESTAURANT_LINK', 'text')    \n",
    "    restaurant_df['DATE'] = \"'\"+ datetime.strftime(date.today(), \"%Y-%m-%d\") + \"'::date\"\n",
    "    execute_mogrify(conn,restaurant_df,\"ODS\",\"EXT_FB_RESTAURANT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_command = \"\"\"\n",
    "    SELECT\n",
    "    \"RESTAURANT_ID\"\n",
    "    FROM \"ODS\".\"EXT_FB_RESTAURANT\" EFR\n",
    "    WHERE 1=1\n",
    "    AND NOT EXISTS(SELECT NULL FROM \"ODS\".\"EXT_FB_MENU\" EFM WHERE EFR.\"RESTAURANT_ID\" = EFM.\"RESTAURANT_ID\");\n",
    "    \"\"\"\n",
    "restaurant_df = pd.read_sql(sql_command,conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(last_execution_date < end_date):\n",
    "    for i in range(len(restaurant_df)):\n",
    "        sublink = restaurant_df.loc[i,\"RESTAURANT_ID\"]\n",
    "        restaurant_link = \"{website}/{sublink}\".format(website=website,sublink=sublink)\n",
    "        \n",
    "        driver.get(restaurant_link)\n",
    "        time.sleep(5)\n",
    "\n",
    "        try:\n",
    "            if(\"sipariş verebilirsiniz.\" in driver.find_element_by_xpath('//*[@id=\"restaurantDetail\"]/div/div[2]/h3').text):\n",
    "                continue\n",
    "            else:\n",
    "                pass\n",
    "        except Exception:\n",
    "            pass\n",
    "        \n",
    "        menu = driver.find_element_by_xpath('//*[@id=\"restaurant_menu\"]')\n",
    "        categories = menu.find_elements_by_xpath('//*[contains(@id,\"menu_\")]')\n",
    "\n",
    "        menu_list = []\n",
    "\n",
    "        for category in categories:\n",
    "            category_name = category.find_element_by_xpath(\".//b\").text\n",
    "            for product in category.find_elements_by_xpath(\".//div[2]/ul/li\"):\n",
    "                try:\n",
    "                    design_type = \"list\"\n",
    "                    try:\n",
    "                        product_id = product.find_elements_by_class_name(\"getProductDetail\")[-1].get_attribute('data-product-id')\n",
    "                        product_name = product.find_elements_by_class_name(\"getProductDetail\")[-1].text\n",
    "                    except:\n",
    "                        product_id = product.find_element_by_xpath(\".//strong\").get_attribute('data-product-id')\n",
    "                        product_name = product.find_element_by_xpath(\".//strong\").text\n",
    "                        design_type = \"card\"\n",
    "                    try:\n",
    "                        product_description = product.find_element_by_class_name(\"product-desc\").text\n",
    "                        product_price = product.find_element_by_class_name(\"price\").text    \n",
    "                    except:\n",
    "                        product_description = product.find_element_by_class_name(\"productInfo\").text\n",
    "                        product_price = product.find_element_by_class_name(\"newPrice\").text\n",
    "                        if(not(design_type==\"card\")):\n",
    "                            design_type = \"box\"\n",
    "                    discount = \"TRUE\"\n",
    "                    try:              \n",
    "                        if(design_type==\"list\"):\n",
    "                            product_listed_price = product.find_element_by_class_name(\"listed-price\").text\n",
    "                        if(design_type in [\"card\",\"box\"]):\n",
    "                            product_listed_price = product.find_element_by_class_name(\"listedPrice\").text\n",
    "                    except:\n",
    "                        product_listed_price = product_price\n",
    "                        discount = \"FALSE\"\n",
    "                    menu_list.append([product_id,sublink,category_name,product_name,product_description,product_listed_price,product_price,discount,design_type])\n",
    "                except:\n",
    "                    continue\n",
    "        menu_df = pd.DataFrame(menu_list, columns=[\"PRODUCT_ID\",\"RESTAURANT_ID\",\"CATEGORY_NAME\",\"PRODUCT_NAME\",\"PRODUCT_DESCRIPTION\",\"PRODUCT_LISTED_PRICE\",\"PRODUCT_PRICE\",\"DISCOUNT\",\"DESIGN_TYPE\"])    \n",
    "        menu_df = menu_df[menu_df['PRODUCT_ID'].str.len() > 0]\n",
    "        menu_df = menu_df[menu_df['PRODUCT_NAME'].str.len() > 0]\n",
    "\n",
    "        df_column_conversation(menu_df, 'PRODUCT_ID', 'text')\n",
    "        df_column_conversation(menu_df, 'RESTAURANT_ID', 'text')\n",
    "        df_column_conversation(menu_df, 'CATEGORY_NAME', 'text')\n",
    "        df_column_conversation(menu_df, 'PRODUCT_NAME', 'text')\n",
    "        df_column_conversation(menu_df, 'PRODUCT_DESCRIPTION', 'text')\n",
    "        df_column_conversation(menu_df, 'PRODUCT_LISTED_PRICE', 'text')\n",
    "        df_column_conversation(menu_df, 'PRODUCT_PRICE', 'text')\n",
    "        df_column_conversation(menu_df, 'DESIGN_TYPE', 'text')\n",
    "        menu_df['DATE'] = \"'\"+ datetime.strftime(date.today(), \"%Y-%m-%d\") + \"'::date\"\n",
    "        execute_mogrify(conn,menu_df,\"ODS\",\"EXT_FB_MENU\")\n",
    "    menu_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                        RESTAURANT_ID\n",
       "40            nisantasi-22-sisli-harbiye-mah-istanbul\n",
       "73         ice-munchies-avcilar-cihangir-mah-istanbul\n",
       "45   calderon-restaurant-besiktas-levent-mah-istanbul\n",
       "47        pizza-2m-kadikoy-caferaga-mah-moda-istanbul\n",
       "38        pasaport-pizza-maltepe-cevizli-mah-istanbul\n",
       "..                                                ...\n",
       "8   coffee-la-rue-restaurant-umraniye-yukari-dudul...\n",
       "71  caffe-di-dosso-dossi-fatih-aksemsettin-mah-ist...\n",
       "21      familys-cafe-eyup-gokturk-merkez-mah-istanbul\n",
       "6               bigs-pizza-tuzla-aydinli-mah-istanbul\n",
       "65  gardenia-burger-pizza-makarna-sariyer-maslak-m...\n",
       "\n",
       "[79 rows x 1 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>RESTAURANT_ID</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>40</th>\n      <td>nisantasi-22-sisli-harbiye-mah-istanbul</td>\n    </tr>\n    <tr>\n      <th>73</th>\n      <td>ice-munchies-avcilar-cihangir-mah-istanbul</td>\n    </tr>\n    <tr>\n      <th>45</th>\n      <td>calderon-restaurant-besiktas-levent-mah-istanbul</td>\n    </tr>\n    <tr>\n      <th>47</th>\n      <td>pizza-2m-kadikoy-caferaga-mah-moda-istanbul</td>\n    </tr>\n    <tr>\n      <th>38</th>\n      <td>pasaport-pizza-maltepe-cevizli-mah-istanbul</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>coffee-la-rue-restaurant-umraniye-yukari-dudul...</td>\n    </tr>\n    <tr>\n      <th>71</th>\n      <td>caffe-di-dosso-dossi-fatih-aksemsettin-mah-ist...</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>familys-cafe-eyup-gokturk-merkez-mah-istanbul</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>bigs-pizza-tuzla-aydinli-mah-istanbul</td>\n    </tr>\n    <tr>\n      <th>65</th>\n      <td>gardenia-burger-pizza-makarna-sariyer-maslak-m...</td>\n    </tr>\n  </tbody>\n</table>\n<p>79 rows × 1 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "sql_command = \"\"\"\n",
    "    SELECT\n",
    "    \"RESTAURANT_ID\"\n",
    "    FROM \"ODS\".\"EXT_FB_RESTAURANT\" EFR\n",
    "    WHERE 1=1\n",
    "    AND NOT EXISTS(SELECT NULL FROM \"ODS\".\"EXT_FB_COMMENT\" EFC WHERE EFR.\"RESTAURANT_ID\" = EFC.\"RESTAURANT_ID\");\n",
    "    \"\"\"\n",
    "restaurant_df = pd.read_sql(sql_command,conn)\n",
    "restaurant_df = restaurant_df.sample(frac=1)\n",
    "restaurant_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(last_execution_date < end_date):\n",
    "    for i in range(len(restaurant_df)):\n",
    "        sublink = restaurant_df.loc[i,\"RESTAURANT_ID\"]\n",
    "        last_comment_page_url = \"{website}/{sublink}?section=comments&page=9999\".format(website=website,sublink=sublink)\n",
    "        \n",
    "        driver.get(last_comment_page_url)\n",
    "        time.sleep(0.1)\n",
    "\n",
    "        comments_list = []\n",
    "        \n",
    "        if(sublink not in driver.current_url):\n",
    "            continue\n",
    "\n",
    "        last_comment_page_redirect_url = driver.current_url\n",
    "        last_comment_page_number = int(last_comment_page_redirect_url.replace(\"&status=closed\",\"\").replace(\"{website}/{sublink}?section=comments&page=\".format(website=website,sublink=sublink),\"\"))\n",
    "\n",
    "        for page_number in range(1, last_comment_page_number+1):\n",
    "            current_comment_page_url = \"{website}/{sublink}?section=comments&page={page_number}\".format(website=website,sublink=sublink,page_number=page_number)\n",
    "            driver.get(current_comment_page_url)\n",
    "            time.sleep(1)\n",
    "\n",
    "            try:\n",
    "                if(\"sipariş verebilirsiniz.\" in driver.find_element_by_xpath('//*[@id=\"restaurantDetail\"]/div/div[2]/h3').text):\n",
    "                    continue\n",
    "                else:\n",
    "                    pass\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "            try:\n",
    "                driver.find_element(By.XPATH, '//*[@id=\"alternative-restaurant-popup\"]/div[1]/div[2]/img').click(); #Closing pop-up\n",
    "            except Exception:\n",
    "                pass   \n",
    "\n",
    "            #driver.find_element(By.XPATH, '//*[@id=\"restaurantDetail\"]/div[2]/div[1]/ul/li[4]/a').click(); #Clicking comments\n",
    "\n",
    "            comment_list = driver.find_elements_by_class_name(\"comments-body\")\n",
    "        \n",
    "            for comment in comment_list:\n",
    "                try:\n",
    "                    username = comment.find_element_by_class_name(\"userName\").text\n",
    "                    comment_text = comment.find_element_by_xpath('.//p').text\n",
    "                    comment_date = comment.find_element_by_class_name(\"commentDate\").text\n",
    "                except NoSuchElementException:\n",
    "                    continue\n",
    "                try:\n",
    "                    speed = comment.find_element_by_class_name(\"speed\").text\n",
    "                except NoSuchElementException:\n",
    "                    speed = \"\"\n",
    "                try:                    \n",
    "                    serving = comment.find_element_by_class_name(\"serving\").text\n",
    "                except NoSuchElementException:\n",
    "                    serving = \"\"\n",
    "                try:\n",
    "                    flavour = comment.find_element_by_class_name(\"flavour\").text \n",
    "                except NoSuchElementException:\n",
    "                    flavour = \"\"\n",
    "                comments_list.append([sublink, username, comment_text, comment_date, speed, serving, flavour])\n",
    "        comment_df = pd.DataFrame(comments_list, columns=[\"RESTAURANT_ID\",\"USERNAME\",\"COMMENT_TEXT\",\"COMMENT_DATE\",\"SPEED\",\"SERVING\",\"FLAVOUR\"])\n",
    "        df_column_conversation(comment_df, 'RESTAURANT_ID', 'text')\n",
    "        df_column_conversation(comment_df, 'USERNAME', 'text')\n",
    "        df_column_conversation(comment_df, 'COMMENT_TEXT', 'text')\n",
    "        df_column_conversation(comment_df, 'COMMENT_DATE', 'text')\n",
    "        df_column_conversation(comment_df, 'SPEED', 'text')\n",
    "        df_column_conversation(comment_df, 'SERVING', 'text')\n",
    "        df_column_conversation(comment_df, 'FLAVOUR', 'text')\n",
    "        comment_df['DATE'] = \"'\"+ datetime.strftime(date.today(), \"%Y-%m-%d\") + \"'::date\"\n",
    "        execute_mogrify(conn,comment_df,\"ODS\",\"EXT_FB_COMMENT\")\n",
    "    comment_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                         RESTAURANT_ID DESIGN_TYPE\n",
       "0     the-boss-pizza-burger-sariyer-maden-mah-istanbul        card\n",
       "1            444-pizza-bagcilar-demirkapi-mah-istanbul        card\n",
       "2    mezzaluna-paket-beykoz-acarlar-mah-acarkent-is...        card\n",
       "3    kafein-plus-kucukcekmece-tevfikbey-mah-sefakoy...        card\n",
       "4                   mayk-cafe-sisli-fulya-mah-istanbul        card\n",
       "..                                                 ...         ...\n",
       "208  amigos-burger-pizza-kagithane-merkez-mah-istanbul        card\n",
       "209            konak-firin-avcilar-merkez-mah-istanbul        card\n",
       "210  keyifle-pide-lahmacun-bakirkoy-atakoy-6-kisim-...        card\n",
       "211           havelka-kadikoy-caddebostan-mah-istanbul        card\n",
       "212            heros-pizza-esenyurt-fatih-mah-istanbul        card\n",
       "\n",
       "[213 rows x 2 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>RESTAURANT_ID</th>\n      <th>DESIGN_TYPE</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>the-boss-pizza-burger-sariyer-maden-mah-istanbul</td>\n      <td>card</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>444-pizza-bagcilar-demirkapi-mah-istanbul</td>\n      <td>card</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>mezzaluna-paket-beykoz-acarlar-mah-acarkent-is...</td>\n      <td>card</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>kafein-plus-kucukcekmece-tevfikbey-mah-sefakoy...</td>\n      <td>card</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>mayk-cafe-sisli-fulya-mah-istanbul</td>\n      <td>card</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>208</th>\n      <td>amigos-burger-pizza-kagithane-merkez-mah-istanbul</td>\n      <td>card</td>\n    </tr>\n    <tr>\n      <th>209</th>\n      <td>konak-firin-avcilar-merkez-mah-istanbul</td>\n      <td>card</td>\n    </tr>\n    <tr>\n      <th>210</th>\n      <td>keyifle-pide-lahmacun-bakirkoy-atakoy-6-kisim-...</td>\n      <td>card</td>\n    </tr>\n    <tr>\n      <th>211</th>\n      <td>havelka-kadikoy-caddebostan-mah-istanbul</td>\n      <td>card</td>\n    </tr>\n    <tr>\n      <th>212</th>\n      <td>heros-pizza-esenyurt-fatih-mah-istanbul</td>\n      <td>card</td>\n    </tr>\n  </tbody>\n</table>\n<p>213 rows × 2 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "sql_command = \"\"\"\n",
    "    SELECT DISTINCT \n",
    "    \"RESTAURANT_ID\",\n",
    "    \"DESIGN_TYPE\"\n",
    "    FROM \"ODS\".\"EXT_FB_MENU\" EFM\n",
    "    WHERE 1=1\n",
    "    AND EFM.\"DESIGN_TYPE\" <> 'list'\n",
    "    AND NOT EXISTS(SELECT NULL FROM \"ODS\".\"EXT_FB_PRODUCT_IMAGE\" EFPI WHERE EFM.\"RESTAURANT_ID\" = EFPI.\"RESTAURANT_ID\");\n",
    "    \"\"\"\n",
    "restaurant_df = pd.read_sql(sql_command,conn)\n",
    "restaurant_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(last_execution_date < end_date):\n",
    "    for i in range(len(restaurant_df)):\n",
    "        sublink = restaurant_df.loc[i,\"RESTAURANT_ID\"]\n",
    "        design_type = restaurant_df.loc[i,\"DESIGN_TYPE\"]\n",
    "        page_url = \"{website}/{sublink}\".format(website=website,sublink=sublink)\n",
    "\n",
    "        driver.get(page_url)\n",
    "        time.sleep(0.1)\n",
    "        \n",
    "        webpage_scroll_down(driver, 15)\n",
    "\n",
    "        if(sublink not in driver.current_url):\n",
    "                continue\n",
    "\n",
    "        try:\n",
    "            if(\"sipariş verebilirsiniz.\" in driver.find_element_by_xpath('//*[@id=\"restaurantDetail\"]/div/div[2]/h3').text):\n",
    "                continue\n",
    "            else:\n",
    "                pass\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "        try:\n",
    "            driver.find_element(By.XPATH, '//*[@id=\"alternative-restaurant-popup\"]/div[1]/div[2]/img').click(); #Closing pop-up\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "        menu = driver.find_element_by_xpath('//*[@id=\"restaurant_menu\"]')\n",
    "        categories = menu.find_elements_by_xpath('//*[contains(@id,\"menu_\")]')\n",
    "\n",
    "        image_list = []\n",
    "\n",
    "        for product in menu.find_elements_by_class_name(\"product-image\"):\n",
    "            try:\n",
    "                product_id = product.get_attribute('data-product-id')\n",
    "                image_link = product.find_element_by_xpath(\".//img\").get_attribute('src')\n",
    "                if(\"www.yemeksepeti.com/assets/images/\" in image_link):\n",
    "                    continue\n",
    "                image_list.append([product_id,sublink,image_link])\n",
    "            except:\n",
    "                pass\n",
    "        image_df = pd.DataFrame(image_list, columns=[\"PRODUCT_ID\",\"RESTAURANT_ID\",\"IMAGE_LINK\"])\n",
    "        df_column_conversation(image_df, 'PRODUCT_ID', 'text')\n",
    "        df_column_conversation(image_df, 'RESTAURANT_ID', 'text')\n",
    "        df_column_conversation(image_df, 'IMAGE_LINK', 'text')    \n",
    "        image_df['DATE'] = \"'\"+ datetime.strftime(date.today(), \"%Y-%m-%d\") + \"'::date\"\n",
    "        execute_mogrify(conn,image_df,\"ODS\",\"EXT_FB_PRODUCT_IMAGE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                          IMAGE_LINK\n",
       "0  https://cdn.yemeksepeti.com/ProductImages/TR_I..."
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>IMAGE_LINK</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>https://cdn.yemeksepeti.com/ProductImages/TR_I...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "sql_command = \"\"\"\n",
    "    SELECT DISTINCT\n",
    "    \"IMAGE_LINK\"\n",
    "    FROM \"ODS\".\"EXT_FB_PRODUCT_IMAGE\" EFPI\n",
    "    WHERE 1=1\n",
    "    AND NOT EXISTS(SELECT NULL FROM \"ODS\".\"EXT_FB_PRODUCT_IMAGE_SOURCE\" EFPIS WHERE EFPIS.\"IMAGE_LINK\" = EFPI.\"IMAGE_LINK\");\n",
    "    \"\"\"\n",
    "image_df = pd.read_sql(sql_command,conn)\n",
    "image_df = image_df.sample(frac=1).reset_index(drop=True)\n",
    "image_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(image_df)):\n",
    "    page_url = image_df.loc[i,\"IMAGE_LINK\"]\n",
    "    image_file_name = \"images/product.jpg\"\n",
    "    try:\n",
    "        urllib.request.urlretrieve(page_url, image_file_name)\n",
    "    except:\n",
    "        continue\n",
    "    image_binary = psycopg2.Binary(open(image_file_name, 'rb').read())\n",
    "    cur.execute(\"\"\"\n",
    "    INSERT INTO \"ODS\".\"EXT_FB_PRODUCT_IMAGE_SOURCE\" (\"IMAGE_LINK\",\"SOURCE\") \n",
    "    VALUES('{image_link}',{image_binary})\n",
    "    ON CONFLICT DO NOTHING;\n",
    "    \"\"\".format(image_link=page_url, image_binary=image_binary))\n",
    "    cur.execute('COMMIT;')"
   ]
  },
  {
   "source": [
    "# Data Preprocessing"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(last_execution_date < end_date):\n",
    "    sql_command = \"\"\"\n",
    "        WITH CLEAN_DATA AS(\n",
    "        SELECT\n",
    "        EFC.\"RESTAURANT_ID\",\n",
    "        EFC.\"USERNAME\",\n",
    "        LOWER(EFC.\"COMMENT_TEXT\") AS \"COMMENT_TEXT\",\n",
    "        EFC.\"COMMENT_DATE\",\n",
    "        TRY_CAST(REGEXP_REPLACE(EFC.\"SPEED\", '\\D','','g'),NULL::INTEGER) AS \"SPEED\",\n",
    "        TRY_CAST(REGEXP_REPLACE(EFC.\"SERVING\", '\\D','','g'),NULL::INTEGER) AS \"SERVING\",\n",
    "        TRY_CAST(REGEXP_REPLACE(EFC.\"FLAVOUR\", '\\D','','g'),NULL::INTEGER) AS \"FLAVOUR\",\n",
    "        EFC.\"DATE\",\n",
    "        REGEXP_REPLACE(EFC.\"COMMENT_DATE\", '\\D','','g')||' '||REPLACE(REPLACE(REPLACE(REGEXP_REPLACE(REPLACE(EFC.\"COMMENT_DATE\",' önce',''), '[^[:alpha:]]', '', 'g'),'ay','month'),'bugün','today'),'gün','day') AS \"COMMENT_DATE_INTERVAL\"\n",
    "        FROM \"ODS\".\"EXT_FB_COMMENT\" EFC\n",
    "        WHERE 1=1\n",
    "        AND EFC.\"USERNAME\" <> 'Yemeksepeti'\n",
    "        )\n",
    "        SELECT\n",
    "        CD.\"RESTAURANT_ID\",\n",
    "        CD.\"USERNAME\",\n",
    "        CD.\"COMMENT_TEXT\",\n",
    "        CASE WHEN CD.\"COMMENT_DATE_INTERVAL\" = ' today' THEN CD.\"DATE\" ELSE CD.\"DATE\" - CAST(CD.\"COMMENT_DATE_INTERVAL\" AS INTERVAL) END::date AS \"COMMENT_DATE\",\n",
    "        CD.\"SPEED\",\n",
    "        CD.\"SERVING\",\n",
    "        CD.\"FLAVOUR\",\n",
    "        CD.\"DATE\"\n",
    "        FROM CLEAN_DATA CD;\n",
    "        \"\"\"\n",
    "    comment_df = pd.read_sql(sql_command,conn)\n",
    "    comment_df['COMMENT_TEXT'] = comment_df['COMMENT_TEXT'].apply(clean_text)\n",
    "    comment_df\n",
    "    df_column_conversation(comment_df, 'RESTAURANT_ID', 'text')\n",
    "    df_column_conversation(comment_df, 'USERNAME', 'text')\n",
    "    df_column_conversation(comment_df, 'COMMENT_TEXT', 'text')\n",
    "    df_column_conversation(comment_df, 'COMMENT_DATE', 'date')\n",
    "    df_column_conversation(comment_df, 'SPEED', 'integer')\n",
    "    df_column_conversation(comment_df, 'SERVING', 'integer')\n",
    "    df_column_conversation(comment_df, 'FLAVOUR', 'integer')\n",
    "    df_column_conversation(comment_df, 'DATE', 'date')\n",
    "    comment_df.replace('<NA>', 'NULL', inplace=True)\n",
    "    execute_mogrify(conn,comment_df,\"EDW\",\"DWH_FB_COMMENT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                     RESTAURANT_ID USERNAME  \\\n",
       "0       magic-akademi-kartal-esentepe-mah-istanbul     ...i   \n",
       "1       magic-akademi-kartal-esentepe-mah-istanbul     ...3   \n",
       "2       magic-akademi-kartal-esentepe-mah-istanbul     ...0   \n",
       "3       magic-akademi-kartal-esentepe-mah-istanbul     ...t   \n",
       "4       magic-akademi-kartal-esentepe-mah-istanbul     ...e   \n",
       "...                                            ...      ...   \n",
       "271838  magic-akademi-kartal-esentepe-mah-istanbul     ...1   \n",
       "271839  magic-akademi-kartal-esentepe-mah-istanbul     ...d   \n",
       "271840  magic-akademi-kartal-esentepe-mah-istanbul     ...k   \n",
       "271841  magic-akademi-kartal-esentepe-mah-istanbul     ...7   \n",
       "271842  magic-akademi-kartal-esentepe-mah-istanbul     ...l   \n",
       "\n",
       "                                             COMMENT_TEXT COMMENT_DATE  SPEED  \\\n",
       "0       i̇lk kez sipariş verdim bu restauranttan patat...   2021-01-10   10.0   \n",
       "1       her söyledigimde somon daha da kötüleşiyor bu ...   2021-01-10    9.0   \n",
       "2                                                     itu   2021-01-10    8.0   \n",
       "3          18 dkda kapıdaydi sıcak ve lezzetli süpersiniz   2021-01-10   10.0   \n",
       "4       dağ kekikli tavuğun yanında gelen makarna bild...   2021-01-10   10.0   \n",
       "...                                                   ...          ...    ...   \n",
       "271838        anladık ki hamburgerler kötü pizzadan devam   2021-01-10    5.0   \n",
       "271839  tiramisu malesef rezaletti kreması ekşimişti y...   2021-01-10    1.0   \n",
       "271840     dağ kekikli tavuk inanılmaz güzel bağımlısıyım   2021-01-10   10.0   \n",
       "271841  waffle söyledik kalın bir hamur üzerine 6 7 kü...   2021-01-10    6.0   \n",
       "271842  pizza adana börek ve pasta nefisti teşekkür ed...   2021-01-10   10.0   \n",
       "\n",
       "        SERVING  FLAVOUR        DATE  \n",
       "0             5        8  2021-06-10  \n",
       "1             6        4  2021-06-10  \n",
       "2             8        8  2021-06-10  \n",
       "3            10       10  2021-06-10  \n",
       "4             6        3  2021-06-10  \n",
       "...         ...      ...         ...  \n",
       "271838        5        5  2021-06-10  \n",
       "271839        1        1  2021-06-10  \n",
       "271840       10       10  2021-06-10  \n",
       "271841        4        3  2021-06-10  \n",
       "271842       10        9  2021-06-10  \n",
       "\n",
       "[271843 rows x 8 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>RESTAURANT_ID</th>\n      <th>USERNAME</th>\n      <th>COMMENT_TEXT</th>\n      <th>COMMENT_DATE</th>\n      <th>SPEED</th>\n      <th>SERVING</th>\n      <th>FLAVOUR</th>\n      <th>DATE</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>magic-akademi-kartal-esentepe-mah-istanbul</td>\n      <td>...i</td>\n      <td>i̇lk kez sipariş verdim bu restauranttan patat...</td>\n      <td>2021-01-10</td>\n      <td>10.0</td>\n      <td>5</td>\n      <td>8</td>\n      <td>2021-06-10</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>magic-akademi-kartal-esentepe-mah-istanbul</td>\n      <td>...3</td>\n      <td>her söyledigimde somon daha da kötüleşiyor bu ...</td>\n      <td>2021-01-10</td>\n      <td>9.0</td>\n      <td>6</td>\n      <td>4</td>\n      <td>2021-06-10</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>magic-akademi-kartal-esentepe-mah-istanbul</td>\n      <td>...0</td>\n      <td>itu</td>\n      <td>2021-01-10</td>\n      <td>8.0</td>\n      <td>8</td>\n      <td>8</td>\n      <td>2021-06-10</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>magic-akademi-kartal-esentepe-mah-istanbul</td>\n      <td>...t</td>\n      <td>18 dkda kapıdaydi sıcak ve lezzetli süpersiniz</td>\n      <td>2021-01-10</td>\n      <td>10.0</td>\n      <td>10</td>\n      <td>10</td>\n      <td>2021-06-10</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>magic-akademi-kartal-esentepe-mah-istanbul</td>\n      <td>...e</td>\n      <td>dağ kekikli tavuğun yanında gelen makarna bild...</td>\n      <td>2021-01-10</td>\n      <td>10.0</td>\n      <td>6</td>\n      <td>3</td>\n      <td>2021-06-10</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>271838</th>\n      <td>magic-akademi-kartal-esentepe-mah-istanbul</td>\n      <td>...1</td>\n      <td>anladık ki hamburgerler kötü pizzadan devam</td>\n      <td>2021-01-10</td>\n      <td>5.0</td>\n      <td>5</td>\n      <td>5</td>\n      <td>2021-06-10</td>\n    </tr>\n    <tr>\n      <th>271839</th>\n      <td>magic-akademi-kartal-esentepe-mah-istanbul</td>\n      <td>...d</td>\n      <td>tiramisu malesef rezaletti kreması ekşimişti y...</td>\n      <td>2021-01-10</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2021-06-10</td>\n    </tr>\n    <tr>\n      <th>271840</th>\n      <td>magic-akademi-kartal-esentepe-mah-istanbul</td>\n      <td>...k</td>\n      <td>dağ kekikli tavuk inanılmaz güzel bağımlısıyım</td>\n      <td>2021-01-10</td>\n      <td>10.0</td>\n      <td>10</td>\n      <td>10</td>\n      <td>2021-06-10</td>\n    </tr>\n    <tr>\n      <th>271841</th>\n      <td>magic-akademi-kartal-esentepe-mah-istanbul</td>\n      <td>...7</td>\n      <td>waffle söyledik kalın bir hamur üzerine 6 7 kü...</td>\n      <td>2021-01-10</td>\n      <td>6.0</td>\n      <td>4</td>\n      <td>3</td>\n      <td>2021-06-10</td>\n    </tr>\n    <tr>\n      <th>271842</th>\n      <td>magic-akademi-kartal-esentepe-mah-istanbul</td>\n      <td>...l</td>\n      <td>pizza adana börek ve pasta nefisti teşekkür ed...</td>\n      <td>2021-01-10</td>\n      <td>10.0</td>\n      <td>10</td>\n      <td>9</td>\n      <td>2021-06-10</td>\n    </tr>\n  </tbody>\n</table>\n<p>271843 rows × 8 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "sql_command = \"\"\"\n",
    "    SELECT\n",
    "    *\n",
    "    FROM \"EDW\".\"DWH_FB_COMMENT\" EFR;\n",
    "    \"\"\"\n",
    "comment_df = pd.read_sql(sql_command,conn)\n",
    "comment_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                     RESTAURANT_ID USERNAME  \\\n",
       "0       magic-akademi-kartal-esentepe-mah-istanbul     ...i   \n",
       "1       magic-akademi-kartal-esentepe-mah-istanbul     ...3   \n",
       "2       magic-akademi-kartal-esentepe-mah-istanbul     ...0   \n",
       "3       magic-akademi-kartal-esentepe-mah-istanbul     ...t   \n",
       "4       magic-akademi-kartal-esentepe-mah-istanbul     ...e   \n",
       "...                                            ...      ...   \n",
       "271838  magic-akademi-kartal-esentepe-mah-istanbul     ...1   \n",
       "271839  magic-akademi-kartal-esentepe-mah-istanbul     ...d   \n",
       "271840  magic-akademi-kartal-esentepe-mah-istanbul     ...k   \n",
       "271841  magic-akademi-kartal-esentepe-mah-istanbul     ...7   \n",
       "271842  magic-akademi-kartal-esentepe-mah-istanbul     ...l   \n",
       "\n",
       "                                             COMMENT_TEXT COMMENT_DATE  SPEED  \\\n",
       "0       i̇lk sipariş verdim restauranttan patates sıca...   2021-01-10   10.0   \n",
       "1       söyledigimde somon kötüleşiyor sefer fettucini...   2021-01-10    9.0   \n",
       "2                                                     itu   2021-01-10    8.0   \n",
       "3             18 dkda kapıdaydi sıcak lezzetli süpersiniz   2021-01-10   10.0   \n",
       "4       dağ kekikli tavuğun yanında gelen makarna bild...   2021-01-10   10.0   \n",
       "...                                                   ...          ...    ...   \n",
       "271838           anladık hamburgerler kötü pizzadan devam   2021-01-10    5.0   \n",
       "271839  tiramisu malesef rezaletti kreması ekşimişti y...   2021-01-10    1.0   \n",
       "271840     dağ kekikli tavuk inanılmaz güzel bağımlısıyım   2021-01-10   10.0   \n",
       "271841  waffle söyledik kalın bir hamur üzerine 6 7 kü...   2021-01-10    6.0   \n",
       "271842    pizza adana börek pasta nefisti teşekkür ederiz   2021-01-10   10.0   \n",
       "\n",
       "        SERVING  FLAVOUR        DATE  \n",
       "0             5        8  2021-06-10  \n",
       "1             6        4  2021-06-10  \n",
       "2             8        8  2021-06-10  \n",
       "3            10       10  2021-06-10  \n",
       "4             6        3  2021-06-10  \n",
       "...         ...      ...         ...  \n",
       "271838        5        5  2021-06-10  \n",
       "271839        1        1  2021-06-10  \n",
       "271840       10       10  2021-06-10  \n",
       "271841        4        3  2021-06-10  \n",
       "271842       10        9  2021-06-10  \n",
       "\n",
       "[271843 rows x 8 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>RESTAURANT_ID</th>\n      <th>USERNAME</th>\n      <th>COMMENT_TEXT</th>\n      <th>COMMENT_DATE</th>\n      <th>SPEED</th>\n      <th>SERVING</th>\n      <th>FLAVOUR</th>\n      <th>DATE</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>magic-akademi-kartal-esentepe-mah-istanbul</td>\n      <td>...i</td>\n      <td>i̇lk sipariş verdim restauranttan patates sıca...</td>\n      <td>2021-01-10</td>\n      <td>10.0</td>\n      <td>5</td>\n      <td>8</td>\n      <td>2021-06-10</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>magic-akademi-kartal-esentepe-mah-istanbul</td>\n      <td>...3</td>\n      <td>söyledigimde somon kötüleşiyor sefer fettucini...</td>\n      <td>2021-01-10</td>\n      <td>9.0</td>\n      <td>6</td>\n      <td>4</td>\n      <td>2021-06-10</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>magic-akademi-kartal-esentepe-mah-istanbul</td>\n      <td>...0</td>\n      <td>itu</td>\n      <td>2021-01-10</td>\n      <td>8.0</td>\n      <td>8</td>\n      <td>8</td>\n      <td>2021-06-10</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>magic-akademi-kartal-esentepe-mah-istanbul</td>\n      <td>...t</td>\n      <td>18 dkda kapıdaydi sıcak lezzetli süpersiniz</td>\n      <td>2021-01-10</td>\n      <td>10.0</td>\n      <td>10</td>\n      <td>10</td>\n      <td>2021-06-10</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>magic-akademi-kartal-esentepe-mah-istanbul</td>\n      <td>...e</td>\n      <td>dağ kekikli tavuğun yanında gelen makarna bild...</td>\n      <td>2021-01-10</td>\n      <td>10.0</td>\n      <td>6</td>\n      <td>3</td>\n      <td>2021-06-10</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>271838</th>\n      <td>magic-akademi-kartal-esentepe-mah-istanbul</td>\n      <td>...1</td>\n      <td>anladık hamburgerler kötü pizzadan devam</td>\n      <td>2021-01-10</td>\n      <td>5.0</td>\n      <td>5</td>\n      <td>5</td>\n      <td>2021-06-10</td>\n    </tr>\n    <tr>\n      <th>271839</th>\n      <td>magic-akademi-kartal-esentepe-mah-istanbul</td>\n      <td>...d</td>\n      <td>tiramisu malesef rezaletti kreması ekşimişti y...</td>\n      <td>2021-01-10</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2021-06-10</td>\n    </tr>\n    <tr>\n      <th>271840</th>\n      <td>magic-akademi-kartal-esentepe-mah-istanbul</td>\n      <td>...k</td>\n      <td>dağ kekikli tavuk inanılmaz güzel bağımlısıyım</td>\n      <td>2021-01-10</td>\n      <td>10.0</td>\n      <td>10</td>\n      <td>10</td>\n      <td>2021-06-10</td>\n    </tr>\n    <tr>\n      <th>271841</th>\n      <td>magic-akademi-kartal-esentepe-mah-istanbul</td>\n      <td>...7</td>\n      <td>waffle söyledik kalın bir hamur üzerine 6 7 kü...</td>\n      <td>2021-01-10</td>\n      <td>6.0</td>\n      <td>4</td>\n      <td>3</td>\n      <td>2021-06-10</td>\n    </tr>\n    <tr>\n      <th>271842</th>\n      <td>magic-akademi-kartal-esentepe-mah-istanbul</td>\n      <td>...l</td>\n      <td>pizza adana börek pasta nefisti teşekkür ederiz</td>\n      <td>2021-01-10</td>\n      <td>10.0</td>\n      <td>10</td>\n      <td>9</td>\n      <td>2021-06-10</td>\n    </tr>\n  </tbody>\n</table>\n<p>271843 rows × 8 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "stop_words = [element for element in stopwords.words('turkish') if element not in ['çok','eğer','gibi','hiç','niçin','niye','sanki','yani','en','az','birkaç','bazı','aslında','neden','hepsi']]\n",
    "comment_df['COMMENT_TEXT'] = comment_df['COMMENT_TEXT'].apply(lambda x: ' '.join([word for word in x.lower().split() if word not in (stop_words)]))\n",
    "#comment_df['COMMENT_TEXT'] = comment_df['COMMENT_TEXT'].apply(lambda x: ' '.join([stemmer.stem(word) for word in x.split()]))\n",
    "comment_df"
   ]
  },
  {
   "source": [
    "# Machine Learning"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Bag of Words"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Gaussian Naive Bayes"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Total Features after vectorizing: 2733\n",
      "Accuracy Score for SPEED: 31.33%\n",
      "F1 Score for SPEED: 31.33%\n",
      "Precision Score for SPEED: 31.33%\n",
      "\n",
      "Total Features after vectorizing: 4003\n",
      "Accuracy Score for SERVING: 31.00%\n",
      "F1 Score for SERVING: 31.00%\n",
      "Precision Score for SERVING: 31.00%\n",
      "\n",
      "Total Features after vectorizing: 4003\n",
      "Accuracy Score for FLAVOUR: 28.87%\n",
      "F1 Score for FLAVOUR: 28.87%\n",
      "Precision Score for FLAVOUR: 28.87%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for label in ['SPEED','SERVING','FLAVOUR']:\n",
    "    model = CountVectorizer(min_df=3)\n",
    "    not_null_df = comment_df[0:10000][pd.notnull(comment_df[label])]\n",
    "    features = model.fit_transform(not_null_df['COMMENT_TEXT'].values).todense()\n",
    "    labels = not_null_df[label].values\n",
    "    print(\"Total Features after vectorizing: {total_features}\".format(total_features = np.shape(features)[1]))\n",
    "    #print(np.shape(labels))\n",
    "\n",
    "    features_train, features_test, labels_train, labels_test = train_test_split(features, labels, test_size = 0.3, random_state = 9)\n",
    "    \n",
    "    model_file_name = \"models/BoW_CountVectorizer_GaussianNB_{label}.mdl\".format(label = label)\n",
    "    \n",
    "    if(check_if_file_exists(model_file_name)):\n",
    "        model = joblib.load(model_file_name)\n",
    "    else:\n",
    "        model = GaussianNB()\n",
    "        model.fit(features_train, labels_train)\n",
    "\n",
    "        joblib.dump(model, model_file_name)\n",
    "\n",
    "    label_prediction = model.predict(features_test)\n",
    "\n",
    "    print(\"Accuracy Score for {label}: {accuracy_score:0.2f}%\".format(accuracy_score = accuracy_score(labels_test, label_prediction)*100, label=label))\n",
    "    print(\"F1 Score for {label}: {f1_score:0.2f}%\".format(f1_score = f1_score(labels_test, label_prediction, average='micro')*100, label=label))\n",
    "    print(\"Precision Score for {label}: {precision_score:0.2f}%\\n\".format(precision_score  = precision_score(labels_test, label_prediction, average='micro')*100, label=label))"
   ]
  },
  {
   "source": [
    "### Support Vector Machines"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "#### C-Support Vector Classification"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Total Features after vectorizing: 2733\n",
      "Accuracy Score for SPEED: 64.19%\n",
      "F1 Score for SPEED: 64.19%\n",
      "Precision Score for SPEED: 64.19%\n",
      "\n",
      "Total Features after vectorizing: 4003\n",
      "Accuracy Score for SERVING: 64.73%\n",
      "F1 Score for SERVING: 64.73%\n",
      "Precision Score for SERVING: 64.73%\n",
      "\n",
      "Total Features after vectorizing: 4003\n",
      "Accuracy Score for FLAVOUR: 62.00%\n",
      "F1 Score for FLAVOUR: 62.00%\n",
      "Precision Score for FLAVOUR: 62.00%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for label in ['SPEED','SERVING','FLAVOUR']:\n",
    "    model = CountVectorizer(min_df=3)\n",
    "    not_null_df = comment_df[0:10000][pd.notnull(comment_df[label])]\n",
    "    features = model.fit_transform(not_null_df['COMMENT_TEXT'].values).todense()\n",
    "    labels = not_null_df[label].values\n",
    "    print(\"Total Features after vectorizing: {total_features}\".format(total_features = np.shape(features)[1]))\n",
    "\n",
    "    features_train, features_test, labels_train, labels_test = train_test_split(features, labels, test_size = 0.3, random_state = 9)\n",
    "\n",
    "    model_file_name = \"models/BoW_CountVectorizer_SVC_{label}.mdl\".format(label = label)\n",
    "\n",
    "    if(check_if_file_exists(model_file_name)):\n",
    "        model = joblib.load(model_file_name)\n",
    "    else:\n",
    "        model = SVC()\n",
    "        model.fit(features_train, labels_train)\n",
    "\n",
    "        joblib.dump(model, model_file_name)\n",
    "\n",
    "    label_prediction = model.predict(features_test)\n",
    "\n",
    "    print(\"Accuracy Score for {label}: {accuracy_score:0.2f}%\".format(accuracy_score = accuracy_score(labels_test, label_prediction)*100, label=label))\n",
    "    print(\"F1 Score for {label}: {f1_score:0.2f}%\".format(f1_score = f1_score(labels_test, label_prediction, average='micro')*100, label=label))\n",
    "    print(\"Precision Score for {label}: {precision_score:0.2f}%\\n\".format(precision_score  = precision_score(labels_test, label_prediction, average='micro')*100, label=label))"
   ]
  },
  {
   "source": [
    "#### Linear Support Vector Classification"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Total Features after vectorizing: 2733\n",
      "Accuracy Score for SPEED: 60.05%\n",
      "F1 Score for SPEED: 60.05%\n",
      "Precision Score for SPEED: 60.05%\n",
      "\n",
      "Total Features after vectorizing: 4003\n",
      "Accuracy Score for SERVING: 61.63%\n",
      "F1 Score for SERVING: 61.63%\n",
      "Precision Score for SERVING: 61.63%\n",
      "\n",
      "Total Features after vectorizing: 4003\n",
      "Accuracy Score for FLAVOUR: 58.20%\n",
      "F1 Score for FLAVOUR: 58.20%\n",
      "Precision Score for FLAVOUR: 58.20%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for label in ['SPEED','SERVING','FLAVOUR']:\n",
    "    model = CountVectorizer(min_df=3)\n",
    "    not_null_df = comment_df[0:10000][pd.notnull(comment_df[label])]\n",
    "    features = model.fit_transform(not_null_df['COMMENT_TEXT'].values).todense()\n",
    "    labels = not_null_df[label].values\n",
    "    print(\"Total Features after vectorizing: {total_features}\".format(total_features = np.shape(features)[1]))\n",
    "\n",
    "    features_train, features_test, labels_train, labels_test = train_test_split(features, labels, test_size = 0.3, random_state = 9)\n",
    "\n",
    "    model_file_name = \"models/BoW_CountVectorizer_LinearSVC_{label}.mdl\".format(label = label)\n",
    "    \n",
    "    if(check_if_file_exists(model_file_name)):\n",
    "        model = joblib.load(model_file_name)\n",
    "    else:\n",
    "        model = LinearSVC()\n",
    "        model.fit(features_train, labels_train)\n",
    "\n",
    "        joblib.dump(model, model_file_name)\n",
    "\n",
    "    label_prediction = model.predict(features_test)\n",
    "\n",
    "    print(\"Accuracy Score for {label}: {accuracy_score:0.2f}%\".format(accuracy_score = accuracy_score(labels_test, label_prediction)*100, label=label))\n",
    "    print(\"F1 Score for {label}: {f1_score:0.2f}%\".format(f1_score = f1_score(labels_test, label_prediction, average='micro')*100, label=label))\n",
    "    print(\"Precision Score for {label}: {precision_score:0.2f}%\\n\".format(precision_score  = precision_score(labels_test, label_prediction, average='micro')*100, label=label))"
   ]
  },
  {
   "source": [
    "### Decision Tree Classifier"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Total Features after vectorizing: 2733\n",
      "Accuracy Score for SPEED: 63.50%\n",
      "F1 Score for SPEED: 63.50%\n",
      "Precision Score for SPEED: 63.50%\n",
      "\n",
      "Total Features after vectorizing: 4003\n",
      "Accuracy Score for SERVING: 63.27%\n",
      "F1 Score for SERVING: 63.27%\n",
      "Precision Score for SERVING: 63.27%\n",
      "\n",
      "Total Features after vectorizing: 4003\n",
      "Accuracy Score for FLAVOUR: 59.33%\n",
      "F1 Score for FLAVOUR: 59.33%\n",
      "Precision Score for FLAVOUR: 59.33%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for label in ['SPEED','SERVING','FLAVOUR']:\n",
    "    model = CountVectorizer(min_df=3)\n",
    "    not_null_df = comment_df[0:10000][pd.notnull(comment_df[label])]\n",
    "    features = model.fit_transform(not_null_df['COMMENT_TEXT'].values).todense()\n",
    "    labels = not_null_df[label].values\n",
    "    print(\"Total Features after vectorizing: {total_features}\".format(total_features = np.shape(features)[1]))\n",
    "\n",
    "    features_train, features_test, labels_train, labels_test = train_test_split(features, labels, test_size = 0.3, random_state = 9)\n",
    "\n",
    "    model_file_name = \"models/BoW_CountVectorizer_DecisionTreeClassifier_{label}.mdl\".format(label = label)\n",
    "    \n",
    "    if(check_if_file_exists(model_file_name)):\n",
    "        model = joblib.load(model_file_name)\n",
    "    else:\n",
    "        params = {\n",
    "            'max_depth': [10,13,14,15],\n",
    "            'min_samples_split': [2,3,4]\n",
    "            }\n",
    "\n",
    "        gscv = GridSearchCV(DecisionTreeClassifier(), params, cv=5)\n",
    "        gscv.fit(features_train, labels_train)\n",
    "        print(\"Best parameters: {best_parameters}\".format(best_parameters = gscv.best_params_))\n",
    "\n",
    "        model = gscv.best_estimator_\n",
    "        model.fit(features_train, labels_train)\n",
    "\n",
    "        joblib.dump(model, model_file_name)\n",
    "\n",
    "    label_prediction = model.predict(features_test)\n",
    "\n",
    "    print(\"Accuracy Score for {label}: {accuracy_score:0.2f}%\".format(accuracy_score = accuracy_score(labels_test, label_prediction)*100, label=label))\n",
    "    print(\"F1 Score for {label}: {f1_score:0.2f}%\".format(f1_score = f1_score(labels_test, label_prediction, average='micro')*100, label=label))\n",
    "    print(\"Precision Score for {label}: {precision_score:0.2f}%\\n\".format(precision_score  = precision_score(labels_test, label_prediction, average='micro')*100, label=label))"
   ]
  },
  {
   "source": [
    "### Logistic Regression"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Total Features after vectorizing: 2619\n",
      "Accuracy Score for SPEED: 63.19%\n",
      "F1 Score for SPEED: 63.19%\n",
      "Precision Score for SPEED: 63.19%\n",
      "\n",
      "Total Features after vectorizing: 3913\n",
      "Accuracy Score for SERVING: 64.90%\n",
      "F1 Score for SERVING: 64.90%\n",
      "Precision Score for SERVING: 64.90%\n",
      "\n",
      "Total Features after vectorizing: 3913\n",
      "Accuracy Score for FLAVOUR: 63.12%\n",
      "F1 Score for FLAVOUR: 63.12%\n",
      "Precision Score for FLAVOUR: 63.12%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for label in ['SPEED','SERVING','FLAVOUR']:\n",
    "    model = CountVectorizer(min_df=3)\n",
    "    not_null_df = comment_df[0:9600][pd.notnull(comment_df[label])]\n",
    "    features = model.fit_transform(not_null_df['COMMENT_TEXT'].values).todense()\n",
    "    labels = not_null_df[label].values\n",
    "    print(\"Total Features after vectorizing: {total_features}\".format(total_features = np.shape(features)[1]))\n",
    "\n",
    "    features_train, features_test, labels_train, labels_test = train_test_split(features, labels, test_size = 0.3, random_state = 9)\n",
    "\n",
    "    model_file_name = \"models/BoW_CountVectorizer_LogisticRegression_{label}.mdl\".format(label = label)\n",
    "    \n",
    "    if(check_if_file_exists(model_file_name)):\n",
    "        model = joblib.load(model_file_name)\n",
    "    else:\n",
    "        model = LogisticRegression(penalty='l2', C=1.2, n_jobs=-1)\n",
    "        model.fit(features_train, labels_train)\n",
    "\n",
    "        joblib.dump(model, model_file_name)\n",
    "\n",
    "    label_prediction = model.predict(features_test)\n",
    "\n",
    "    print(\"Accuracy Score for {label}: {accuracy_score:0.2f}%\".format(accuracy_score = accuracy_score(labels_test, label_prediction)*100, label=label))\n",
    "    print(\"F1 Score for {label}: {f1_score:0.2f}%\".format(f1_score = f1_score(labels_test, label_prediction, average='micro')*100, label=label))\n",
    "    print(\"Precision Score for {label}: {precision_score:0.2f}%\\n\".format(precision_score  = precision_score(labels_test, label_prediction, average='micro')*100, label=label))"
   ]
  },
  {
   "source": [
    "## Bag of Words with TF-IDF Vectorizer"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Gaussian Naive Bayes"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Total Features after vectorizing: 2733\n",
      "Accuracy Score for SPEED: 31.43%\n",
      "F1 Score for SPEED: 31.43%\n",
      "Precision Score for SPEED: 31.43%\n",
      "\n",
      "Total Features after vectorizing: 4003\n",
      "Accuracy Score for SERVING: 31.40%\n",
      "F1 Score for SERVING: 31.40%\n",
      "Precision Score for SERVING: 31.40%\n",
      "\n",
      "Total Features after vectorizing: 4003\n",
      "Accuracy Score for FLAVOUR: 28.57%\n",
      "F1 Score for FLAVOUR: 28.57%\n",
      "Precision Score for FLAVOUR: 28.57%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for label in ['SPEED','SERVING','FLAVOUR']:\n",
    "    model = TfidfVectorizer(min_df=3)\n",
    "    not_null_df = comment_df[0:10000][pd.notnull(comment_df[label])]\n",
    "    features = model.fit_transform(not_null_df['COMMENT_TEXT'].values).todense()\n",
    "    labels = not_null_df[label].values\n",
    "    print(\"Total Features after vectorizing: {total_features}\".format(total_features = np.shape(features)[1]))\n",
    "    #print(np.shape(labels))\n",
    "\n",
    "    features_train, features_test, labels_train, labels_test = train_test_split(features, labels, test_size = 0.3, random_state = 9)\n",
    "    \n",
    "    model_file_name = \"models/BoW_TFIDFVectorizer_GaussianNB_{label}.mdl\".format(label = label)\n",
    "    \n",
    "    if(check_if_file_exists(model_file_name)):\n",
    "        model = joblib.load(model_file_name)\n",
    "    else:\n",
    "        model = GaussianNB()\n",
    "        model.fit(features_train, labels_train)\n",
    "\n",
    "        joblib.dump(model, model_file_name)\n",
    "\n",
    "    label_prediction = model.predict(features_test)\n",
    "\n",
    "    print(\"Accuracy Score for {label}: {accuracy_score:0.2f}%\".format(accuracy_score = accuracy_score(labels_test, label_prediction)*100, label=label))\n",
    "    print(\"F1 Score for {label}: {f1_score:0.2f}%\".format(f1_score = f1_score(labels_test, label_prediction, average='micro')*100, label=label))\n",
    "    print(\"Precision Score for {label}: {precision_score:0.2f}%\\n\".format(precision_score  = precision_score(labels_test, label_prediction, average='micro')*100, label=label))"
   ]
  },
  {
   "source": [
    "### Support Vector Machines"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "#### C-Support Vector Classification"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Total Features after vectorizing: 2733\n",
      "Accuracy Score for SPEED: 65.76%\n",
      "F1 Score for SPEED: 65.76%\n",
      "Precision Score for SPEED: 65.76%\n",
      "\n",
      "Total Features after vectorizing: 4003\n",
      "Accuracy Score for SERVING: 66.67%\n",
      "F1 Score for SERVING: 66.67%\n",
      "Precision Score for SERVING: 66.67%\n",
      "\n",
      "Total Features after vectorizing: 4003\n",
      "Accuracy Score for FLAVOUR: 63.53%\n",
      "F1 Score for FLAVOUR: 63.53%\n",
      "Precision Score for FLAVOUR: 63.53%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for label in ['SPEED','SERVING','FLAVOUR']:\n",
    "    model = TfidfVectorizer(min_df=3)\n",
    "    not_null_df = comment_df[0:10000][pd.notnull(comment_df[label])]\n",
    "    features = model.fit_transform(not_null_df['COMMENT_TEXT'].values).todense()\n",
    "    labels = not_null_df[label].values\n",
    "    print(\"Total Features after vectorizing: {total_features}\".format(total_features = np.shape(features)[1]))\n",
    "\n",
    "    features_train, features_test, labels_train, labels_test = train_test_split(features, labels, test_size = 0.3, random_state = 9)\n",
    "    \n",
    "    model_file_name = \"models/BoW_TFIDFVectorizer_SVC_{label}.mdl\".format(label = label)\n",
    "    \n",
    "    if(check_if_file_exists(model_file_name)):\n",
    "        model = joblib.load(model_file_name)\n",
    "    else:\n",
    "        params = {\n",
    "            'C': [1.5],\n",
    "            #'C': [1.4,1.5,1.6],\n",
    "            'kernel': ['rbf']\n",
    "            #'kernel': ['linear','rbf','sigmoid']\n",
    "            }\n",
    "\n",
    "        gscv = GridSearchCV(SVC(), params, cv=5)\n",
    "        gscv.fit(features_train, labels_train)\n",
    "        print(\"Best parameters: {best_parameters}\".format(best_parameters = gscv.best_params_))\n",
    "\n",
    "        model = gscv.best_estimator_\n",
    "        model.fit(features_train, labels_train)\n",
    "\n",
    "        joblib.dump(model, model_file_name)\n",
    "\n",
    "    label_prediction = model.predict(features_test)\n",
    "\n",
    "    print(\"Accuracy Score for {label}: {accuracy_score:0.2f}%\".format(accuracy_score = accuracy_score(labels_test, label_prediction)*100, label=label))\n",
    "    print(\"F1 Score for {label}: {f1_score:0.2f}%\".format(f1_score = f1_score(labels_test, label_prediction, average='micro')*100, label=label))\n",
    "    print(\"Precision Score for {label}: {precision_score:0.2f}%\\n\".format(precision_score  = precision_score(labels_test, label_prediction, average='micro')*100, label=label))"
   ]
  },
  {
   "source": [
    "#### Linear Support Vector Classification"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Total Features after vectorizing: 2733\n",
      "Accuracy Score for SPEED: 63.05%\n",
      "F1 Score for SPEED: 63.05%\n",
      "Precision Score for SPEED: 63.05%\n",
      "\n",
      "Total Features after vectorizing: 4003\n",
      "Accuracy Score for SERVING: 65.10%\n",
      "F1 Score for SERVING: 65.10%\n",
      "Precision Score for SERVING: 65.10%\n",
      "\n",
      "Total Features after vectorizing: 4003\n",
      "Accuracy Score for FLAVOUR: 61.67%\n",
      "F1 Score for FLAVOUR: 61.67%\n",
      "Precision Score for FLAVOUR: 61.67%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for label in ['SPEED','SERVING','FLAVOUR']:\n",
    "    model = TfidfVectorizer(min_df=3)\n",
    "    not_null_df = comment_df[0:10000][pd.notnull(comment_df[label])]\n",
    "    features = model.fit_transform(not_null_df['COMMENT_TEXT'].values).todense()\n",
    "    labels = not_null_df[label].values\n",
    "    print(\"Total Features after vectorizing: {total_features}\".format(total_features = np.shape(features)[1]))\n",
    "\n",
    "    features_train, features_test, labels_train, labels_test = train_test_split(features, labels, test_size = 0.3, random_state = 9)\n",
    "    \n",
    "    model_file_name = \"models/BoW_TFIDFVectorizer_LinearSVC_{label}.mdl\".format(label = label)\n",
    "    \n",
    "    if(check_if_file_exists(model_file_name)):\n",
    "        model = joblib.load(model_file_name)\n",
    "    else:\n",
    "        model = LinearSVC()\n",
    "        model.fit(features_train, labels_train)\n",
    "\n",
    "        joblib.dump(model, model_file_name)\n",
    "\n",
    "    label_prediction = model.predict(features_test)\n",
    "\n",
    "    print(\"Accuracy Score for {label}: {accuracy_score:0.2f}%\".format(accuracy_score = accuracy_score(labels_test, label_prediction)*100, label=label))\n",
    "    print(\"F1 Score for {label}: {f1_score:0.2f}%\".format(f1_score = f1_score(labels_test, label_prediction, average='micro')*100, label=label))\n",
    "    print(\"Precision Score for {label}: {precision_score:0.2f}%\\n\".format(precision_score  = precision_score(labels_test, label_prediction, average='micro')*100, label=label))"
   ]
  },
  {
   "source": [
    "### Decision Tree Classifier"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Total Features after vectorizing: 2619\n",
      "Accuracy Score for SPEED: 62.93%\n",
      "F1 Score for SPEED: 62.93%\n",
      "Precision Score for SPEED: 62.93%\n",
      "\n",
      "Total Features after vectorizing: 3913\n",
      "Accuracy Score for SERVING: 61.98%\n",
      "F1 Score for SERVING: 61.98%\n",
      "Precision Score for SERVING: 61.98%\n",
      "\n",
      "Total Features after vectorizing: 3913\n",
      "Accuracy Score for FLAVOUR: 60.03%\n",
      "F1 Score for FLAVOUR: 60.03%\n",
      "Precision Score for FLAVOUR: 60.03%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for label in ['SPEED','SERVING','FLAVOUR']:\n",
    "    model = TfidfVectorizer(min_df=3)\n",
    "    not_null_df = comment_df[0:9600][pd.notnull(comment_df[label])]\n",
    "    features = model.fit_transform(not_null_df['COMMENT_TEXT'].values).todense()\n",
    "    labels = not_null_df[label].values\n",
    "    print(\"Total Features after vectorizing: {total_features}\".format(total_features = np.shape(features)[1]))\n",
    "\n",
    "    features_train, features_test, labels_train, labels_test = train_test_split(features, labels, test_size = 0.3, random_state = 9)\n",
    "    \n",
    "    model_file_name = \"models/BoW_TFIDFVectorizer_DecisionTreeClassifier_{label}.mdl\".format(label = label)\n",
    "    \n",
    "    if(check_if_file_exists(model_file_name)):\n",
    "        model = joblib.load(model_file_name)\n",
    "    else:\n",
    "        params = {\n",
    "            'max_depth': [9,10,11],\n",
    "            'min_samples_split': [2,3]\n",
    "            }\n",
    "\n",
    "        gscv = GridSearchCV(DecisionTreeClassifier(), params, cv=5)\n",
    "        gscv.fit(features_train, labels_train)\n",
    "        print(\"Best parameters: {best_parameters}\".format(best_parameters = gscv.best_params_))\n",
    "\n",
    "        model = gscv.best_estimator_\n",
    "        model.fit(features_train, labels_train)\n",
    "\n",
    "        joblib.dump(model, model_file_name)\n",
    "\n",
    "    label_prediction = model.predict(features_test)\n",
    "\n",
    "    print(\"Accuracy Score for {label}: {accuracy_score:0.2f}%\".format(accuracy_score = accuracy_score(labels_test, label_prediction)*100, label=label))\n",
    "    print(\"F1 Score for {label}: {f1_score:0.2f}%\".format(f1_score = f1_score(labels_test, label_prediction, average='micro')*100, label=label))\n",
    "    print(\"Precision Score for {label}: {precision_score:0.2f}%\\n\".format(precision_score  = precision_score(labels_test, label_prediction, average='micro')*100, label=label))"
   ]
  },
  {
   "source": [
    "### Logistic Regression"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Total Features after vectorizing: 2619\n",
      "Accuracy Score for SPEED: 65.71%\n",
      "F1 Score for SPEED: 65.71%\n",
      "Precision Score for SPEED: 65.71%\n",
      "\n",
      "Total Features after vectorizing: 3913\n",
      "Accuracy Score for SERVING: 65.73%\n",
      "F1 Score for SERVING: 65.73%\n",
      "Precision Score for SERVING: 65.73%\n",
      "\n",
      "Total Features after vectorizing: 3913\n",
      "Accuracy Score for FLAVOUR: 63.96%\n",
      "F1 Score for FLAVOUR: 63.96%\n",
      "Precision Score for FLAVOUR: 63.96%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for label in ['SPEED','SERVING','FLAVOUR']:\n",
    "    model = TfidfVectorizer(min_df=3)\n",
    "    not_null_df = comment_df[0:9600][pd.notnull(comment_df[label])]\n",
    "    features = model.fit_transform(not_null_df['COMMENT_TEXT'].values).todense()\n",
    "    labels = not_null_df[label].values\n",
    "    print(\"Total Features after vectorizing: {total_features}\".format(total_features = np.shape(features)[1]))\n",
    "\n",
    "    features_train, features_test, labels_train, labels_test = train_test_split(features, labels, test_size = 0.3, random_state = 9)\n",
    "    \n",
    "    model_file_name = \"models/BoW_TFIDFVectorizer_LogisticRegression_{label}.mdl\".format(label = label)\n",
    "    \n",
    "    if(check_if_file_exists(model_file_name)):\n",
    "        model = joblib.load(model_file_name)\n",
    "    else:\n",
    "        model = LogisticRegression(penalty='l2', C=1.2, n_jobs=-1)\n",
    "        model.fit(features_train, labels_train)\n",
    "\n",
    "        joblib.dump(model, model_file_name)\n",
    "\n",
    "    label_prediction = model.predict(features_test)\n",
    "\n",
    "    print(\"Accuracy Score for {label}: {accuracy_score:0.2f}%\".format(accuracy_score = accuracy_score(labels_test, label_prediction)*100, label=label))\n",
    "    print(\"F1 Score for {label}: {f1_score:0.2f}%\".format(f1_score = f1_score(labels_test, label_prediction, average='micro')*100, label=label))\n",
    "    print(\"Precision Score for {label}: {precision_score:0.2f}%\\n\".format(precision_score  = precision_score(labels_test, label_prediction, average='micro')*100, label=label))"
   ]
  },
  {
   "source": [
    "## Markov Chains"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                   RESTAURANT_ID  \\\n",
       "0    pizza-bulls-uskudar-altunizade-mah-istanbul   \n",
       "1         pizza-bulls-uskudar-ferah-mah-istanbul   \n",
       "2  pizza-bulls-kartal-soganlik-yeni-mah-istanbul   \n",
       "3       pizza-bulls-umraniye-cakmak-mah-istanbul   \n",
       "4        pizza-bulls-atasehir-fetih-mah-istanbul   \n",
       "\n",
       "                                         all_comment  comment_count  \n",
       "0  lezzeti eskisi gibi gelmedi bize. fark ödeyip ...           2293  \n",
       "1  her şey çok güzeldi. elinize sağlık. hizli ve ...           1764  \n",
       "2  cok pahali olmasi disinda bir problem yok gibi...           1743  \n",
       "3  çok lezzetli güvenle çoçuguma yedirebiliyorum ...           1582  \n",
       "4  servis ve hız 10 üzerinden 20.. bu siparişi is...           1277  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>RESTAURANT_ID</th>\n      <th>all_comment</th>\n      <th>comment_count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>pizza-bulls-uskudar-altunizade-mah-istanbul</td>\n      <td>lezzeti eskisi gibi gelmedi bize. fark ödeyip ...</td>\n      <td>2293</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>pizza-bulls-uskudar-ferah-mah-istanbul</td>\n      <td>her şey çok güzeldi. elinize sağlık. hizli ve ...</td>\n      <td>1764</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>pizza-bulls-kartal-soganlik-yeni-mah-istanbul</td>\n      <td>cok pahali olmasi disinda bir problem yok gibi...</td>\n      <td>1743</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>pizza-bulls-umraniye-cakmak-mah-istanbul</td>\n      <td>çok lezzetli güvenle çoçuguma yedirebiliyorum ...</td>\n      <td>1582</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>pizza-bulls-atasehir-fetih-mah-istanbul</td>\n      <td>servis ve hız 10 üzerinden 20.. bu siparişi is...</td>\n      <td>1277</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "source": [
    "sql_command = \"\"\"\n",
    "    WITH COMMENTS AS(\n",
    "    SELECT \"RESTAURANT_ID\",\n",
    "    STRING_AGG(LOWER(\"COMMENT_TEXT\"), ' ') AS ALL_COMMENT,\n",
    "    COUNT(\"COMMENT_TEXT\") AS COMMENT_COUNT\n",
    "    FROM \"ODS\".\"EXT_FB_COMMENT\" EFC\n",
    "    GROUP BY \"RESTAURANT_ID\"\n",
    "    )\n",
    "    SELECT * \n",
    "    FROM COMMENTS\n",
    "    ORDER BY COMMENT_COUNT DESC;\n",
    "    \"\"\"\n",
    "restaurant_df = pd.read_sql(sql_command,conn)\n",
    "restaurant_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def make_markov_model(cleaned_stories, n_gram=2):\n",
    "    markov_model = {}\n",
    "    for i in range(len(cleaned_stories)-n_gram-1):\n",
    "        curr_state, next_state = \"\", \"\"\n",
    "        for j in range(n_gram):\n",
    "            curr_state += cleaned_stories[i+j] + \" \"\n",
    "            next_state += cleaned_stories[i+j+n_gram] + \" \"\n",
    "        curr_state = curr_state[:-1]\n",
    "        next_state = next_state[:-1]\n",
    "        if curr_state not in markov_model:\n",
    "            markov_model[curr_state] = {}\n",
    "            markov_model[curr_state][next_state] = 1\n",
    "        else:\n",
    "            if next_state in markov_model[curr_state]:\n",
    "                markov_model[curr_state][next_state] += 1\n",
    "            else:\n",
    "                markov_model[curr_state][next_state] = 1\n",
    "    \n",
    "    # calculating transition probabilities\n",
    "    for curr_state, transition in markov_model.items():\n",
    "        total = sum(transition.values())\n",
    "        for state, count in transition.items():\n",
    "            markov_model[curr_state][state] = count/total\n",
    "        \n",
    "    return markov_model\n",
    "\n",
    "def generate_story(markov_model, limit=100, start='my god'):\n",
    "    n = 0\n",
    "    curr_state = start\n",
    "    next_state = None\n",
    "    story = \"\"\n",
    "    story+=curr_state+\" \"\n",
    "    while n<limit:\n",
    "        next_state = random.choices(list(markov_model[curr_state].keys()),\n",
    "                                    list(markov_model[curr_state].values()))\n",
    "        \n",
    "        curr_state = next_state[0]\n",
    "        story+=curr_state+\" \"\n",
    "        n+=1\n",
    "    return story"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.  yemek çok lezzetliydi ve restoran bana çok yakın olmamasına rağmen sıcaktı da soğan halkaları için de çok teşekkür ederim atakan beye ve tüm ekibe teşekkür ederim pizzalar sıcak ve lezzetli geldi tatlı ikramınız için çok teşekkürler her şey çok iyiydi getiren arkadaşları \n1.  yemek çok lezzetliydi ve yanında 2 adet ikram sufle geldi i̇ftar vakti olmasına rağmen vaktinde geldi bilal beye teşekkür ederim bilal beye sufle için atakan beye ilgi ve ikram için yunus beye çok teşekkür ederiz restorandan beni arayan restoran çalışanı oldukça içten \n2.  yemek çok lezzetliydi ve kurye de cok nazikti cheddar yoktu resmen çok basit bir not yazdık evde uyuyanlar lütfen zile basmayın notları okumayacaksanız söyleyelim yemeksepetine kaldırsınlar çok güzel her zamanki gibi mükemmel ayrıca ikram için teşekkür ederim pizza siparişi için en lezzetli \n3.  yemek çok lezzetliydi ve restoran bana çok yakın olmamasına rağmen sıcaktı da soğan halkaları da ayrıca yanıktı restoran müdürü bayagı ilgiliydihızlı ve sıcak geldi kezzetliydi ancak ince hamur en sevdiğimiz çalışanların hepsi çok nazik ve işlerini çok iyi çok iyiydi teşekkürler tam \n4.  yemek çok güzeldi semih beye çok teşekkürler ellerinize sağlık çok güzeldi bu sebeple ayrı bir teşekkürü hakediyorsunuz merhaba pizza bullsu tercih edeceğim dahi soruldu restoran siparişi aldığı andan teslim ettiği ana kadar son derece memnun kaldım bilal beye çok teşekkürler muazzam mustafa \n5.  yemek çok güzeldi semih bey harikasınız sıcak geldi atakan kardeşim sağolsun çok kibar teşekkür ederim atakan beye teşekkürler bana tatlı hediye göndermişler çok hoşuma gitti teşekkür ediyorum kendilerine bilal bey muhteşem bir pazar akşamı keyfi yaşadık bilal beye cok teşekkür ederiz her \n6.  yemek çok güzeldi semih beye çok teşekkür her şey harikaydı i̇lgililer her şey çok güzeldi ta ki eleman bozuk yok kalanını bir sonraki siparişte halledelim diyene kadar bana borçlusunuz her şey çok güzeldi üstelik tatlı ikramları için de çok teşekkür ederim tatlı \n7.  yemek çok güzeldi semih beye çok teşekkür ederiz bilal beye mükemmel iletişimi ve desteği için teşekkür ederim atakan beye teşekkürler bilal beye teşekkür ederiz ismini unuttum lezizdi ve cok cabuk geldi lezzetli hızlı lezzetliydi atakan beye ilgisinden dolayı çok teşekkür ederim ellerinize \n8.  yemek çok lezzetliydi ve hızlıydı tesekkurler çok hızlı hem de pismemis olarak nasil gonderebildiniz tebrik ederim pizza çok güzel ve sıcaktı teşekkür ederim harika hatalarını telafi etmek için elinden geleni yapan bir firma fiyatlar yüksek ama kaliteli hediye tatlım gelmedi ama kurye \n9.  yemek çok lezzetliydi ve kuriyeniz atakan bey çok nazik ve tam bir beyefendi olan burak beye de teşekkürler kuryeniz burak çok kibardı hızlı geldi ayrıca hediye olarak tatlı getirmişler teşekkür ediyorum kuryenize de geçmiş olsun her zaman tercih ettiğim bir yer her \n10.  yemek çok lezzetliydi ve her şey çok güzeldi atakan ustam eline sağlık pizzaları aşırı güzel ve en lezzetli pizzalardan biriydi ayrıca gönderdiğiniz sufleler için de ayrıca çok teşekkürler ayrıca siparişimde tam zamanında geldi berbat bilal bey çok ilgili birisi i̇yi kenan beye \n11.  yemek çok lezzetliydi ve getiren arkadasta cok hizli getirdi ve adres çok tarif edilemez bir yerde ol asına rağmen konumu buldu lezzet desen mükemmel ilgi desen 10 numara hizmet bilal bey çok sağolsun çok kibar ve işin ehli atakan kardeşime teşekkürler kurye \n12.  yemek çok lezzetliydi ve hızlıydı tesekkurler çok hızlı ve çok nazikler teşekkürler atakan abiya selam bir sonrakine ikramını bekleriz atakan beye ozel ilgilerinden dolayi tesekkur ederiz i̇lgisi icin semih beye ikramı için teşekkürler atakan beye ve tüm ekibe teşekkürler lezzetiniz çok kotuydu \n13.  yemek çok lezzetliydi ve sıcak geldi çok lezzetliydi ve kurye arkadaşımıza teşekkür ederim siparişimde soğan halkası unutulmuştu ama sorun değil anlayabiliyoruz emeklerinize sağlık sizden sipariş vermeye devam atakan beye güler yüzlülüğünden dolayı 10 puan lezzet bilal beye ekstra tesekkur ediyorum orta boy \n14.  yemek çok lezzetliydi ve her şey çok güzel bir yemekti tesekkurler engin kurye berat beye tesekkur ederim restoransa her zamanki gibi lezzetli bir pizza geldi hizli olmadgi icin de sogumustu sürekli alışveriş yaptığım çok da memnun kaldım elma dilim patateslerde çiğ tadı \n15.  yemek çok lezzetliydi ve her şey çok lezzetli çok seviyorum 3 şu yaşıma kadar kaç adet kurye gördüm hiçbiri mustafanın parmağı olamaz 10puan mustafa için tahmini sipariş süresi uzun da olsa gelen pizza gayet sıcaktı küçük tatlı hediyeleri çok güzel hizmetleriniz için \n16.  yemek çok güzeldi semih beye teşekkürler tam anlamı ile türkiyenin zincir pizzacıları içinde 1 numara uzun yıllardır severek sipariş verdiğim için yapıcı olması adına bu yorumu yazıyorum i̇yi çalışmalar dilerim her zaman harika her zamanki gibi muhteşem bir hizmet verdi bilal beye \n17.  yemek çok lezzetliydi ve hızlı ulaştı he zamanki gibi cumali beye ayrıca teşekkürler çok nazikdi pizza ve sufle gelmedi madem öyle bari hiç konuşmasaydık kendi tatlı siparişimizi de boş yere iptal ettik biraz dikkat lütfen efsanesiniz tek sorun pizza kesimleri en iyisi \n18.  yemek çok lezzetliydi ve hızlıydı tesekkurler çok hızlı bize ulaştırdığı için teşekkür ederiz newyork ve boston pizza sipariş vereceksem tercih ettiğim tek restaurant pizza bulls oluyor çok teşekkür ederim 10 üzerinden 100 verilesi muhteşem ilgisi ve ince ikramları için çok teşekkür ederim \n19.  yemek çok güzeldi semih beye ilgisinden dolayı teşekkür ediyorum yağmur olmasına rağmen lezzetiyle telafi ediyor lezzet ve servis mükemmel teşekkürler mustafa bey çok teşekkürler pizzası leziz o kadar güzel bir pizza markasıydı tadı hala güzel 45 dk da geldi hediye olarak sufle \n"
     ]
    }
   ],
   "source": [
    "restaurant_df['clean_comment'] = restaurant_df['all_comment'].apply(clean_text)\n",
    "text = restaurant_df.loc[0]['clean_comment'].split()\n",
    "\n",
    "markov_model = make_markov_model(text)\n",
    "\n",
    "for i in range(20):\n",
    "    print(str(i)+\". \", generate_story(markov_model, start=\"yemek çok\", limit=20))"
   ]
  },
  {
   "source": [
    "## Convolutional Neural Network"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                             IMAGE_LINK  \\\n",
       "0     https://cdn.yemeksepeti.com/ProductImages/corb...   \n",
       "1     https://cdn.yemeksepeti.com/ProductImages/corb...   \n",
       "2     https://cdn.yemeksepeti.com/ProductImages/corb...   \n",
       "3     https://cdn.yemeksepeti.com/ProductImages/corb...   \n",
       "4     https://cdn.yemeksepeti.com/ProductImages/corb...   \n",
       "...                                                 ...   \n",
       "4961  https://cdn.yemeksepeti.com/restaurant/TR_ISTA...   \n",
       "4962  https://cdn.yemeksepeti.com/restaurant/TR_ISTA...   \n",
       "4963  https://cdn.yemeksepeti.com/restaurant/TR_ISTA...   \n",
       "4964  https://cdn.yemeksepeti.com/restaurant/TR_ISTA...   \n",
       "4965  https://cdn.yemeksepeti.com/restaurant/TR_ISTA...   \n",
       "\n",
       "                                                 SOURCE  IS_PIZZA  \n",
       "0     [b'\\xff', b'\\xd8', b'\\xff', b'\\xe0', b'\\x00', ...         0  \n",
       "1     [b'\\xff', b'\\xd8', b'\\xff', b'\\xe0', b'\\x00', ...         0  \n",
       "2     [b'\\xff', b'\\xd8', b'\\xff', b'\\xe0', b'\\x00', ...         0  \n",
       "3     [b'\\xff', b'\\xd8', b'\\xff', b'\\xe0', b'\\x00', ...         0  \n",
       "4     [b'\\xff', b'\\xd8', b'\\xff', b'\\xe0', b'\\x00', ...         0  \n",
       "...                                                 ...       ...  \n",
       "4961  [b'\\xff', b'\\xd8', b'\\xff', b'\\xe0', b'\\x00', ...         1  \n",
       "4962  [b'\\xff', b'\\xd8', b'\\xff', b'\\xe0', b'\\x00', ...         0  \n",
       "4963  [b'\\xff', b'\\xd8', b'\\xff', b'\\xe0', b'\\x00', ...         1  \n",
       "4964  [b'\\xff', b'\\xd8', b'\\xff', b'\\xe0', b'\\x00', ...         1  \n",
       "4965  [b'\\xff', b'\\xd8', b'\\xff', b'\\xe0', b'\\x00', ...         0  \n",
       "\n",
       "[4966 rows x 3 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>IMAGE_LINK</th>\n      <th>SOURCE</th>\n      <th>IS_PIZZA</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>https://cdn.yemeksepeti.com/ProductImages/corb...</td>\n      <td>[b'\\xff', b'\\xd8', b'\\xff', b'\\xe0', b'\\x00', ...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>https://cdn.yemeksepeti.com/ProductImages/corb...</td>\n      <td>[b'\\xff', b'\\xd8', b'\\xff', b'\\xe0', b'\\x00', ...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>https://cdn.yemeksepeti.com/ProductImages/corb...</td>\n      <td>[b'\\xff', b'\\xd8', b'\\xff', b'\\xe0', b'\\x00', ...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>https://cdn.yemeksepeti.com/ProductImages/corb...</td>\n      <td>[b'\\xff', b'\\xd8', b'\\xff', b'\\xe0', b'\\x00', ...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>https://cdn.yemeksepeti.com/ProductImages/corb...</td>\n      <td>[b'\\xff', b'\\xd8', b'\\xff', b'\\xe0', b'\\x00', ...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>4961</th>\n      <td>https://cdn.yemeksepeti.com/restaurant/TR_ISTA...</td>\n      <td>[b'\\xff', b'\\xd8', b'\\xff', b'\\xe0', b'\\x00', ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4962</th>\n      <td>https://cdn.yemeksepeti.com/restaurant/TR_ISTA...</td>\n      <td>[b'\\xff', b'\\xd8', b'\\xff', b'\\xe0', b'\\x00', ...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4963</th>\n      <td>https://cdn.yemeksepeti.com/restaurant/TR_ISTA...</td>\n      <td>[b'\\xff', b'\\xd8', b'\\xff', b'\\xe0', b'\\x00', ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4964</th>\n      <td>https://cdn.yemeksepeti.com/restaurant/TR_ISTA...</td>\n      <td>[b'\\xff', b'\\xd8', b'\\xff', b'\\xe0', b'\\x00', ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4965</th>\n      <td>https://cdn.yemeksepeti.com/restaurant/TR_ISTA...</td>\n      <td>[b'\\xff', b'\\xd8', b'\\xff', b'\\xe0', b'\\x00', ...</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>4966 rows × 3 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 31
    }
   ],
   "source": [
    "sql_command = \"\"\"\n",
    "    SELECT\n",
    "    DISTINCT\n",
    "    FPI.\"IMAGE_LINK\",\n",
    "    FPIS.\"SOURCE\",\n",
    "    CASE WHEN LOWER(EFM.\"CATEGORY_NAME\") LIKE '%pizza%' OR LOWER(EFM.\"PRODUCT_NAME\") LIKE '%pizza%' OR LOWER(EFM.\"PRODUCT_DESCRIPTION\") LIKE '%pizza%' THEN 1 ELSE 0 END AS \"IS_PIZZA\"\n",
    "    FROM \"ODS\".\"EXT_FB_MENU\" EFM\n",
    "    INNER JOIN \"ODS\".\"EXT_FB_PRODUCT_IMAGE\" FPI ON (EFM.\"PRODUCT_ID\" = FPI.\"PRODUCT_ID\")\n",
    "    INNER JOIN \"ODS\".\"EXT_FB_PRODUCT_IMAGE_SOURCE\" FPIS ON (FPI.\"IMAGE_LINK\" = FPIS.\"IMAGE_LINK\");\n",
    "    \"\"\"\n",
    "image_source_df = pd.read_sql(sql_command,conn)\n",
    "image_source_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Feature Shape: (4966, 200, 200, 3) Label Shape: (4966, 2)\n",
      "Epoch 1/5\n",
      "218/218 [==============================] - 88s 402ms/step - loss: 0.5073 - accuracy: 0.7604 - val_loss: 0.5369 - val_accuracy: 0.7584\n",
      "Epoch 2/5\n",
      "218/218 [==============================] - 87s 397ms/step - loss: 0.2859 - accuracy: 0.8789 - val_loss: 0.3591 - val_accuracy: 0.8497\n",
      "Epoch 3/5\n",
      "218/218 [==============================] - 87s 397ms/step - loss: 0.2053 - accuracy: 0.9163 - val_loss: 0.3146 - val_accuracy: 0.8792\n",
      "Epoch 4/5\n",
      "218/218 [==============================] - 87s 401ms/step - loss: 0.1574 - accuracy: 0.9376 - val_loss: 0.3462 - val_accuracy: 0.8779\n",
      "Epoch 5/5\n",
      "218/218 [==============================] - 89s 407ms/step - loss: 0.1129 - accuracy: 0.9571 - val_loss: 0.2569 - val_accuracy: 0.8993\n",
      "Test Score:  0.2569006085395813\n",
      "Test accuracy:  0.899328887462616\n"
     ]
    }
   ],
   "source": [
    "features = []\n",
    "labels = []\n",
    "#image_id = []\n",
    "\n",
    "for i in range(len(image_source_df)):\n",
    "    image_source = byte_image_to_numpy_array(image_source_df.iloc[i][\"SOURCE\"], 200)\n",
    "    is_pizza = image_source_df.iloc[i][\"IS_PIZZA\"]\n",
    "    #image_id.append(image_source_df.iloc[i][\"IMAGE_LINK\"])\n",
    "    features.append(image_source)\n",
    "    labels.append(is_pizza)\n",
    "\n",
    "#Image.fromarray(features[2381])\n",
    "\n",
    "features = np.array(features).reshape(-1, 200, 200, 3)\n",
    "features = features.astype('float32')/255\n",
    "labels = np_utils.to_categorical(labels, 2)\n",
    "\n",
    "batch_size = 16\n",
    "epochs = 5\n",
    "\n",
    "print(\"Feature Shape: {f_shape} Label Shape: {l_shape}\".format(f_shape=features.shape, l_shape=labels.shape))\n",
    "\n",
    "features_train, features_test, labels_train, labels_test = train_test_split(features, labels, test_size = 0.3, random_state = 9)\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3,3), padding='same', activation=tf.nn.relu,\n",
    "                           input_shape=(200, 200, 3)),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2), strides=2),\n",
    "    tf.keras.layers.Conv2D(32, (3,3), padding='same', activation=tf.nn.relu),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2), strides=2),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(2,  activation=tf.nn.softmax)\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "model.fit(features_train, labels_train, batch_size = batch_size, epochs = epochs, verbose = 1, validation_data = (features_test, labels_test))\n",
    "score = model.evaluate(features_test, labels_test, verbose = 0 )\n",
    "print(\"Test Score: \", score[0])\n",
    "print(\"Test accuracy: \", score[1])"
   ]
  },
  {
   "source": [
    "# Sources\n",
    "\n",
    " 1. [Selenium Documentation](https://selenium-python.readthedocs.io/)\n",
    " 2. [Selenium choose element by partial id](https://stackoverflow.com/questions/15845563/choose-element-by-partial-id-using-selenium-with-python)\n",
    " 3. [Selenium scroll down to end of the page](https://pythonbasics.org/selenium-scroll-down/)\n",
    " 4. [Selenium click button](https://stackoverflow.com/questions/52405456/selenium-how-to-click-on-javascript-button/52405550)\n",
    " 5. [Markov Chains](https://www.kaggle.com/orion99/markov-chain-nlp)\n",
    " 6. [Bag of Words](https://github.com/Suji04/NormalizedNerd/blob/master/Introduction%20to%20NLP/Bag%20of%20Words%20%2B%20TF-IDF.ipynb)\n",
    " 7. [Turkish Porter Stemmer](https://github.com/otuncelli/turkish-stemmer-python)\n",
    " 8. [Scikit-Learn: Save & Restore Models](https://stackabuse.com/scikit-learn-save-and-restore-models)\n",
    " 9. [Joblib vs Pickle](https://stackoverflow.com/questions/12615525/what-are-the-different-use-cases-of-joblib-versus-pickle)\n",
    " 10. [Hide warnings in Python](https://stackoverflow.com/questions/9031783/hide-all-warnings-in-ipython)\n",
    " 11. [Slow scrolling down the page using selenium](https://stackoverflow.com/questions/30942041/slow-scrolling-down-the-page-using-selenium)\n",
    " 12. [Download images using urllib](https://stackoverflow.com/questions/49627458/python-selenium-download-images-jpeg-png-or-pdf-using-chromedriver)\n",
    " 13. [Saving an image to Postgres](https://stackoverflow.com/questions/16763904/how-to-save-a-image-file-on-a-postgres-database)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}