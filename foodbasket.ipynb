{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.0 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "0e8f02916ce4ec57490847cc8c54c12a9dae65680be9326a3269d9b7a61d6d19"
   }
  },
  "interpreter": {
   "hash": "0e8f02916ce4ec57490847cc8c54c12a9dae65680be9326a3269d9b7a61d6d19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Web Scraping"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv(\"dev.env\")\n",
    "import os\n",
    "\n",
    "db_name = os.getenv(\"db_name\")\n",
    "db_username = os.getenv(\"db_username\")\n",
    "db_password = os.getenv(\"db_password\")\n",
    "db_host = os.getenv(\"db_host\")\n",
    "db_port = os.getenv(\"db_port\")\n",
    "website = os.getenv(\"website\")\n",
    "city_link = os.getenv(\"city_link\")\n",
    "chrome_path = os.getenv(\"chrome_path\")\n",
    "selenium_chrome_driver_path = os.getenv(\"selenium_chrome_driver_path\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import time\n",
    "import math\n",
    "import numpy as np\n",
    "import os.path\n",
    "import pandas as pd\n",
    "import re\n",
    "import pycld2\n",
    "import nltk\n",
    "from datetime import date, timedelta, datetime\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By \n",
    "from selenium.webdriver.support.ui import WebDriverWait \n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from nltk.corpus import stopwords\n",
    "from TurkishStemmer import TurkishStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "nltk.download('stopwords', quiet=True)\n",
    "\n",
    "stemmer = TurkishStemmer()\n",
    "\n",
    "conn_string = 'host={pghost} port={pgport} dbname={pgdatabase} user={pguser} password={pgpassword}'.format(pgdatabase=db_name,pguser=db_username,pgpassword=db_password,pghost=db_host,pgport=db_port)\n",
    "conn=psycopg2.connect(conn_string)\n",
    "cur=conn.cursor()\n",
    "\n",
    "options = Options()\n",
    "options.binary_location = chrome_path\n",
    "\n",
    "def check_if_table_exists(schema,table):\n",
    "    cur.execute(\"select exists(select * from information_schema.tables where table_schema='{schema}' AND table_name='{table}')\".format(schema=schema, table=table))\n",
    "    return cur.fetchone()[0]\n",
    "\n",
    "def check_if_index_exists(index):\n",
    "    cur.execute(\"SELECT EXISTS(SELECT * FROM PG_CLASS WHERE relname = '{index}')\".format(index=index))\n",
    "    return cur.fetchone()[0]\n",
    "\n",
    "def check_if_file_exists(filename):\n",
    "    return os.path.isfile(filename)\n",
    "\n",
    "def execute_mogrify(conn, df, schema, table):\n",
    "    tuples = [tuple(x) for x in df.to_numpy()]\n",
    "    cols = '\"'+'\",\"'.join(list(df.columns))+'\"'\n",
    "    cursor = conn.cursor()    \n",
    "    try:\n",
    "        for tup in tuples:\n",
    "            query  = \"\"\"INSERT INTO \"{schema}\".\"{table}\"({cols}) VALUES ({values}) ON CONFLICT DO NOTHING\"\"\".format(schema=schema,table=table, cols=cols, values=\",\".join(map(str,tup)))\n",
    "            cursor.execute(query)\n",
    "            conn.commit()\n",
    "    except (Exception, psycopg2.DatabaseError) as error:\n",
    "        print(\"Error: %s\" % error)\n",
    "        conn.rollback()\n",
    "        cursor.close()\n",
    "        return 1\n",
    "    cursor.close()\n",
    "\n",
    "def df_column_conversation(df, column_name, type):\n",
    "    if(type == 'timestamp'):\n",
    "        df[column_name] = df[column_name].apply(lambda x: f\"'{x}'::timestamp\")\n",
    "    if(type == 'text'):\n",
    "        df[column_name] = df[column_name].str.replace(\"'\",\"\").apply(lambda x: f\"'{x}'\")\n",
    "    if(type == 'date'):\n",
    "        df[column_name] = df[column_name].apply(lambda x: f\"'{x}'::date\")\n",
    "    if(type == 'numeric'):\n",
    "        df[column_name] = df[column_name].apply(str).str.replace(',','.')\n",
    "    if(type == 'integer'):\n",
    "        df[column_name] = df[column_name].apply(str).str.replace(',','.').apply(float).astype('Int64').apply(str)\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"[,.\\\"\\'!@#$%^&*(){}?/;`~:<>+=-\\\\]\", \"\", text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Table ODS.EXT_FB_RESTAURANT already exists.\nTable ODS.EXT_FB_MENU already exists.\nTable ODS.EXT_FB_COMMENT already exists.\nTable EDW.DWH_FB_COMMENT already exists.\n"
     ]
    }
   ],
   "source": [
    "if(check_if_table_exists('ODS','EXT_FB_RESTAURANT')):\n",
    "    print('Table ODS.EXT_FB_RESTAURANT already exists.')   \n",
    "else:\n",
    "    start_time = math.trunc(time.time())\n",
    "    cur.execute(\"\"\"\n",
    "    CREATE TABLE \"ODS\".\"EXT_FB_RESTAURANT\"\n",
    "    (\n",
    "    \"RESTAURANT_ID\" text NOT NULL,\n",
    "    \"RESTAURANT_NAME\" text,\n",
    "    \"RESTAURANT_LINK\" text,\n",
    "    \"DATE\" date,    \n",
    "    CONSTRAINT \"RESTAURANT_ID\" UNIQUE (\"RESTAURANT_ID\")\n",
    "    );\n",
    "    \"\"\")\n",
    "    cur.execute('COMMIT;')\n",
    "    end_time = math.trunc(time.time())\n",
    "    print(\"Table ODS.EXT_FB_RESTAURANT created in {execute_time} seconds.\".format(execute_time=end_time-start_time))\n",
    "\n",
    "if(check_if_table_exists('ODS','EXT_FB_MENU')):\n",
    "    print('Table ODS.EXT_FB_MENU already exists.')   \n",
    "else:\n",
    "    start_time = math.trunc(time.time())\n",
    "    cur.execute(\"\"\"\n",
    "    CREATE TABLE \"ODS\".\"EXT_FB_MENU\"\n",
    "    (\n",
    "    \"PRODUCT_ID\" text NOT NULL,\n",
    "    \"RESTAURANT_ID\" text,\n",
    "    \"CATEGORY_NAME\" text,\n",
    "    \"PRODUCT_NAME\" text,\n",
    "    \"PRODUCT_DESCRIPTION\" text,\n",
    "    \"PRODUCT_LISTED_PRICE\" text,\n",
    "    \"PRODUCT_PRICE\" text,\n",
    "    \"DISCOUNT\" boolean,\n",
    "    \"DESIGN_TYPE\" text,\n",
    "    \"DATE\" date,\n",
    "    CONSTRAINT \"PRODUCT_ID\" UNIQUE (\"PRODUCT_ID\")\n",
    "    );\n",
    "    \"\"\")\n",
    "    cur.execute('COMMIT;')\n",
    "    end_time = math.trunc(time.time())\n",
    "    print(\"Table ODS.EXT_FB_MENU created in {execute_time} seconds.\".format(execute_time=end_time-start_time))\n",
    "\n",
    "if(check_if_table_exists('ODS','EXT_FB_COMMENT')):\n",
    "    print('Table ODS.EXT_FB_COMMENT already exists.')   \n",
    "else:\n",
    "    start_time = math.trunc(time.time())\n",
    "    cur.execute(\"\"\"\n",
    "    CREATE TABLE \"ODS\".\"EXT_FB_COMMENT\"\n",
    "    (\n",
    "    \"RESTAURANT_ID\" text,\n",
    "    \"USERNAME\" text,\n",
    "    \"COMMENT_TEXT\" text,\n",
    "    \"COMMENT_DATE\" text,\n",
    "    \"SPEED\" text,\n",
    "    \"SERVING\" text,\n",
    "    \"FLAVOUR\" text,\n",
    "    \"DATE\" date,\n",
    "    CONSTRAINT \"UNIQUE_COMMENTS\" UNIQUE (\"RESTAURANT_ID\", \"USERNAME\", \"COMMENT_TEXT\")\n",
    "    );\n",
    "    \"\"\")\n",
    "    cur.execute('COMMIT;')\n",
    "    end_time = math.trunc(time.time())\n",
    "    print(\"Table ODS.EXT_FB_COMMENT created in {execute_time} seconds.\".format(execute_time=end_time-start_time))\n",
    "\n",
    "if(check_if_table_exists('EDW','DWH_FB_COMMENT')):\n",
    "    print('Table EDW.DWH_FB_COMMENT already exists.')   \n",
    "else:\n",
    "    start_time = math.trunc(time.time())\n",
    "    cur.execute(\"\"\"\n",
    "    CREATE TABLE \"EDW\".\"DWH_FB_COMMENT\"\n",
    "    (\n",
    "    \"RESTAURANT_ID\" text,\n",
    "    \"USERNAME\" text,\n",
    "    \"COMMENT_TEXT\" text,\n",
    "    \"COMMENT_DATE\" date,\n",
    "    \"SPEED\" integer,\n",
    "    \"SERVING\" integer,\n",
    "    \"FLAVOUR\" integer,\n",
    "    \"DATE\" date,\n",
    "    CONSTRAINT \"UNIQUE_COMMENTS\" UNIQUE (\"RESTAURANT_ID\", \"USERNAME\", \"COMMENT_TEXT\")\n",
    "    );\n",
    "    \"\"\")\n",
    "    cur.execute('COMMIT;')\n",
    "    end_time = math.trunc(time.time())\n",
    "    print(\"Table EDW.DWH_FB_COMMENT created in {execute_time} seconds.\".format(execute_time=end_time-start_time))\n",
    "\n",
    "cur.execute(\"\"\"\n",
    "CREATE OR REPLACE FUNCTION public.try_cast(_in text, INOUT _out anyelement)\n",
    "    LANGUAGE 'plpgsql'\n",
    "AS $BODY$\n",
    "BEGIN\n",
    "   EXECUTE format('SELECT %L::%s', $1, pg_typeof(_out))\n",
    "   INTO  _out;\n",
    "EXCEPTION WHEN others THEN\n",
    "   -- do nothing: _out already carries default\n",
    "END\n",
    "$BODY$;\n",
    "\"\"\")\n",
    "cur.execute('COMMIT;')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "datetime.date(2021, 6, 11)"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "cur.execute(\"\"\"\n",
    "WITH DATES AS(\n",
    "SELECT \n",
    "MAX(\"DATE\") AS \"DATE\"\n",
    "FROM \"ODS\".\"EXT_FB_MENU\" EFM\n",
    "UNION ALL\n",
    "SELECT \n",
    "MAX(\"DATE\") AS \"DATE\"\n",
    "FROM \"ODS\".\"EXT_FB_COMMENT\" EFC\n",
    ")\n",
    "SELECT \n",
    "MAX(\"DATE\") AS \"LAST_EXECUTION_DATE\"\n",
    "FROM DATES;\n",
    "\"\"\")\n",
    "last_execution_date = cur.fetchone()[0]\n",
    "last_execution_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "restaurant_list = []\n",
    "end_date = min(date(2021,6,11),(date.today() - timedelta(days=1)))\n",
    "\n",
    "driver = webdriver.Chrome(options=options, executable_path=selenium_chrome_driver_path)\n",
    "if(last_execution_date < end_date):\n",
    "    driver.get(city_link)\n",
    "    time.sleep(5)\n",
    "    for i in range(25):\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(2)\n",
    "    city_restaurant_groups = driver.find_elements_by_class_name(\"restaurant-main-info\")\n",
    "    for restaurant in city_restaurant_groups:\n",
    "        restaurant_name = restaurant.find_element_by_class_name(\"restaurant-display-name\").text\n",
    "        restaurant_name = restaurant_name.replace(\"YENİ \", \"\")\n",
    "        restaurant_link = restaurant.find_element_by_class_name(\"restaurant-display-name\").find_element_by_xpath(\".//a\").get_attribute('href')\n",
    "        restaurant_id = restaurant_link.split(\"/\")[-1]\n",
    "        if(len(restaurant_link) < 2):\n",
    "            continue\n",
    "        restaurant_list.append([restaurant_id,restaurant_name,restaurant_link])\n",
    "    restaurant_df = pd.DataFrame(restaurant_list, columns=[\"RESTAURANT_ID\",\"RESTAURANT_NAME\",\"RESTAURANT_LINK\"])\n",
    "\n",
    "    df_column_conversation(restaurant_df, 'RESTAURANT_ID', 'text')\n",
    "    df_column_conversation(restaurant_df, 'RESTAURANT_NAME', 'text')\n",
    "    df_column_conversation(restaurant_df, 'RESTAURANT_LINK', 'text')    \n",
    "    restaurant_df['DATE'] = \"'\"+ datetime.strftime(date.today(), \"%Y-%m-%d\") + \"'::date\"\n",
    "    execute_mogrify(conn,restaurant_df,\"ODS\",\"EXT_FB_RESTAURANT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_command = \"\"\"\n",
    "    SELECT\n",
    "    \"RESTAURANT_ID\"\n",
    "    FROM \"ODS\".\"EXT_FB_RESTAURANT\" EFR\n",
    "    WHERE 1=1\n",
    "    AND NOT EXISTS(SELECT NULL FROM \"ODS\".\"EXT_FB_MENU\" EFM WHERE EFR.\"RESTAURANT_ID\" = EFM.\"RESTAURANT_ID\");\n",
    "    \"\"\"\n",
    "restaurant_df = pd.read_sql(sql_command,conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(last_execution_date < end_date):\n",
    "    for i in range(len(restaurant_df)):\n",
    "        sublink = restaurant_df.loc[i,\"RESTAURANT_ID\"]\n",
    "        restaurant_link = \"{website}/{sublink}\".format(website=website,sublink=sublink)\n",
    "        \n",
    "        driver.get(restaurant_link)\n",
    "        time.sleep(5)\n",
    "\n",
    "        try:\n",
    "            if(\"sipariş verebilirsiniz.\" in driver.find_element_by_xpath('//*[@id=\"restaurantDetail\"]/div/div[2]/h3').text):\n",
    "                continue\n",
    "            else:\n",
    "                pass\n",
    "        except Exception:\n",
    "            pass\n",
    "        \n",
    "        menu = driver.find_element_by_xpath('//*[@id=\"restaurant_menu\"]')\n",
    "        categories = menu.find_elements_by_xpath('//*[contains(@id,\"menu_\")]')\n",
    "\n",
    "        menu_list = []\n",
    "\n",
    "        for category in categories:\n",
    "            category_name = category.find_element_by_xpath(\".//b\").text\n",
    "            for product in category.find_elements_by_xpath(\".//div[2]/ul/li\"):\n",
    "                try:\n",
    "                    design_type = \"list\"\n",
    "                    try:\n",
    "                        product_id = product.find_elements_by_class_name(\"getProductDetail\")[-1].get_attribute('data-product-id')\n",
    "                        product_name = product.find_elements_by_class_name(\"getProductDetail\")[-1].text\n",
    "                    except:\n",
    "                        product_id = product.find_element_by_xpath(\".//strong\").get_attribute('data-product-id')\n",
    "                        product_name = product.find_element_by_xpath(\".//strong\").text\n",
    "                        design_type = \"card\"\n",
    "                    try:\n",
    "                        product_description = product.find_element_by_class_name(\"product-desc\").text\n",
    "                        product_price = product.find_element_by_class_name(\"price\").text    \n",
    "                    except:\n",
    "                        product_description = product.find_element_by_class_name(\"productInfo\").text\n",
    "                        product_price = product.find_element_by_class_name(\"newPrice\").text\n",
    "                        if(not(design_type==\"card\")):\n",
    "                            design_type = \"box\"\n",
    "                    discount = \"TRUE\"\n",
    "                    try:              \n",
    "                        if(design_type==\"list\"):\n",
    "                            product_listed_price = product.find_element_by_class_name(\"listed-price\").text\n",
    "                        if(design_type in [\"card\",\"box\"]):\n",
    "                            product_listed_price = product.find_element_by_class_name(\"listedPrice\").text\n",
    "                    except:\n",
    "                        product_listed_price = product_price\n",
    "                        discount = \"FALSE\"\n",
    "                    menu_list.append([product_id,sublink,category_name,product_name,product_description,product_listed_price,product_price,discount,design_type])\n",
    "                except:\n",
    "                    continue\n",
    "        menu_df = pd.DataFrame(menu_list, columns=[\"PRODUCT_ID\",\"RESTAURANT_ID\",\"CATEGORY_NAME\",\"PRODUCT_NAME\",\"PRODUCT_DESCRIPTION\",\"PRODUCT_LISTED_PRICE\",\"PRODUCT_PRICE\",\"DISCOUNT\",\"DESIGN_TYPE\"])    \n",
    "        menu_df = menu_df[menu_df['PRODUCT_ID'].str.len() > 0]\n",
    "        menu_df = menu_df[menu_df['PRODUCT_NAME'].str.len() > 0]\n",
    "\n",
    "        df_column_conversation(menu_df, 'PRODUCT_ID', 'text')\n",
    "        df_column_conversation(menu_df, 'RESTAURANT_ID', 'text')\n",
    "        df_column_conversation(menu_df, 'CATEGORY_NAME', 'text')\n",
    "        df_column_conversation(menu_df, 'PRODUCT_NAME', 'text')\n",
    "        df_column_conversation(menu_df, 'PRODUCT_DESCRIPTION', 'text')\n",
    "        df_column_conversation(menu_df, 'PRODUCT_LISTED_PRICE', 'text')\n",
    "        df_column_conversation(menu_df, 'PRODUCT_PRICE', 'text')\n",
    "        df_column_conversation(menu_df, 'DESIGN_TYPE', 'text')\n",
    "        menu_df['DATE'] = \"'\"+ datetime.strftime(date.today(), \"%Y-%m-%d\") + \"'::date\"\n",
    "        execute_mogrify(conn,menu_df,\"ODS\",\"EXT_FB_MENU\")\n",
    "    menu_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                        RESTAURANT_ID\n",
       "41              fitchino-avcilar-ambarli-mah-istanbul\n",
       "17  dominos-pizza-atasehir-ataturk-mah-girne-cad-i...\n",
       "56   kurucesme-kahvesi-atasehir-barbaros-mah-istanbul\n",
       "72           bocek-kadikoy-caferaga-mah-moda-istanbul\n",
       "14              mondes-besiktas-mecidiye-mah-istanbul\n",
       "..                                                ...\n",
       "42  food-hall-istanbul-beyoglu-asmalimescit-mah-is...\n",
       "61        pizza-hut-umraniye-ihlamurkuyu-mah-istanbul\n",
       "64                un-po-beyoglu-kemankes-mah-istanbul\n",
       "43    vera-pizza-pasta-bakirkoy-cevizlik-mah-istanbul\n",
       "48  kafein-plus-kucukcekmece-tevfikbey-mah-sefakoy...\n",
       "\n",
       "[79 rows x 1 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>RESTAURANT_ID</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>41</th>\n      <td>fitchino-avcilar-ambarli-mah-istanbul</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>dominos-pizza-atasehir-ataturk-mah-girne-cad-i...</td>\n    </tr>\n    <tr>\n      <th>56</th>\n      <td>kurucesme-kahvesi-atasehir-barbaros-mah-istanbul</td>\n    </tr>\n    <tr>\n      <th>72</th>\n      <td>bocek-kadikoy-caferaga-mah-moda-istanbul</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>mondes-besiktas-mecidiye-mah-istanbul</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>42</th>\n      <td>food-hall-istanbul-beyoglu-asmalimescit-mah-is...</td>\n    </tr>\n    <tr>\n      <th>61</th>\n      <td>pizza-hut-umraniye-ihlamurkuyu-mah-istanbul</td>\n    </tr>\n    <tr>\n      <th>64</th>\n      <td>un-po-beyoglu-kemankes-mah-istanbul</td>\n    </tr>\n    <tr>\n      <th>43</th>\n      <td>vera-pizza-pasta-bakirkoy-cevizlik-mah-istanbul</td>\n    </tr>\n    <tr>\n      <th>48</th>\n      <td>kafein-plus-kucukcekmece-tevfikbey-mah-sefakoy...</td>\n    </tr>\n  </tbody>\n</table>\n<p>79 rows × 1 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "sql_command = \"\"\"\n",
    "    SELECT\n",
    "    \"RESTAURANT_ID\"\n",
    "    FROM \"ODS\".\"EXT_FB_RESTAURANT\" EFR\n",
    "    WHERE 1=1\n",
    "    AND NOT EXISTS(SELECT NULL FROM \"ODS\".\"EXT_FB_COMMENT\" EFC WHERE EFR.\"RESTAURANT_ID\" = EFC.\"RESTAURANT_ID\");\n",
    "    \"\"\"\n",
    "restaurant_df = pd.read_sql(sql_command,conn)\n",
    "restaurant_df = restaurant_df.sample(frac=1)\n",
    "restaurant_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(last_execution_date < end_date):\n",
    "    for i in range(len(restaurant_df)):\n",
    "        sublink = restaurant_df.loc[i,\"RESTAURANT_ID\"]\n",
    "        last_comment_page_url = \"{website}/{sublink}?section=comments&page=9999\".format(website=website,sublink=sublink)\n",
    "        \n",
    "        driver.get(last_comment_page_url)\n",
    "        time.sleep(0.1)\n",
    "\n",
    "        comments_list = []\n",
    "        \n",
    "        if(sublink not in driver.current_url):\n",
    "            continue\n",
    "\n",
    "        last_comment_page_redirect_url = driver.current_url\n",
    "        last_comment_page_number = int(last_comment_page_redirect_url.replace(\"&status=closed\",\"\").replace(\"{website}/{sublink}?section=comments&page=\".format(website=website,sublink=sublink),\"\"))\n",
    "\n",
    "        for page_number in range(1, last_comment_page_number+1):\n",
    "            current_comment_page_url = \"{website}/{sublink}?section=comments&page={page_number}\".format(website=website,sublink=sublink,page_number=page_number)\n",
    "            driver.get(current_comment_page_url)\n",
    "            time.sleep(1)\n",
    "\n",
    "            try:\n",
    "                if(\"sipariş verebilirsiniz.\" in driver.find_element_by_xpath('//*[@id=\"restaurantDetail\"]/div/div[2]/h3').text):\n",
    "                    continue\n",
    "                else:\n",
    "                    pass\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "            try:\n",
    "                driver.find_element(By.XPATH, '//*[@id=\"alternative-restaurant-popup\"]/div[1]/div[2]/img').click(); #Closing pop-up\n",
    "            except Exception:\n",
    "                pass   \n",
    "\n",
    "            #driver.find_element(By.XPATH, '//*[@id=\"restaurantDetail\"]/div[2]/div[1]/ul/li[4]/a').click(); #Clicking comments\n",
    "\n",
    "            comment_list = driver.find_elements_by_class_name(\"comments-body\")\n",
    "        \n",
    "            for comment in comment_list:\n",
    "                try:\n",
    "                    username = comment.find_element_by_class_name(\"userName\").text\n",
    "                    comment_text = comment.find_element_by_xpath('.//p').text\n",
    "                    comment_date = comment.find_element_by_class_name(\"commentDate\").text\n",
    "                except NoSuchElementException:\n",
    "                    continue\n",
    "                try:\n",
    "                    speed = comment.find_element_by_class_name(\"speed\").text\n",
    "                except NoSuchElementException:\n",
    "                    speed = \"\"\n",
    "                try:                    \n",
    "                    serving = comment.find_element_by_class_name(\"serving\").text\n",
    "                except NoSuchElementException:\n",
    "                    serving = \"\"\n",
    "                try:\n",
    "                    flavour = comment.find_element_by_class_name(\"flavour\").text \n",
    "                except NoSuchElementException:\n",
    "                    flavour = \"\"\n",
    "                comments_list.append([sublink, username, comment_text, comment_date, speed, serving, flavour])\n",
    "        comment_df = pd.DataFrame(comments_list, columns=[\"RESTAURANT_ID\",\"USERNAME\",\"COMMENT_TEXT\",\"COMMENT_DATE\",\"SPEED\",\"SERVING\",\"FLAVOUR\"])\n",
    "        df_column_conversation(comment_df, 'RESTAURANT_ID', 'text')\n",
    "        df_column_conversation(comment_df, 'USERNAME', 'text')\n",
    "        df_column_conversation(comment_df, 'COMMENT_TEXT', 'text')\n",
    "        df_column_conversation(comment_df, 'COMMENT_DATE', 'text')\n",
    "        df_column_conversation(comment_df, 'SPEED', 'text')\n",
    "        df_column_conversation(comment_df, 'SERVING', 'text')\n",
    "        df_column_conversation(comment_df, 'FLAVOUR', 'text')\n",
    "        comment_df['DATE'] = \"'\"+ datetime.strftime(date.today(), \"%Y-%m-%d\") + \"'::date\"\n",
    "        execute_mogrify(conn,comment_df,\"ODS\",\"EXT_FB_COMMENT\")\n",
    "    comment_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.quit()"
   ]
  },
  {
   "source": [
    "# Data Preprocessing"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(last_execution_date < end_date):\n",
    "    sql_command = \"\"\"\n",
    "        WITH CLEAN_DATA AS(\n",
    "        SELECT\n",
    "        EFC.\"RESTAURANT_ID\",\n",
    "        EFC.\"USERNAME\",\n",
    "        LOWER(EFC.\"COMMENT_TEXT\") AS \"COMMENT_TEXT\",\n",
    "        EFC.\"COMMENT_DATE\",\n",
    "        TRY_CAST(REGEXP_REPLACE(EFC.\"SPEED\", '\\D','','g'),NULL::INTEGER) AS \"SPEED\",\n",
    "        TRY_CAST(REGEXP_REPLACE(EFC.\"SERVING\", '\\D','','g'),NULL::INTEGER) AS \"SERVING\",\n",
    "        TRY_CAST(REGEXP_REPLACE(EFC.\"FLAVOUR\", '\\D','','g'),NULL::INTEGER) AS \"FLAVOUR\",\n",
    "        EFC.\"DATE\",\n",
    "        REGEXP_REPLACE(EFC.\"COMMENT_DATE\", '\\D','','g')||' '||REPLACE(REPLACE(REPLACE(REGEXP_REPLACE(REPLACE(EFC.\"COMMENT_DATE\",' önce',''), '[^[:alpha:]]', '', 'g'),'ay','month'),'bugün','today'),'gün','day') AS \"COMMENT_DATE_INTERVAL\"\n",
    "        FROM \"ODS\".\"EXT_FB_COMMENT\" EFC\n",
    "        WHERE 1=1\n",
    "        AND EFC.\"USERNAME\" <> 'Yemeksepeti'\n",
    "        )\n",
    "        SELECT\n",
    "        CD.\"RESTAURANT_ID\",\n",
    "        CD.\"USERNAME\",\n",
    "        CD.\"COMMENT_TEXT\",\n",
    "        CASE WHEN CD.\"COMMENT_DATE_INTERVAL\" = ' today' THEN CD.\"DATE\" ELSE CD.\"DATE\" - CAST(CD.\"COMMENT_DATE_INTERVAL\" AS INTERVAL) END::date AS \"COMMENT_DATE\",\n",
    "        CD.\"SPEED\",\n",
    "        CD.\"SERVING\",\n",
    "        CD.\"FLAVOUR\",\n",
    "        CD.\"DATE\"\n",
    "        FROM CLEAN_DATA CD;\n",
    "        \"\"\"\n",
    "    comment_df = pd.read_sql(sql_command,conn)\n",
    "    comment_df['COMMENT_TEXT'] = comment_df['COMMENT_TEXT'].apply(clean_text)\n",
    "    comment_df\n",
    "    df_column_conversation(comment_df, 'RESTAURANT_ID', 'text')\n",
    "    df_column_conversation(comment_df, 'USERNAME', 'text')\n",
    "    df_column_conversation(comment_df, 'COMMENT_TEXT', 'text')\n",
    "    df_column_conversation(comment_df, 'COMMENT_DATE', 'date')\n",
    "    df_column_conversation(comment_df, 'SPEED', 'integer')\n",
    "    df_column_conversation(comment_df, 'SERVING', 'integer')\n",
    "    df_column_conversation(comment_df, 'FLAVOUR', 'integer')\n",
    "    df_column_conversation(comment_df, 'DATE', 'date')\n",
    "    comment_df.replace('<NA>', 'NULL', inplace=True)\n",
    "    execute_mogrify(conn,comment_df,\"EDW\",\"DWH_FB_COMMENT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                     RESTAURANT_ID USERNAME  \\\n",
       "0       magic-akademi-kartal-esentepe-mah-istanbul     ...i   \n",
       "1       magic-akademi-kartal-esentepe-mah-istanbul     ...3   \n",
       "2       magic-akademi-kartal-esentepe-mah-istanbul     ...0   \n",
       "3       magic-akademi-kartal-esentepe-mah-istanbul     ...t   \n",
       "4       magic-akademi-kartal-esentepe-mah-istanbul     ...e   \n",
       "...                                            ...      ...   \n",
       "271838  magic-akademi-kartal-esentepe-mah-istanbul     ...1   \n",
       "271839  magic-akademi-kartal-esentepe-mah-istanbul     ...d   \n",
       "271840  magic-akademi-kartal-esentepe-mah-istanbul     ...k   \n",
       "271841  magic-akademi-kartal-esentepe-mah-istanbul     ...7   \n",
       "271842  magic-akademi-kartal-esentepe-mah-istanbul     ...l   \n",
       "\n",
       "                                             COMMENT_TEXT COMMENT_DATE  SPEED  \\\n",
       "0       i̇lk kez sipariş verdim bu restauranttan patat...   2021-01-10   10.0   \n",
       "1       her söyledigimde somon daha da kötüleşiyor bu ...   2021-01-10    9.0   \n",
       "2                                                     itu   2021-01-10    8.0   \n",
       "3          18 dkda kapıdaydi sıcak ve lezzetli süpersiniz   2021-01-10   10.0   \n",
       "4       dağ kekikli tavuğun yanında gelen makarna bild...   2021-01-10   10.0   \n",
       "...                                                   ...          ...    ...   \n",
       "271838        anladık ki hamburgerler kötü pizzadan devam   2021-01-10    5.0   \n",
       "271839  tiramisu malesef rezaletti kreması ekşimişti y...   2021-01-10    1.0   \n",
       "271840     dağ kekikli tavuk inanılmaz güzel bağımlısıyım   2021-01-10   10.0   \n",
       "271841  waffle söyledik kalın bir hamur üzerine 6 7 kü...   2021-01-10    6.0   \n",
       "271842  pizza adana börek ve pasta nefisti teşekkür ed...   2021-01-10   10.0   \n",
       "\n",
       "        SERVING  FLAVOUR        DATE  \n",
       "0             5        8  2021-06-10  \n",
       "1             6        4  2021-06-10  \n",
       "2             8        8  2021-06-10  \n",
       "3            10       10  2021-06-10  \n",
       "4             6        3  2021-06-10  \n",
       "...         ...      ...         ...  \n",
       "271838        5        5  2021-06-10  \n",
       "271839        1        1  2021-06-10  \n",
       "271840       10       10  2021-06-10  \n",
       "271841        4        3  2021-06-10  \n",
       "271842       10        9  2021-06-10  \n",
       "\n",
       "[271843 rows x 8 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>RESTAURANT_ID</th>\n      <th>USERNAME</th>\n      <th>COMMENT_TEXT</th>\n      <th>COMMENT_DATE</th>\n      <th>SPEED</th>\n      <th>SERVING</th>\n      <th>FLAVOUR</th>\n      <th>DATE</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>magic-akademi-kartal-esentepe-mah-istanbul</td>\n      <td>...i</td>\n      <td>i̇lk kez sipariş verdim bu restauranttan patat...</td>\n      <td>2021-01-10</td>\n      <td>10.0</td>\n      <td>5</td>\n      <td>8</td>\n      <td>2021-06-10</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>magic-akademi-kartal-esentepe-mah-istanbul</td>\n      <td>...3</td>\n      <td>her söyledigimde somon daha da kötüleşiyor bu ...</td>\n      <td>2021-01-10</td>\n      <td>9.0</td>\n      <td>6</td>\n      <td>4</td>\n      <td>2021-06-10</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>magic-akademi-kartal-esentepe-mah-istanbul</td>\n      <td>...0</td>\n      <td>itu</td>\n      <td>2021-01-10</td>\n      <td>8.0</td>\n      <td>8</td>\n      <td>8</td>\n      <td>2021-06-10</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>magic-akademi-kartal-esentepe-mah-istanbul</td>\n      <td>...t</td>\n      <td>18 dkda kapıdaydi sıcak ve lezzetli süpersiniz</td>\n      <td>2021-01-10</td>\n      <td>10.0</td>\n      <td>10</td>\n      <td>10</td>\n      <td>2021-06-10</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>magic-akademi-kartal-esentepe-mah-istanbul</td>\n      <td>...e</td>\n      <td>dağ kekikli tavuğun yanında gelen makarna bild...</td>\n      <td>2021-01-10</td>\n      <td>10.0</td>\n      <td>6</td>\n      <td>3</td>\n      <td>2021-06-10</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>271838</th>\n      <td>magic-akademi-kartal-esentepe-mah-istanbul</td>\n      <td>...1</td>\n      <td>anladık ki hamburgerler kötü pizzadan devam</td>\n      <td>2021-01-10</td>\n      <td>5.0</td>\n      <td>5</td>\n      <td>5</td>\n      <td>2021-06-10</td>\n    </tr>\n    <tr>\n      <th>271839</th>\n      <td>magic-akademi-kartal-esentepe-mah-istanbul</td>\n      <td>...d</td>\n      <td>tiramisu malesef rezaletti kreması ekşimişti y...</td>\n      <td>2021-01-10</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2021-06-10</td>\n    </tr>\n    <tr>\n      <th>271840</th>\n      <td>magic-akademi-kartal-esentepe-mah-istanbul</td>\n      <td>...k</td>\n      <td>dağ kekikli tavuk inanılmaz güzel bağımlısıyım</td>\n      <td>2021-01-10</td>\n      <td>10.0</td>\n      <td>10</td>\n      <td>10</td>\n      <td>2021-06-10</td>\n    </tr>\n    <tr>\n      <th>271841</th>\n      <td>magic-akademi-kartal-esentepe-mah-istanbul</td>\n      <td>...7</td>\n      <td>waffle söyledik kalın bir hamur üzerine 6 7 kü...</td>\n      <td>2021-01-10</td>\n      <td>6.0</td>\n      <td>4</td>\n      <td>3</td>\n      <td>2021-06-10</td>\n    </tr>\n    <tr>\n      <th>271842</th>\n      <td>magic-akademi-kartal-esentepe-mah-istanbul</td>\n      <td>...l</td>\n      <td>pizza adana börek ve pasta nefisti teşekkür ed...</td>\n      <td>2021-01-10</td>\n      <td>10.0</td>\n      <td>10</td>\n      <td>9</td>\n      <td>2021-06-10</td>\n    </tr>\n  </tbody>\n</table>\n<p>271843 rows × 8 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "sql_command = \"\"\"\n",
    "    SELECT\n",
    "    *\n",
    "    FROM \"EDW\".\"DWH_FB_COMMENT\" EFR;\n",
    "    \"\"\"\n",
    "comment_df = pd.read_sql(sql_command,conn)\n",
    "comment_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                     RESTAURANT_ID USERNAME  \\\n",
       "0       magic-akademi-kartal-esentepe-mah-istanbul     ...i   \n",
       "1       magic-akademi-kartal-esentepe-mah-istanbul     ...3   \n",
       "2       magic-akademi-kartal-esentepe-mah-istanbul     ...0   \n",
       "3       magic-akademi-kartal-esentepe-mah-istanbul     ...t   \n",
       "4       magic-akademi-kartal-esentepe-mah-istanbul     ...e   \n",
       "...                                            ...      ...   \n",
       "271838  magic-akademi-kartal-esentepe-mah-istanbul     ...1   \n",
       "271839  magic-akademi-kartal-esentepe-mah-istanbul     ...d   \n",
       "271840  magic-akademi-kartal-esentepe-mah-istanbul     ...k   \n",
       "271841  magic-akademi-kartal-esentepe-mah-istanbul     ...7   \n",
       "271842  magic-akademi-kartal-esentepe-mah-istanbul     ...l   \n",
       "\n",
       "                                             COMMENT_TEXT COMMENT_DATE  SPEED  \\\n",
       "0       i̇lk sipariş verdim restauranttan patates sıca...   2021-01-10   10.0   \n",
       "1       söyledigimde somon kötüleşiyor sefer fettucini...   2021-01-10    9.0   \n",
       "2                                                     itu   2021-01-10    8.0   \n",
       "3             18 dkda kapıdaydi sıcak lezzetli süpersiniz   2021-01-10   10.0   \n",
       "4       dağ kekikli tavuğun yanında gelen makarna bild...   2021-01-10   10.0   \n",
       "...                                                   ...          ...    ...   \n",
       "271838           anladık hamburgerler kötü pizzadan devam   2021-01-10    5.0   \n",
       "271839  tiramisu malesef rezaletti kreması ekşimişti y...   2021-01-10    1.0   \n",
       "271840     dağ kekikli tavuk inanılmaz güzel bağımlısıyım   2021-01-10   10.0   \n",
       "271841  waffle söyledik kalın bir hamur üzerine 6 7 kü...   2021-01-10    6.0   \n",
       "271842    pizza adana börek pasta nefisti teşekkür ederiz   2021-01-10   10.0   \n",
       "\n",
       "        SERVING  FLAVOUR        DATE  \n",
       "0             5        8  2021-06-10  \n",
       "1             6        4  2021-06-10  \n",
       "2             8        8  2021-06-10  \n",
       "3            10       10  2021-06-10  \n",
       "4             6        3  2021-06-10  \n",
       "...         ...      ...         ...  \n",
       "271838        5        5  2021-06-10  \n",
       "271839        1        1  2021-06-10  \n",
       "271840       10       10  2021-06-10  \n",
       "271841        4        3  2021-06-10  \n",
       "271842       10        9  2021-06-10  \n",
       "\n",
       "[271843 rows x 8 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>RESTAURANT_ID</th>\n      <th>USERNAME</th>\n      <th>COMMENT_TEXT</th>\n      <th>COMMENT_DATE</th>\n      <th>SPEED</th>\n      <th>SERVING</th>\n      <th>FLAVOUR</th>\n      <th>DATE</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>magic-akademi-kartal-esentepe-mah-istanbul</td>\n      <td>...i</td>\n      <td>i̇lk sipariş verdim restauranttan patates sıca...</td>\n      <td>2021-01-10</td>\n      <td>10.0</td>\n      <td>5</td>\n      <td>8</td>\n      <td>2021-06-10</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>magic-akademi-kartal-esentepe-mah-istanbul</td>\n      <td>...3</td>\n      <td>söyledigimde somon kötüleşiyor sefer fettucini...</td>\n      <td>2021-01-10</td>\n      <td>9.0</td>\n      <td>6</td>\n      <td>4</td>\n      <td>2021-06-10</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>magic-akademi-kartal-esentepe-mah-istanbul</td>\n      <td>...0</td>\n      <td>itu</td>\n      <td>2021-01-10</td>\n      <td>8.0</td>\n      <td>8</td>\n      <td>8</td>\n      <td>2021-06-10</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>magic-akademi-kartal-esentepe-mah-istanbul</td>\n      <td>...t</td>\n      <td>18 dkda kapıdaydi sıcak lezzetli süpersiniz</td>\n      <td>2021-01-10</td>\n      <td>10.0</td>\n      <td>10</td>\n      <td>10</td>\n      <td>2021-06-10</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>magic-akademi-kartal-esentepe-mah-istanbul</td>\n      <td>...e</td>\n      <td>dağ kekikli tavuğun yanında gelen makarna bild...</td>\n      <td>2021-01-10</td>\n      <td>10.0</td>\n      <td>6</td>\n      <td>3</td>\n      <td>2021-06-10</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>271838</th>\n      <td>magic-akademi-kartal-esentepe-mah-istanbul</td>\n      <td>...1</td>\n      <td>anladık hamburgerler kötü pizzadan devam</td>\n      <td>2021-01-10</td>\n      <td>5.0</td>\n      <td>5</td>\n      <td>5</td>\n      <td>2021-06-10</td>\n    </tr>\n    <tr>\n      <th>271839</th>\n      <td>magic-akademi-kartal-esentepe-mah-istanbul</td>\n      <td>...d</td>\n      <td>tiramisu malesef rezaletti kreması ekşimişti y...</td>\n      <td>2021-01-10</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2021-06-10</td>\n    </tr>\n    <tr>\n      <th>271840</th>\n      <td>magic-akademi-kartal-esentepe-mah-istanbul</td>\n      <td>...k</td>\n      <td>dağ kekikli tavuk inanılmaz güzel bağımlısıyım</td>\n      <td>2021-01-10</td>\n      <td>10.0</td>\n      <td>10</td>\n      <td>10</td>\n      <td>2021-06-10</td>\n    </tr>\n    <tr>\n      <th>271841</th>\n      <td>magic-akademi-kartal-esentepe-mah-istanbul</td>\n      <td>...7</td>\n      <td>waffle söyledik kalın bir hamur üzerine 6 7 kü...</td>\n      <td>2021-01-10</td>\n      <td>6.0</td>\n      <td>4</td>\n      <td>3</td>\n      <td>2021-06-10</td>\n    </tr>\n    <tr>\n      <th>271842</th>\n      <td>magic-akademi-kartal-esentepe-mah-istanbul</td>\n      <td>...l</td>\n      <td>pizza adana börek pasta nefisti teşekkür ederiz</td>\n      <td>2021-01-10</td>\n      <td>10.0</td>\n      <td>10</td>\n      <td>9</td>\n      <td>2021-06-10</td>\n    </tr>\n  </tbody>\n</table>\n<p>271843 rows × 8 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "stop_words = [element for element in stopwords.words('turkish') if element not in ['çok','eğer','gibi','hiç','niçin','niye','sanki','yani','en','az','birkaç','bazı','aslında','neden','hepsi']]\n",
    "comment_df['COMMENT_TEXT'] = comment_df['COMMENT_TEXT'].apply(lambda x: ' '.join([word for word in x.lower().split() if word not in (stop_words)]))\n",
    "#comment_df['COMMENT_TEXT'] = comment_df['COMMENT_TEXT'].apply(lambda x: ' '.join([stemmer.stem(word) for word in x.split()]))\n",
    "comment_df"
   ]
  },
  {
   "source": [
    "# Machine Learning"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Bag of Words"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Gaussian Naive Bayes"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-14-57e8c84ed6cb>:2: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  not_null_df = comment_df[0:10000][pd.notnull(comment_df['SPEED'])]\n",
      "Total Features after vectorizing: 2733\n",
      "Accuracy Score: 31.33%\n",
      "F1 Score: 31.33%\n",
      "Precision Score: 31.33%\n"
     ]
    }
   ],
   "source": [
    "model = CountVectorizer(min_df=3)\n",
    "not_null_df = comment_df[0:10000][pd.notnull(comment_df['SPEED'])]\n",
    "features = model.fit_transform(not_null_df['COMMENT_TEXT'].values).todense()\n",
    "labels = not_null_df['SPEED'].values\n",
    "print(\"Total Features after vectorizing: {total_features}\".format(total_features = np.shape(features)[1]))\n",
    "#print(np.shape(labels))\n",
    "\n",
    "features_train, features_test, labels_train, labels_test = train_test_split(features, labels, test_size = 0.3, random_state = 9)\n",
    "\n",
    "model = GaussianNB()\n",
    "model.fit(features_train, labels_train)\n",
    "\n",
    "label_prediction = model.predict(features_test)\n",
    "\n",
    "print(\"Accuracy Score: {accuracy_score:0.2f}%\".format(accuracy_score = accuracy_score(labels_test, label_prediction)*100))\n",
    "print(\"F1 Score: {f1_score:0.2f}%\".format(f1_score = f1_score(labels_test, label_prediction, average='micro')*100))\n",
    "print(\"Precision Score: {precision_score:0.2f}%\".format(precision_score  = precision_score(labels_test, label_prediction, average='micro')*100))"
   ]
  },
  {
   "source": [
    "### Support Vector Machines"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "#### C-Support Vector Classification"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Total Features after vectorizing: 2733\n",
      "<ipython-input-15-31bcc9e0fb71>:2: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  not_null_df = comment_df[0:10000][pd.notnull(comment_df['SPEED'])]\n",
      "Accuracy Score: 64.19%\n",
      "F1 Score: 64.19%\n",
      "Precision Score: 64.19%\n"
     ]
    }
   ],
   "source": [
    "model = CountVectorizer(min_df=3)\n",
    "not_null_df = comment_df[0:10000][pd.notnull(comment_df['SPEED'])]\n",
    "features = model.fit_transform(not_null_df['COMMENT_TEXT'].values).todense()\n",
    "labels = not_null_df['SPEED'].values\n",
    "print(\"Total Features after vectorizing: {total_features}\".format(total_features = np.shape(features)[1]))\n",
    "\n",
    "features_train, features_test, labels_train, labels_test = train_test_split(features, labels, test_size = 0.3, random_state = 9)\n",
    "\n",
    "model = SVC()\n",
    "model.fit(features_train, labels_train)\n",
    "\n",
    "label_prediction = model.predict(features_test)\n",
    "\n",
    "print(\"Accuracy Score: {accuracy_score:0.2f}%\".format(accuracy_score = accuracy_score(labels_test, label_prediction)*100))\n",
    "print(\"F1 Score: {f1_score:0.2f}%\".format(f1_score = f1_score(labels_test, label_prediction, average='micro')*100))\n",
    "print(\"Precision Score: {precision_score:0.2f}%\".format(precision_score  = precision_score(labels_test, label_prediction, average='micro')*100))"
   ]
  },
  {
   "source": [
    "#### Linear Support Vector Classification"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Total Features after vectorizing: 2733\n",
      "<ipython-input-16-abecfc9eee10>:2: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  not_null_df = comment_df[0:10000][pd.notnull(comment_df['SPEED'])]\n",
      "Accuracy Score: 60.05%\n",
      "F1 Score: 60.05%\n",
      "Precision Score: 60.05%\n"
     ]
    }
   ],
   "source": [
    "model = CountVectorizer(min_df=3)\n",
    "not_null_df = comment_df[0:10000][pd.notnull(comment_df['SPEED'])]\n",
    "features = model.fit_transform(not_null_df['COMMENT_TEXT'].values).todense()\n",
    "labels = not_null_df['SPEED'].values\n",
    "print(\"Total Features after vectorizing: {total_features}\".format(total_features = np.shape(features)[1]))\n",
    "\n",
    "features_train, features_test, labels_train, labels_test = train_test_split(features, labels, test_size = 0.3, random_state = 9)\n",
    "\n",
    "model = LinearSVC()\n",
    "model.fit(features_train, labels_train)\n",
    "\n",
    "label_prediction = model.predict(features_test)\n",
    "\n",
    "print(\"Accuracy Score: {accuracy_score:0.2f}%\".format(accuracy_score = accuracy_score(labels_test, label_prediction)*100))\n",
    "print(\"F1 Score: {f1_score:0.2f}%\".format(f1_score = f1_score(labels_test, label_prediction, average='micro')*100))\n",
    "print(\"Precision Score: {precision_score:0.2f}%\".format(precision_score  = precision_score(labels_test, label_prediction, average='micro')*100))"
   ]
  },
  {
   "source": [
    "### Decision Tree Classifier"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Total Features after vectorizing: 2619\n",
      "<ipython-input-17-de71e106f8b8>:2: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  not_null_df = comment_df[0:9600][pd.notnull(comment_df['SPEED'])]\n",
      "Best parameters: {'max_depth': 13, 'min_samples_split': 2}\n",
      "Accuracy Score: 63.09%\n",
      "F1 Score: 63.09%\n",
      "Precision Score: 63.09%\n"
     ]
    }
   ],
   "source": [
    "model = CountVectorizer(min_df=3)\n",
    "not_null_df = comment_df[0:9600][pd.notnull(comment_df['SPEED'])]\n",
    "features = model.fit_transform(not_null_df['COMMENT_TEXT'].values).todense()\n",
    "labels = not_null_df['SPEED'].values\n",
    "print(\"Total Features after vectorizing: {total_features}\".format(total_features = np.shape(features)[1]))\n",
    "\n",
    "features_train, features_test, labels_train, labels_test = train_test_split(features, labels, test_size = 0.3, random_state = 9)\n",
    "\n",
    "params = {\n",
    "    'max_depth': [10,13,14,15],\n",
    "    'min_samples_split': [2,3,4]\n",
    "    }\n",
    "\n",
    "gscv = GridSearchCV(DecisionTreeClassifier(), params, cv=5)\n",
    "gscv.fit(features_train, labels_train)\n",
    "print(\"Best parameters: {best_parameters}\".format(best_parameters = gscv.best_params_))\n",
    "\n",
    "model = gscv.best_estimator_\n",
    "model.fit(features_train, labels_train)\n",
    "\n",
    "label_prediction = model.predict(features_test)\n",
    "\n",
    "print(\"Accuracy Score: {accuracy_score:0.2f}%\".format(accuracy_score = accuracy_score(labels_test, label_prediction)*100))\n",
    "print(\"F1 Score: {f1_score:0.2f}%\".format(f1_score = f1_score(labels_test, label_prediction, average='micro')*100))\n",
    "print(\"Precision Score: {precision_score:0.2f}%\".format(precision_score  = precision_score(labels_test, label_prediction, average='micro')*100))"
   ]
  },
  {
   "source": [
    "### Logistic Regression"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Total Features after vectorizing: 2619\n",
      "<ipython-input-18-eccb7253df41>:2: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  not_null_df = comment_df[0:9600][pd.notnull(comment_df['SPEED'])]\n",
      "Accuracy Score: 63.19%\n",
      "F1 Score: 63.19%\n",
      "Precision Score: 63.19%\n"
     ]
    }
   ],
   "source": [
    "model = CountVectorizer(min_df=3)\n",
    "not_null_df = comment_df[0:9600][pd.notnull(comment_df['SPEED'])]\n",
    "features = model.fit_transform(not_null_df['COMMENT_TEXT'].values).todense()\n",
    "labels = not_null_df['SPEED'].values\n",
    "print(\"Total Features after vectorizing: {total_features}\".format(total_features = np.shape(features)[1]))\n",
    "\n",
    "features_train, features_test, labels_train, labels_test = train_test_split(features, labels, test_size = 0.3, random_state = 9)\n",
    "\n",
    "model = LogisticRegression(penalty='l2', C=1.2, n_jobs=-1)\n",
    "model.fit(features_train, labels_train)\n",
    "\n",
    "label_prediction = model.predict(features_test)\n",
    "\n",
    "print(\"Accuracy Score: {accuracy_score:0.2f}%\".format(accuracy_score = accuracy_score(labels_test, label_prediction)*100))\n",
    "print(\"F1 Score: {f1_score:0.2f}%\".format(f1_score = f1_score(labels_test, label_prediction, average='micro')*100))\n",
    "print(\"Precision Score: {precision_score:0.2f}%\".format(precision_score  = precision_score(labels_test, label_prediction, average='micro')*100))"
   ]
  },
  {
   "source": [
    "## Bag of Words with TF-IDF Vectorizer"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Gaussian Naive Bayes"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Total Features after vectorizing: 2733\n",
      "<ipython-input-19-6f54f08c5ef9>:2: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  not_null_df = comment_df[0:10000][pd.notnull(comment_df['SPEED'])]\n",
      "Accuracy Score: 31.43%\n",
      "F1 Score: 31.43%\n",
      "Precision Score: 31.43%\n"
     ]
    }
   ],
   "source": [
    "model = TfidfVectorizer(min_df=3)\n",
    "not_null_df = comment_df[0:10000][pd.notnull(comment_df['SPEED'])]\n",
    "features = model.fit_transform(not_null_df['COMMENT_TEXT'].values).todense()\n",
    "labels = not_null_df['SPEED'].values\n",
    "print(\"Total Features after vectorizing: {total_features}\".format(total_features = np.shape(features)[1]))\n",
    "#print(np.shape(labels))\n",
    "\n",
    "features_train, features_test, labels_train, labels_test = train_test_split(features, labels, test_size = 0.3, random_state = 9)\n",
    "\n",
    "model = GaussianNB()\n",
    "model.fit(features_train, labels_train)\n",
    "\n",
    "label_prediction = model.predict(features_test)\n",
    "\n",
    "print(\"Accuracy Score: {accuracy_score:0.2f}%\".format(accuracy_score = accuracy_score(labels_test, label_prediction)*100))\n",
    "print(\"F1 Score: {f1_score:0.2f}%\".format(f1_score = f1_score(labels_test, label_prediction, average='micro')*100))\n",
    "print(\"Precision Score: {precision_score:0.2f}%\".format(precision_score  = precision_score(labels_test, label_prediction, average='micro')*100))"
   ]
  },
  {
   "source": [
    "### Support Vector Machines"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "#### C-Support Vector Classification"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Total Features after vectorizing: 2733\n",
      "<ipython-input-20-ed41f9384cd3>:2: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  not_null_df = comment_df[0:10000][pd.notnull(comment_df['SPEED'])]\n",
      "Best parameters: {'C': 1.5, 'kernel': 'rbf'}\n",
      "Accuracy Score: 65.76%\n",
      "F1 Score: 65.76%\n",
      "Precision Score: 65.76%\n"
     ]
    }
   ],
   "source": [
    "model = TfidfVectorizer(min_df=3)\n",
    "not_null_df = comment_df[0:10000][pd.notnull(comment_df['SPEED'])]\n",
    "features = model.fit_transform(not_null_df['COMMENT_TEXT'].values).todense()\n",
    "labels = not_null_df['SPEED'].values\n",
    "print(\"Total Features after vectorizing: {total_features}\".format(total_features = np.shape(features)[1]))\n",
    "\n",
    "features_train, features_test, labels_train, labels_test = train_test_split(features, labels, test_size = 0.3, random_state = 9)\n",
    "\n",
    "params = {\n",
    "    'C': [1.5],\n",
    "    #'C': [1.4,1.5,1.6],\n",
    "    'kernel': ['rbf']\n",
    "    #'kernel': ['linear','rbf','sigmoid']\n",
    "    }\n",
    "\n",
    "gscv = GridSearchCV(SVC(), params, cv=5)\n",
    "gscv.fit(features_train, labels_train)\n",
    "print(\"Best parameters: {best_parameters}\".format(best_parameters = gscv.best_params_))\n",
    "\n",
    "model = gscv.best_estimator_\n",
    "model.fit(features_train, labels_train)\n",
    "\n",
    "label_prediction = model.predict(features_test)\n",
    "\n",
    "print(\"Accuracy Score: {accuracy_score:0.2f}%\".format(accuracy_score = accuracy_score(labels_test, label_prediction)*100))\n",
    "print(\"F1 Score: {f1_score:0.2f}%\".format(f1_score = f1_score(labels_test, label_prediction, average='micro')*100))\n",
    "print(\"Precision Score: {precision_score:0.2f}%\".format(precision_score  = precision_score(labels_test, label_prediction, average='micro')*100))"
   ]
  },
  {
   "source": [
    "#### Linear Support Vector Classification"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Total Features after vectorizing: 2733\n",
      "<ipython-input-21-61109543768c>:2: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  not_null_df = comment_df[0:10000][pd.notnull(comment_df['SPEED'])]\n",
      "Accuracy Score: 63.05%\n",
      "F1 Score: 63.05%\n",
      "Precision Score: 63.05%\n"
     ]
    }
   ],
   "source": [
    "model = TfidfVectorizer(min_df=3)\n",
    "not_null_df = comment_df[0:10000][pd.notnull(comment_df['SPEED'])]\n",
    "features = model.fit_transform(not_null_df['COMMENT_TEXT'].values).todense()\n",
    "labels = not_null_df['SPEED'].values\n",
    "print(\"Total Features after vectorizing: {total_features}\".format(total_features = np.shape(features)[1]))\n",
    "\n",
    "features_train, features_test, labels_train, labels_test = train_test_split(features, labels, test_size = 0.3, random_state = 9)\n",
    "\n",
    "model = LinearSVC()\n",
    "model.fit(features_train, labels_train)\n",
    "\n",
    "label_prediction = model.predict(features_test)\n",
    "\n",
    "print(\"Accuracy Score: {accuracy_score:0.2f}%\".format(accuracy_score = accuracy_score(labels_test, label_prediction)*100))\n",
    "print(\"F1 Score: {f1_score:0.2f}%\".format(f1_score = f1_score(labels_test, label_prediction, average='micro')*100))\n",
    "print(\"Precision Score: {precision_score:0.2f}%\".format(precision_score  = precision_score(labels_test, label_prediction, average='micro')*100))"
   ]
  },
  {
   "source": [
    "### Decision Tree Classifier"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Total Features after vectorizing: 2619\n",
      "<ipython-input-22-b6a83c6a06e2>:2: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  not_null_df = comment_df[0:9600][pd.notnull(comment_df['SPEED'])]\n",
      "Best parameters: {'max_depth': 10, 'min_samples_split': 2}\n",
      "Accuracy Score: 62.77%\n",
      "F1 Score: 62.77%\n",
      "Precision Score: 62.77%\n"
     ]
    }
   ],
   "source": [
    "model = TfidfVectorizer(min_df=3)\n",
    "not_null_df = comment_df[0:9600][pd.notnull(comment_df['SPEED'])]\n",
    "features = model.fit_transform(not_null_df['COMMENT_TEXT'].values).todense()\n",
    "labels = not_null_df['SPEED'].values\n",
    "print(\"Total Features after vectorizing: {total_features}\".format(total_features = np.shape(features)[1]))\n",
    "\n",
    "features_train, features_test, labels_train, labels_test = train_test_split(features, labels, test_size = 0.3, random_state = 9)\n",
    "\n",
    "params = {\n",
    "    'max_depth': [9,10,11],\n",
    "    'min_samples_split': [2,3]\n",
    "    }\n",
    "\n",
    "gscv = GridSearchCV(DecisionTreeClassifier(), params, cv=5)\n",
    "gscv.fit(features_train, labels_train)\n",
    "print(\"Best parameters: {best_parameters}\".format(best_parameters = gscv.best_params_))\n",
    "\n",
    "model = gscv.best_estimator_\n",
    "model.fit(features_train, labels_train)\n",
    "\n",
    "label_prediction = model.predict(features_test)\n",
    "\n",
    "print(\"Accuracy Score: {accuracy_score:0.2f}%\".format(accuracy_score = accuracy_score(labels_test, label_prediction)*100))\n",
    "print(\"F1 Score: {f1_score:0.2f}%\".format(f1_score = f1_score(labels_test, label_prediction, average='micro')*100))\n",
    "print(\"Precision Score: {precision_score:0.2f}%\".format(precision_score  = precision_score(labels_test, label_prediction, average='micro')*100))"
   ]
  },
  {
   "source": [
    "### Logistic Regression"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Total Features after vectorizing: 2619\n",
      "<ipython-input-23-3703865826cd>:2: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  not_null_df = comment_df[0:9600][pd.notnull(comment_df['SPEED'])]\n",
      "Accuracy Score: 65.71%\n",
      "F1 Score: 65.71%\n",
      "Precision Score: 65.71%\n"
     ]
    }
   ],
   "source": [
    "model = TfidfVectorizer(min_df=3)\n",
    "not_null_df = comment_df[0:9600][pd.notnull(comment_df['SPEED'])]\n",
    "features = model.fit_transform(not_null_df['COMMENT_TEXT'].values).todense()\n",
    "labels = not_null_df['SPEED'].values\n",
    "print(\"Total Features after vectorizing: {total_features}\".format(total_features = np.shape(features)[1]))\n",
    "\n",
    "features_train, features_test, labels_train, labels_test = train_test_split(features, labels, test_size = 0.3, random_state = 9)\n",
    "\n",
    "model = LogisticRegression(penalty='l2', C=1.2, n_jobs=-1)\n",
    "model.fit(features_train, labels_train)\n",
    "\n",
    "label_prediction = model.predict(features_test)\n",
    "\n",
    "print(\"Accuracy Score: {accuracy_score:0.2f}%\".format(accuracy_score = accuracy_score(labels_test, label_prediction)*100))\n",
    "print(\"F1 Score: {f1_score:0.2f}%\".format(f1_score = f1_score(labels_test, label_prediction, average='micro')*100))\n",
    "print(\"Precision Score: {precision_score:0.2f}%\".format(precision_score  = precision_score(labels_test, label_prediction, average='micro')*100))"
   ]
  },
  {
   "source": [
    "## Markov Chains"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                   RESTAURANT_ID  \\\n",
       "0    pizza-bulls-uskudar-altunizade-mah-istanbul   \n",
       "1         pizza-bulls-uskudar-ferah-mah-istanbul   \n",
       "2  pizza-bulls-kartal-soganlik-yeni-mah-istanbul   \n",
       "3       pizza-bulls-umraniye-cakmak-mah-istanbul   \n",
       "4        pizza-bulls-atasehir-fetih-mah-istanbul   \n",
       "\n",
       "                                         all_comment  comment_count  \n",
       "0  lezzeti eskisi gibi gelmedi bize. fark ödeyip ...           2293  \n",
       "1  her şey çok güzeldi. elinize sağlık. hizli ve ...           1764  \n",
       "2  cok pahali olmasi disinda bir problem yok gibi...           1743  \n",
       "3  çok lezzetli güvenle çoçuguma yedirebiliyorum ...           1582  \n",
       "4  servis ve hız 10 üzerinden 20.. bu siparişi is...           1277  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>RESTAURANT_ID</th>\n      <th>all_comment</th>\n      <th>comment_count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>pizza-bulls-uskudar-altunizade-mah-istanbul</td>\n      <td>lezzeti eskisi gibi gelmedi bize. fark ödeyip ...</td>\n      <td>2293</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>pizza-bulls-uskudar-ferah-mah-istanbul</td>\n      <td>her şey çok güzeldi. elinize sağlık. hizli ve ...</td>\n      <td>1764</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>pizza-bulls-kartal-soganlik-yeni-mah-istanbul</td>\n      <td>cok pahali olmasi disinda bir problem yok gibi...</td>\n      <td>1743</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>pizza-bulls-umraniye-cakmak-mah-istanbul</td>\n      <td>çok lezzetli güvenle çoçuguma yedirebiliyorum ...</td>\n      <td>1582</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>pizza-bulls-atasehir-fetih-mah-istanbul</td>\n      <td>servis ve hız 10 üzerinden 20.. bu siparişi is...</td>\n      <td>1277</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    "sql_command = \"\"\"\n",
    "    WITH COMMENTS AS(\n",
    "    SELECT \"RESTAURANT_ID\",\n",
    "    STRING_AGG(LOWER(\"COMMENT_TEXT\"), ' ') AS ALL_COMMENT,\n",
    "    COUNT(\"COMMENT_TEXT\") AS COMMENT_COUNT\n",
    "    FROM \"ODS\".\"EXT_FB_COMMENT\" EFC\n",
    "    GROUP BY \"RESTAURANT_ID\"\n",
    "    )\n",
    "    SELECT * \n",
    "    FROM COMMENTS\n",
    "    ORDER BY COMMENT_COUNT DESC;\n",
    "    \"\"\"\n",
    "restaurant_df = pd.read_sql(sql_command,conn)\n",
    "restaurant_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def make_markov_model(cleaned_stories, n_gram=2):\n",
    "    markov_model = {}\n",
    "    for i in range(len(cleaned_stories)-n_gram-1):\n",
    "        curr_state, next_state = \"\", \"\"\n",
    "        for j in range(n_gram):\n",
    "            curr_state += cleaned_stories[i+j] + \" \"\n",
    "            next_state += cleaned_stories[i+j+n_gram] + \" \"\n",
    "        curr_state = curr_state[:-1]\n",
    "        next_state = next_state[:-1]\n",
    "        if curr_state not in markov_model:\n",
    "            markov_model[curr_state] = {}\n",
    "            markov_model[curr_state][next_state] = 1\n",
    "        else:\n",
    "            if next_state in markov_model[curr_state]:\n",
    "                markov_model[curr_state][next_state] += 1\n",
    "            else:\n",
    "                markov_model[curr_state][next_state] = 1\n",
    "    \n",
    "    # calculating transition probabilities\n",
    "    for curr_state, transition in markov_model.items():\n",
    "        total = sum(transition.values())\n",
    "        for state, count in transition.items():\n",
    "            markov_model[curr_state][state] = count/total\n",
    "        \n",
    "    return markov_model\n",
    "\n",
    "def generate_story(markov_model, limit=100, start='my god'):\n",
    "    n = 0\n",
    "    curr_state = start\n",
    "    next_state = None\n",
    "    story = \"\"\n",
    "    story+=curr_state+\" \"\n",
    "    while n<limit:\n",
    "        next_state = random.choices(list(markov_model[curr_state].keys()),\n",
    "                                    list(markov_model[curr_state].values()))\n",
    "        \n",
    "        curr_state = next_state[0]\n",
    "        story+=curr_state+\" \"\n",
    "        n+=1\n",
    "    return story"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.  yemek çok güzeldi semih beye ilgisinden dolayı tesekkurler atakan kardeşim çok ilgili teşekkür ederim guzel güzel güzeldi güzlel harika harikaaaaa tavsiye ederim efsane lezzetin sıcacık ve çok lezzetliydi ayrıca ikram sufle için de teşekkürler sıcak olarak hızlı bir şekilde getirdiği için cumali \n1.  yemek çok güzeldi semih beyin özel ilgisi için ayrıca teşekkür ederim oğlumun doğum günü sebebiyle sufle hediyesiyle bizi oldukça mutlu etti çok lezzetliydi çok hızlı geldi çalışanlara arkadaşlara çok teşekkür ediyorum her zamanki gibi müthiş hizli servisleri sahane pizzalari ve kadinlar gunu \n2.  yemek çok lezzetliydi ve yanında 2 adet ikram sufle geldi 2 tane multinetten çektiği için surat yaptı ve maskesizdi bir daha asla suflenize bayılıyoruz gerçekten 30 liraya sufle satan yerlere taş çıkartırsınız hep böyle devam eder pizzalar gerçekten güzel ve lezzetliydi pizzamız \n3.  yemek çok güzeldi semih beye çok teşekkür ederiz çok lezzetliydi teşekkürler tatlı için teşekkür ederim özellikle aramanız inceliktir pizza çok küçüktü diğer restoranlarda bu fiyata büyük bi pizza getirdiği için teşekkür ederim pizza mükemmeldi mükemmeldi pizza da tek gecerim doyurucu lezzetli temiz \n4.  yemek çok lezzetliydi ve sıcak geldi suffle ikramı içinde teşekkürler bilal beyin ilgisine teşekkür ederim tatlı ikramınız için çok teşekkür ederim sipariş gelmeden önce arayıp bilgi verdi i̇kramlarınız için ayrıca teşekkür ederiz yardımcı oldu siparişim neredeyse 1 saatte ve soğuk geldi notum \n5.  yemek çok lezzetliydi ve restoran bana çok yakın olmamasına rağmen sıcaktı da soğan halkaları da tam tersi az pişmişti ama pizzanın lezzeti malzeme kalitesi ve malzeme kalitesi iyiydi sufle ikramı için semih bey e de ikram gönderdi şiddetle tavsiye edilir muazzam adeta \n6.  yemek çok lezzetliydi ve kuriyeniz atakan bey çok nazik teşekkürler küçük boy new jersey siparişi vermiştim gayet güzeldi çok hızlı sıcak güzel çok iyi nazik bi insan dı kendisine ayrıca teşekkür ederiz hızlı sıcak lezzetli çok lezzetliydi sicak geldi ikraminiz içinde teşekkür \n7.  yemek çok lezzetliydi ve hızlıydı tesekkurler çok hızlı ve sıcak geldi getiren çalışan arkadaşımız güler yüzle teslim etti sufle hediye edeceğiz diyip göndermeyerek beni üzseniz de seviyorum sufle ikramı için bilal beye ilgilerinden dolayı teşekkür ediyorum kuryenize de geçmiş olsun her zaman \n8.  yemek çok lezzetliydi ve hızlı ulaştı he zamanki gibi cumali beye ayrıca teşekkür ederim hızlı sıcak ve lezzetli geldi atakan beye ayrıca teşekkür ederim bize hediye sufle gönderen atakan beye çok teşekkür ederiz çok hızlı ve sıcak geldi ellerinize sağlık pizza bullsdan \n9.  yemek çok lezzetliydi ve kurye de çok hızlıydı semih bey sağolsun hızlı ve sıcak geldi bilal beyin göndermiş olduğu süpriz tatlı çocuklarımı ve beni çok mutlu etti tek kelimeyle mukemmel pizzalar sicacik geliyor ve citir bir hamuru var teslimat cok hizli yedigimiz \n10.  yemek çok güzeldi semih beye teşekkürler ürünler gayet sıcak geldi sıcak ve lezzetli ürünler ilgilenen arkadşlarada teşekür ederim hızlı sıcak ve lezzetli pizzaları için pizza bulls tatlı ikramları için çok çok teşekkür her şey çok güzeldi ürün sipariş ettiğimiz gibi ortalama bir \n11.  yemek çok lezzetliydi ve sıcak geldi cumali beye çok teşekkürler kuryeniz cumali beye kibarlığından dolayı teşekkür ederim atakan beye ikramlar icin teşekkür ederim fakat 1 saatte geldi çok lezzetliydi ayrıca ikramları için çok teşekkür ederiz selim beyin gonderdigi sufle icin cok teşekkür \n12.  yemek çok güzeldi semih beye çok teşekkürler ilgisi için keep up the good work d muhteşem hızlı taze ve sıcak geldi ayrıca teslimatı yapan ibrahim beye ayrıca teşekkürler pizzaları sıcacık ve kurye çok nazik bir beyefendiydi 2 senedir benim pizzamın adresi burasıayrıca \n13.  yemek çok lezzetliydi ve kurye de çok hızlıydı atakan beye ilgisinden dolayı teşekkürler bilal beye inceligi ve hediyeleri içn çok teşekkür ederim harika hatalarını telafi etmek için elinden geleni yapan bir firma tatlı ikramı için ayrıca teşekkürler soguk ve geç saat olduğu \n14.  yemek çok güzeldi semih beyin özel ilgisi için teşekkürler yarım saat olmadan sipariş sıcacık şekilde geldi bilal beye teşekkür ederiz sağlıkla kalın her zamanki gibi harikaydi sufle ikrami icin tesekkur ediyorum pizza dışındaki yan ürünler lezzet açısından sınıfta kaldı pizzanın dilim kesimleri \n15.  yemek çok lezzetliydi ve getiren arkadasta cok hizli ve saygiliydi kuryeniz mustafa beye teşekkür ederiz hiç beğenmedim hiçbir siparişimde beni mağdur etmenize rağmen bir kere bile pişman olmadım şaşırtmadı her zaman harika tatlı hediye göndermişler çok lezzetliydi teşekkürler tatlı ikramı için ayrıca \n16.  yemek çok güzeldi semih beye ilgisinden dolayı teşekkür ederiz atakan beye teşekkürler sıcacıktı kurye mustafa pizzaları çok hızlı ve sıcak geldi başarılarının devamını dilerim ridvan beydi sanirim tesekkurler semih beye çok teşekkürler böylesi karlı bir havada pizzalar sıcacık ve çok ilgiliydi pizza \n17.  yemek çok lezzetliydi ve hızlıydı tesekkurler çok hızlı teslimat ettiği için teşekkürler bilal bey olmak üzere tüm altunizade şubesi pizza bulls çalışanlarına özellikle duygu hanıma ilgi ve alakalarından dolayı bilal beye çok teşekkür ederim cumali beye ayrıca teşekkürler zincir pizzacılar arasındaki en \n18.  yemek çok güzeldi semih beye teşekkürler bilal beye tatlı ikramı ve ilgisinden dolayı tekrar teşekkür ediyorum cumaliye teşekkürler çıtır tavukların tadı hariç güzeldi pizzaları bol malzemeli geldi harikaydı e güzeldi baya elinize saglik teşekkürler fasfasf gayet başarılı ayrıca bilal beye de jestinden \n19.  yemek çok güzeldi semih beye ilgisinden dolayı teşekkür ederim bilal bey teşekkürler bilal bey in ilgi ve alakasina cok tesekkur ederiz semih beye ikramı yardımı ve ilgisi için servis hızlıydı kurye de çok nazikti kendileri pizzamız hızlı ve lezzetli kuryeler hep güler \n"
     ]
    }
   ],
   "source": [
    "restaurant_df['clean_comment'] = restaurant_df['all_comment'].apply(clean_text)\n",
    "text = restaurant_df.loc[0]['clean_comment'].split()\n",
    "\n",
    "markov_model = make_markov_model(text)\n",
    "\n",
    "for i in range(20):\n",
    "    print(str(i)+\". \", generate_story(markov_model, start=\"yemek çok\", limit=20))"
   ]
  },
  {
   "source": [
    "# Sources\n",
    "\n",
    " 1. [Selenium Documentation](https://selenium-python.readthedocs.io/)\n",
    " 2. [Selenium choose element by partial id](https://stackoverflow.com/questions/15845563/choose-element-by-partial-id-using-selenium-with-python)\n",
    " 3. [Selenium scroll down to end of the page](https://pythonbasics.org/selenium-scroll-down/)\n",
    " 4. [Selenium click button](https://stackoverflow.com/questions/52405456/selenium-how-to-click-on-javascript-button/52405550)\n",
    " 5. [Markov Chains](https://www.kaggle.com/orion99/markov-chain-nlp)\n",
    " 6. [Bag of Words](https://github.com/Suji04/NormalizedNerd/blob/master/Introduction%20to%20NLP/Bag%20of%20Words%20%2B%20TF-IDF.ipynb)\n",
    " 7. [Turkish Porter Stemmer](https://github.com/otuncelli/turkish-stemmer-python)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}